<html><head></head><body>
        <section>

            <header>
                <h1 class="header-title">Have a Good Command</h1>
            </header>

            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Concatenating with <kbd>cat</kbd></li>
<li>Recording and playing back terminal sessions</li>
<li>Finding files and file listing</li>
<li>Playing with <kbd>xargs</kbd></li>
<li>Translating with <kbd>tr</kbd></li>
<li>Checksum and verification</li>
<li>Cryptographic tools and hashes</li>
<li>Sorting unique and duplicate lines</li>
<li>Temporary file naming and random numbers</li>
<li>Splitting files and data</li>
<li>Slicing filenames based on extensions  </li>
<li>Renaming and moving files in bulk</li>
<li>Spell–checking and dictionary manipulation   </li>
<li>Automating interactive input</li>
<li>Making commands quicker by running parallel processes</li>
<li>Examining a directory, files and subdirectories in it</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Introduction</h1>
            </header>

            <article>
                
<p>Unix-like systems have the best command-line tools. Each command performs a simple function to make our work easier. These simple functions can be combined with other commands to solve complex problems. Combining simple commands is an art; you will get better at it as you practice and gain experience. This chapter introduces some of the most interesting and useful commands, including <kbd>grep</kbd>, <kbd>awk</kbd>, <kbd>sed</kbd>, and <kbd>find</kbd>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Concatenating with cat</h1>
            </header>

            <article>
                
<p>The <kbd>cat</kbd> command displays or concatenates the contents of a file, but <kbd>cat</kbd> is capable of more. For example, <kbd>cat</kbd> can combine standard input data with data from a file. One way of combining the <kbd>stdin</kbd> data with file data is to redirect <kbd>stdin</kbd> to a file and then append two files. The <kbd>cat</kbd> command can do this in a single invocation. The next recipes show basic and advanced usages of <kbd>cat</kbd>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The <kbd>cat</kbd> command is a simple and frequently used command and it stands for <strong>conCATenate</strong>.</p>
<p>The general syntax of <kbd>cat</kbd> for reading contents is as follows:</p>
<pre>
<strong>$ cat file1 file2 file3 ...</strong>
</pre>
<p>This command concatenates data from the files specified as command-line arguments and sends that data to <kbd>stdout</kbd>.</p>
<ul>
<li>To print contents of a single file, execute the following command:</li>
</ul>
<pre>
        <strong>$ cat file.txt</strong>
<strong>        This is a line inside file.txt</strong>
<strong>        This is the second line inside file.txt</strong>
</pre>
<ul>
<li>To print contents of more than one file, execute the following command:</li>
</ul>
<pre>
        <strong>$ cat one.txt two.txt </strong>
<strong>        This line is from one.txt</strong>
<strong>        This line is from two.txt</strong>
</pre>
<p>The <kbd>cat</kbd> command not only reads from files and concatenates the data but also reads from the standard input.</p>
<p>The pipe operator redirects data to the cat command's standard input as follows:</p>
<pre>
<strong>OUTPUT_FROM_SOME COMMANDS | cat</strong>
</pre>
<p>The <kbd>cat</kbd> command can also concatenate content from files with input from a terminal.</p>
<p>Combine <kbd>stdin</kbd> and data from another file, like this:</p>
<pre>
<strong>$ echo 'Text through stdin' | cat - file.txt</strong>
</pre>
<p>In this example, <kbd>-</kbd> acts as the filename for the <kbd>stdin</kbd> text.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>The <kbd>cat</kbd> command has many other options for viewing files. You can view the complete list by typing <kbd>man cat</kbd> in a terminal session.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting rid of extra blank lines</h1>
            </header>

            <article>
                
<p>Some text files contain two or more blank lines together. If you need to remove the extra blank lines, use the following syntax:</p>
<pre>
<strong>$ cat -s file</strong>
</pre>
<p>Consider the following example:</p>
<pre>
<strong>$ cat multi_blanks.txt</strong>
<strong>line 1</strong>


<strong>line 2</strong>
 


<strong>line 3</strong>
     



<strong>line 4</strong>

<strong>$ cat -s multi_blanks.txt # Squeeze adjacent blank lines</strong>
<strong>line 1</strong>
      
<strong>line 2</strong>
      
<strong>line 3</strong>

<strong>line 4</strong>
</pre>
<p>We can remove all blank lines with <kbd>tr</kbd>, as discussed in the <em>Translating with tr</em> recipe in this chapter.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Displaying tabs as ^I</h1>
            </header>

            <article>
                
<p>It is hard to distinguish tabs and repeated space characters. Languages such as Python may treat tabs and spaces differently. Mixtures of tabs and spaces may look similar in an editor, but appear as different indentations to the interpreter. It is difficult to identify the difference between tabs and spaces when viewing a file in a text editor. <kbd>cat</kbd> can also identify tabs. This helps you to debug indentation errors.</p>
<p>The <kbd>cat</kbd> command's <kbd>-T</kbd> option displays tab characters as <kbd>^I</kbd>:</p>
<pre>
$ cat file.py 
def function(): 
    var = 5 
        next = 6 
    third = 7 

$ cat -T file.py 
def function():
^Ivar = 5
^I^Inext = 6
^Ithird = 7^I
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Line numbers</h1>
            </header>

            <article>
                
<p>The cat command's <kbd>-n</kbd> flag prefixes a line number to each line. Consider this example:</p>
<pre>
<strong>$ cat lines.txt</strong>
<strong>line </strong>
<strong>line</strong>
<strong>line</strong>

<strong>$ cat -n lines.txt</strong>
<strong>     1 line</strong>
<strong>     2 line</strong>
<strong>     3 line</strong>
</pre>
<div class="packt_infobox">The <kbd>cat</kbd> command never changes a file. It sends output to <kbd>stdout</kbd> after modifying the input according to the options. Do not attempt to use redirection to overwrite your input file. The shell creates the new output file before it opens the input file. The <kbd>cat</kbd> command will not let you use the same file as input and redirected output. Trying to trick <kbd>cat</kbd> with a pipe and redirecting the output will empty the input file.</div>
<pre>
<strong>$&gt; echo "This will vanish" &gt; myfile</strong>
<strong>$&gt; cat -n myfile &gt;myfile</strong>
<strong>cat: myfile: input file is output file</strong>
<strong>$&gt; cat myfile | cat -n &gt;myfile</strong>
<strong>$&gt; ls -l myfile</strong>
<strong>-rw-rw-rw-. 1 user user 0 Aug 24 00:14 myfile   ;# myfile has 0
bytes</strong>
</pre>
<div class="packt_infobox">The <kbd>-n</kbd> option generates line numbers for all lines, including blank lines. If you want to skip numbering blank lines, use the <kbd>-b</kbd> option.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Recording and playing back terminal sessions</h1>
            </header>

            <article>
                
<p>Recording a screen session as a video is useful, but a video is an overkill for debugging terminal sessions or providing a shell tutorial.</p>
<p>The shell provides another option. The <kbd>script</kbd> command records your keystrokes and the timing of keystrokes as you type, and saves your input and the resulting output in a pair of files. The <kbd>scriptreplay</kbd> command will replay the session.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>script</kbd> and <kbd>scriptreplay</kbd> commands are available in most GNU/Linux distributions. You can create tutorials of command-line hacks and tricks by recording the terminal sessions. You can also share the recorded files for others to playback and see how to perform a particular task with the command line. You can even invoke other interpreters and record the keystrokes sent to that interpreter. You cannot record vi, emacs, or other applications that map characters to particular locations on the screen.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>Start recording the terminal session with the following command:</p>
<pre>
<strong>$ script -t 2&gt; timing.log -a output.session</strong>
</pre>
<p>A full example looks like this:</p>
<pre>
<strong>$ script -t 2&gt; timing.log -a output.session</strong>

<strong># This is a demonstration of tclsh</strong>
<strong>$ tclsh</strong>
<strong>% puts [expr 2 + 2]</strong>
<strong>4</strong>
<strong>% exit</strong>
<strong>$ exit</strong>
</pre>
<div class="packt_infobox">Note that this recipe will not work with shells that do not support redirecting only <kbd>stderr</kbd> to a file, such as the <kbd>csh</kbd> shell.</div>
<p>The <kbd>script</kbd> command accepts a filename as an argument. This file will hold the keystrokes and the command results. When you use the <kbd>-t</kbd> option, the script command sends timing data to <kbd>stdout</kbd>. The timing data can be redirected to a file (<kbd>timing.log</kbd>), which records the timing info for each keystroke and output. The previous example used <kbd>2&gt;</kbd> to redirect <kbd>stderr</kbd> to <kbd>timing.log</kbd>.</p>
<p>Using the two files, <kbd>timing.log</kbd> and <kbd>output.session</kbd>, we can replay the sequence of command execution as follows:</p>
<pre>
<strong>$ scriptreplay timing.log output.session</strong>
<strong># Plays the sequence of commands and output</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>We often record desktop videos to prepare tutorials. However, videos require a considerable amount of storage, while a terminal script file is just a text file, usually only in the order of kilobytes.</p>
<p>You can share the <kbd>timing.log</kbd> and <kbd>output.session</kbd> files to anyone who wants to replay a terminal session in their terminal.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Finding files and file listing</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command is one of the great utilities in the Unix/Linux command-line toolbox. It is useful both at the command line and in shell scripts. Like <kbd>cat</kbd> and <kbd>ls</kbd>, <kbd>find</kbd> has many features, and most people do not use it to its fullest. This recipe deals with some common ways to utilize <kbd>find</kbd> to locate files.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command uses the following strategy:  <kbd>find</kbd> descends through a hierarchy of files, matches files that meet the specified criteria, and performs some actions. The default action is to print the names of files and folders, which can be specified with the <kbd>-print</kbd> option.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>To list all the files and folders descending from a given directory, use this syntax:</p>
<pre>
<strong>$ find base_path</strong>
</pre>
<p>The <kbd>base_path</kbd> can be any location from which <kbd>find</kbd> should start descending (for example, <kbd>/home/slynux/</kbd>).</p>
<p>Here's an example of this command:</p>
<pre>
<strong>$ find . -print
.history</strong>
<strong>Downloads</strong>
<strong>Downloads/tcl.fossil</strong>
<strong>Downloads/chapter2.doc</strong>
<strong>…</strong>
</pre>
<p>The <kbd>.</kbd> specifies the current directory and <kbd>..</kbd> specifies the parent directory. This convention is followed throughout the Unix filesystem.</p>
<p>The print option separates each file or folder name with a <kbd>\n</kbd> (newline). The <kbd>-print0</kbd> option separates each name with a null character <kbd>'\0'</kbd>. The main use for <kbd>-print0</kbd> is to pass filenames containing newlines or whitespace characters to the <kbd>xargs</kbd> command. The <kbd>xargs</kbd> command will be discussed in more detail later:</p>
<pre>
<strong>$&gt; echo "test" &gt; "file name"</strong>
<strong>$&gt; find . -type f -print | xargs ls -l</strong>
<strong>ls: cannot access ./file: No such file or directory</strong>
<strong>ls: cannot access name: No such file or directory</strong>
<strong>$&gt; find . -type f -print0 | xargs -0 ls -l</strong>
<strong>-rw-rw-rw-. 1 user group 5  Aug 24 15:00 ./file name</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>The previous examples demonstrated using <kbd>find</kbd> to list all the files and folders in a filesystem hierarchy. The <kbd>find</kbd> command can select files based on glob or regular expression rules, depth in the filesystem tree, date, type of file, and more.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Search based on name or regular expression match</h1>
            </header>

            <article>
                
<p>The <kbd>-name</kbd> argument specifies a selection pattern for the name. The <kbd>-name</kbd> argument accepts both glob-style wildcards and regular expressions. In the following example, <kbd>'*.txt'</kbd> matches all the file or folder names ending with <kbd>.txt</kbd> and prints them.</p>
<div class="packt_infobox">Note the single quotes around <kbd>*.txt</kbd>. The shell will expand glob wildcards with no quotes or using double-quotes (<kbd>"</kbd>). The single quotes prevent the shell from expanding the <kbd>*.txt</kbd> and passes that string to the <kbd>find</kbd> command.</div>
<pre>
<strong>$ find /home/slynux -name '*.txt' -print</strong>
</pre>
<p>The <kbd>find</kbd> command has an option <kbd>-iname</kbd> (ignore case), which is similar to <kbd>-name</kbd>, but it matches filenames regardless of case.</p>
<p>Consider the following example:</p>
<pre>
<strong>$ ls</strong>
<strong>example.txt  EXAMPLE.txt  file.txt</strong>
<strong>$ find . -iname "example*" -print</strong>
<strong>./example.txt</strong>
<strong>./EXAMPLE.txt</strong>
</pre>
<p>The <kbd>find</kbd> command supports logical operations with the selection options. The   <kbd>-a</kbd>  and     <kbd>-and</kbd> options perform a logical <strong>AND</strong>, while the <kbd>-o</kbd> and <kbd>-or</kbd> option perform a logical <strong>OR</strong>.</p>
<pre>
<strong>$ ls</strong>
<strong>new.txt  some.jpg  text.pdf   stuff.png</strong>
<strong>$ find . \( -name '*.txt' -o -name '*.pdf' \) -print</strong>
<strong>./text.pdf</strong>
<strong>./new.txt</strong>
</pre>
<p>The previous command will print all the <kbd>.txt</kbd> and <kbd>.pdf</kbd> files, since the <kbd>find</kbd> command matches both <kbd>.txt</kbd> and <kbd>.pdf</kbd> files. <kbd>\(</kbd> and <kbd>\)</kbd> are used to treat <kbd>-name "*.txt" -o -name "*.pdf"</kbd> as a single unit.</p>
<p>The following command demonstrates using the <kbd>-and</kbd> operator to select only the file that starts with an <kbd>s</kbd> and has an <kbd>e</kbd> in the name somewhere.</p>
<pre>
<strong>$ find . \( -name '*e*' -and -name 's*' \) </strong>
<strong>./some.jpg</strong>
</pre>
<p>The <kbd>-path</kbd> argument restricts the match to files that match a path as well as a name. For example, <kbd>$ find /home/users -path '*/slynux/*' -name '*.txt' -print</kbd> will find <kbd>/home/users/slynux/readme.txt</kbd>, but not <kbd>/home/users/slynux.txt</kbd>.</p>
<div class="packt_infobox">The <kbd>-regex</kbd> argument is similar to <kbd>-path</kbd>, but <kbd>-regex</kbd> matches the file paths based on regular expressions.</div>
<p>Regular expressions are more complex than glob wildcards and support more precise pattern matching. A typical example of text matching with regular expressions is to recognize all e-mail addresses. An e-mail address takes the <kbd>name@host.root</kbd> form. It can be generalized as <kbd>[a-z0-9]+@[a-z0-9]+\.[a-z0-9]+</kbd>. The characters inside the square brackets represent a set of characters. In this case, <kbd>a-z</kbd> and <kbd>0-9</kbd> The <kbd>+</kbd> sign signifies that the previous class of characters can occur one or more times. A period is a single character wildcard (like a <kbd>?</kbd> in glob wildcards), so it must be escaped with a backslash to match an actual dot in the e-mail address. So, this regular expression translates to 'a sequence of letters or numbers, followed by an <kbd>@</kbd>, followed by a sequence of letters or numbers, followed by a period, and ending with a sequence of letters or numbers'. See the <em>Using regular expressions </em> recipe in <a href="22424a9e-fea7-49de-9589-ea32aeb0b829.xhtml" target="_blank">Chapter 4</a>, <em>Texting and Driving  </em>for more details.</p>
<p>This command matches the <kbd>.py</kbd> or <kbd>.sh</kbd> files:</p>
<pre>
<strong>$ ls</strong>
<strong>new.PY  next.jpg  test.py script.sh
</strong><strong>$ find . -regex '.*\.(py\|sh\)$'</strong>
<strong>./test.py
script.sh</strong>
</pre>
<p>The <kbd>-iregex</kbd> option ignores the case for regular expression matches.</p>
<p>Consider this example:</p>
<pre>
<strong>$ find . -iregex '.*\(\.py\|\.sh\)$'</strong>
<strong>./test.py</strong>
<strong>./new.PY
./script.sh</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Negating arguments</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command can also exclude things that match a pattern using <kbd>!</kbd>:</p>
<pre>
<strong>$ find . ! -name "*.txt" -print</strong>
</pre>
<p>This will match all the files whose names do not end in <kbd>.txt</kbd>. The following example shows the result of the command:</p>
<pre>
<strong>$ ls</strong>
<strong>list.txt  new.PY  new.txt  next.jpg  test.py</strong>

<strong>$ find . ! -name "*.txt" -print</strong>
<strong>.</strong>
<strong>./next.jpg</strong>
<strong>./test.py</strong>
<strong>./new.PY</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Searching based on the directory depth</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command walks through all the subdirectories until it reaches the bottom of each subdirectory tree. By default, the <kbd>find</kbd> command will not follow symbolic links. The <kbd>-L</kbd> option will force it to follow symbolic links. If a link references a link that points to the original, <kbd>find</kbd> will be stuck in a loop.</p>
<p>The <kbd>-maxdepth</kbd> and <kbd>-mindepth</kbd> parameters restrict how far the <kbd>find</kbd> command will traverse. This will break the <kbd>find</kbd> command from an otherwise infinite search.</p>
<p>The <kbd>/proc</kbd> filesystem contains information about your system and running tasks. The folder hierarchy for a task is quite deep and includes symbolic links that loop back on themselves. Each process running your system has an entry in <kbd>proc</kbd>, named for the process ID. Under each process ID is a folder called <kbd>cwd</kbd>, which is a link to that task's current working directory.</p>
<p>The following example shows how to list all the tasks that are running in a folder with a file named <kbd>bundlemaker.def</kbd>:</p>
<pre>
<strong>$ find -L /proc -maxdepth 3 -name 'bundlemaker.def' 2&gt;/dev/null</strong>
</pre>
<ul>
<li>The <kbd>-L</kbd> option tells the <kbd>find</kbd> command to follow symbolic links</li>
<li>The <kbd>/proc</kbd> is a folder to start searching</li>
<li>The <kbd>-maxdepth 3</kbd> option limits the search to only the current folder, not subfolders</li>
<li>The <kbd>-name 'bundlemaker.def'</kbd> option is the file to search for</li>
<li>The <kbd>2&gt;/dev/null</kbd> redirects error messages about recursive loops to the null device</li>
</ul>
<p>The <kbd>-mindepth</kbd> option is similar to <kbd>-maxdepth</kbd>, but it sets the minimum depth for which <kbd>find</kbd> will report matches. It can be used to find and print files that are located with a minimum level of depth from the base path. For example, to print all files whose names begin with <kbd>f</kbd> and that are at least two subdirectories distant from the current directory, use the following command:</p>
<pre>
<strong>$ find . -mindepth 2 -name "f*" -print</strong>
<strong>./dir1/dir2/file1</strong>
<strong>./dir3/dir4/f2</strong>
</pre>
<p>Files with names starting with <kbd>f</kbd> in the current directory or in <kbd>dir1</kbd> and <kbd>dir3</kbd> will not be printed.</p>
<div class="packt_infobox">The <kbd>-maxdepth</kbd> and <kbd>-mindepth</kbd> option should be early in the <kbd>find</kbd> command. If they are specified as later arguments, it may affect the efficiency of <kbd>find</kbd> as it has to do unnecessary checks. For example, if <kbd>-maxdepth</kbd> is specified after a <kbd>-type</kbd> argument, the <kbd>find</kbd> command will first find the files having the specified <kbd>-type</kbd> and then filter out the files that don't match the proper depth. However, if the depth was specified before the <kbd>-type</kbd>, <kbd>find</kbd> will collect the files having the specified depth and then check for the file type, which is the most efficient way to search.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Searching based on file type</h1>
            </header>

            <article>
                
<p>Unix-like operating systems treat every object as a file. There are different kinds of file, such as regular files, directory, character devices, block devices, symlinks, hardlinks, sockets, FIFO, and so on.</p>
<p>The <kbd>find</kbd> command filters the file search with the <kbd>-type</kbd> option. Using <kbd>-type</kbd>, we can tell the <kbd>find</kbd> command to match only files of a specified type.</p>
<p>List only directories including descendants:</p>
<pre>
<strong>$ find . -type d -print</strong>
</pre>
<p>It is hard to list directories and files separately. But <kbd>find</kbd> helps to do it. List only regular files as follows:</p>
<pre>
<strong>$ find . -type f -print</strong>
</pre>
<p>List only symbolic links as follows:</p>
<pre>
<strong>$ find . -type l -print</strong>
</pre>
<p>The following table shows the types and arguments <kbd>find</kbd> recognizes:</p>
<table class="table">
<tbody>
<tr>
<td>
<div class="CDPAlignCenter CDPAlign"><strong>File type</strong></div>
</td>
<td>
<div class="CDPAlignCenter CDPAlign"><strong>Type argument</strong></div>
</td>
</tr>
<tr>
<td>
<p>Regular file</p>
</td>
<td>
<p><kbd>f</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Symbolic link</p>
</td>
<td>
<p><kbd>l</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Directory</p>
</td>
<td>
<p><kbd>d</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Character special device</p>
</td>
<td>
<p><kbd>c</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Block device</p>
</td>
<td>
<p><kbd>b</kbd></p>
</td>
</tr>
<tr>
<td>
<p>Socket</p>
</td>
<td>
<p><kbd>s</kbd></p>
</td>
</tr>
<tr>
<td>
<p>FIFO</p>
</td>
<td>
<p><kbd>p</kbd></p>
</td>
</tr>
</tbody>
</table>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Searching by file timestamp</h1>
            </header>

            <article>
                
<p>Unix/Linux filesystems have three types of timestamp on each file. They are as follows:</p>
<ul>
<li><strong>Access time</strong> (<kbd>-atime</kbd>): The timestamp when the file was last accessed</li>
<li><strong>Modification time</strong> (<kbd>-mtime</kbd>): The timestamp when the file was last modified</li>
<li><strong>Change time</strong> (<kbd>-ctime</kbd>): The timestamp when the metadata for a file (such as permissions or ownership) was last modified</li>
</ul>
<div class="packt_infobox">Unix does not store file creation time by default; however, some filesystems (<kbd>ufs2</kbd>, <kbd>ext4</kbd>, <kbd>zfs</kbd>, <kbd>btrfs</kbd>, <kbd>jfs</kbd>) save the creation time. The creation time can be accessed with the stat command.<br/>
Given that some applications modify a file by creating a new file and then deleting the original, the creation date may not be accurate.<br/>
The <kbd>-atime</kbd>, <kbd>-mtime</kbd>, and <kbd>-ctime</kbd> option are the time parameter options available with <kbd>find</kbd>. They can be specified with integer values in <em>number of days</em>. The number may be prefixed with <kbd>-</kbd> or <kbd>+</kbd> signs. The <kbd>-</kbd> sign implies less than, whereas the <kbd>+</kbd> sign implies greater than.</div>
<p>Consider the following example:</p>
<ul>
<li>Print files that were accessed within the last seven days:</li>
</ul>
<pre>
        <strong>$ find . -type f -atime -7 -print</strong>
</pre>
<ul>
<li>Print files that have an access time exactly seven days old:</li>
</ul>
<pre>
        <strong>$ find . -type f -atime 7 -print</strong>
</pre>
<ul>
<li>Print files that have an access time older than seven days:</li>
</ul>
<pre>
        <strong>$ find . -type f -atime +7 -print</strong>
</pre>
<p>The <kbd>-mtime</kbd> parameter will search for files based on the modification time; <kbd>-ctime</kbd> searches based on the change time.</p>
<p>The <kbd>-atime</kbd>, <kbd>-mtime</kbd>, and <kbd>-ctime</kbd> use time measured in days. The <kbd>find</kbd> command also supports options that measure in minutes. These are as follows:</p>
<ul>
<li><kbd>-amin</kbd> (access time)</li>
<li><kbd>-mmin</kbd> (modification time)</li>
<li><kbd>-cmin</kbd> (change time)</li>
</ul>
<p>To print all the files that have an access time older than seven minutes, use the following command:</p>
<pre>
<strong>$ find . -type f -amin +7 -print</strong>
</pre>
<p>The <kbd>-newer</kbd> option specifies a reference file with a modification time that will be used to select files modified more recently than the reference file.</p>
<p>Find all the files that were modified more recently than <kbd>file.txt</kbd> file:</p>
<pre>
<strong>$ find . -type f -newer file.txt -print</strong>
</pre>
<p>The <kbd>find</kbd> command's timestamp flags are useful for writing backup and maintenance scripts.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Searching based on file size</h1>
            </header>

            <article>
                
<p>Based on the file sizes of the files, a search can be performed:</p>
<pre>
<strong># Files having size greater than 2 kilobytes</strong>
<strong>$ find . -type f -size +2k</strong>

<strong># Files having size less than 2 kilobytes</strong>
<strong>$ find . -type f -size -2k</strong>

<strong># Files having size 2 kilobytes</strong>
<strong>$ find . -type f -size 2k</strong>
</pre>
<p>Instead of <kbd>k</kbd>, we can use these different size units:</p>
<ul>
<li><kbd>b</kbd>: 512 byte blocks</li>
<li><kbd>c</kbd>: Bytes</li>
<li><kbd>w</kbd>: Two-byte words</li>
<li><kbd>k</kbd>: Kilobytes (1,024 bytes)</li>
<li><kbd>M</kbd>: Megabytes (1,024 kilobytes)</li>
<li><kbd>G</kbd>: Gigabytes (1,024 megabytes)</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Matching based on file permissions and ownership</h1>
            </header>

            <article>
                
<p>It is possible to match files based on the file permissions. We can list out the files with specified file permissions:</p>
<pre>
<strong>$ find . -type f -perm 644 -print</strong>
<strong># Print files having permission 644</strong>
</pre>
<p>The <kbd>-perm</kbd> option specifies that <kbd>find</kbd> should only match files with their permission set to a particular value. Permissions are explained in more detail in the <em>Working with file permissions, ownership, </em><em>and the sticky bit </em> recipe in <a href="" target="_blank"><span class="ChapterrefPACKT">Chapter 3</span></a>, <em>File In, File Out</em>.</p>
<p>As an example usage case, we can consider the case of the Apache web server. The PHP files in the web server require proper permissions to execute. We can find PHP files that don't have proper executing permissions:</p>
<pre>
<strong>$ find . -type f -name "*.php" ! -perm 644 -print
PHP/custom.php</strong>
<strong>$ ls -l PHP/custom.php</strong>
<strong>-rw-rw-rw-.  root   root   513 Mar 13  2016  PHP/custom.php</strong>
</pre>
<p>We can also search files based on ownership. The files owned by a specific user can be found with the <kbd>-user USER</kbd> option.</p>
<p>The <kbd>USER</kbd> argument can be a username or UID.</p>
<p>For example, to print a list of all files owned by the <kbd>slynux</kbd> user, you can use the following command:</p>
<pre>
<strong>$ find . -type f -user slynux -print</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Performing actions on files with find</h1>
            </header>

            <article>
                
<p>The find command can perform actions on the files it identifies. You can delete files, or execute an arbitrary Linux command on the files.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Deleting based on file matches</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command's <kbd>-delete</kbd> flag removes files that are matched instead of displaying them. Remove the <kbd>.swp</kbd> files from the current directory:</p>
<pre>
<strong>$ find . -type f -name "*.swp" -delete</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Executing a command</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command can be coupled with many of the other commands using the <kbd>-exec</kbd> option.</p>
<p>Consider the previous example. We used <kbd>-perm</kbd> to find files that do not have proper permissions. Similarly, in the case where we need to change the ownership of all files owned by a certain user (for example, <kbd>root</kbd>) to another user (for example, <kbd>www-data</kbd>, the default Apache user in the web server), we can find all the files owned by <kbd>root</kbd> using the <kbd>-user</kbd> option and use <kbd>-exec</kbd> to perform the ownership change operation.</p>
<div class="packt_tip">You must run the <kbd>find</kbd> command as root if you want to change the ownership of files or directories.</div>
<p>The <kbd>find</kbd> command uses an open/close curly brace pair <kbd>{}</kbd> to represent the filename. In the next example, each time <kbd>find</kbd> identifies a file it will replace the <kbd>{}</kbd> with the filename and change the ownership of the file. For example, if the <kbd>find</kbd> command finds two files with the <kbd>root</kbd> owner it will change both so they're owned by <kbd>slynux</kbd>:</p>
<pre>
<strong># find . -type f -user root -exec chown slynux {} \;</strong>
</pre>
<div class="packt_infobox">Note that the command is terminated with <kbd>\;</kbd>. The semicolon must be escaped or it will be grabbed by your command shell as the end of the <kbd>find</kbd> command instead of the end of the <kbd>chown</kbd> command.</div>
<p>Invoking a command for each file is a lot of overhead. If the command accepts multiple arguments (as <kbd>chown</kbd> does) you can terminate the command with a plus (<kbd>+</kbd>) instead of a semicolon. The plus causes <kbd>find</kbd> to make a list of all the files that match the search parameter and execute the application once with all the files on a single command line.</p>
<p>Another usage example is to concatenate all the C program files in a given directory and write them to a single file, say, <kbd>all_c_files.txt</kbd>. Each of these examples will perform this action:</p>
<pre>
<strong>$ find . -type f -name '*.c' -exec cat {} \;&gt;all_c_files.txt</strong>
<strong>$ find . -type f -name '*.c' -exec cat {} &gt; all_c_files.txt \;</strong>
<strong>$ fine . -type f -name '*.c' -exec cat {} &gt;all_c_files.txt +</strong>
</pre>
<p>To redirect the data from <kbd>find</kbd> to the <kbd>all_c_files.txt</kbd> file, we used the <kbd>&gt;</kbd> operator instead of <kbd>&gt;&gt;</kbd> (append) because the entire output from the <kbd>find</kbd> command is a single data stream (<kbd>stdin</kbd>); <kbd>&gt;&gt;</kbd> is necessary when multiple data streams are to be appended to a single file.</p>
<p>The following command will copy all the <kbd>.txt</kbd> files that are older than 10 days to a directory <kbd>OLD</kbd>:</p>
<pre>
<strong>$ find . -type f -mtime +10 -name "*.txt" -exec cp {} OLD  \;</strong>
</pre>
<p>The <kbd>find</kbd> command can be coupled with many other commands.</p>
<div class="packt_tip">We cannot use multiple commands along with the <kbd>-exec</kbd> parameter. It accepts only a single command, but we can use a trick. Write multiple commands in a shell script (for example, <kbd>commands.sh</kbd>) and use it with <kbd>-exec</kbd> as follows:</div>
<pre>
<strong>-exec ./commands.sh {} \;</strong>
</pre>
<p>The <kbd>-exec</kbd> parameter can be coupled with <kbd>printf</kbd> to produce <kbd>joutput</kbd>. Consider this example:</p>
<pre>
<strong>$ find . -type f -name "*.txt" -exec printf "Text file: %s\n" {} \;</strong>
<strong>Config file: /etc/openvpn/easy-rsa/openssl-1.0.0.cnf</strong>
<strong>Config file: /etc/my.cnf</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Skipping specified directories when using the find command</h1>
            </header>

            <article>
                
<p>Skipping certain subdirectories may improve performance during the operation of <kbd>find</kbd>. For example, when searching for files in a development source tree under a version control system such as <kbd>Git</kbd>, the filesystem contains a directory in each of the subdirectories where version-control-related information is stored. These directories may not contain useful files and should be excluded from the search.</p>
<p>The technique of excluding files and directories is known as <strong>pruning</strong>. The following example shows how to use the <kbd>-prune</kbd> option to exclude files that match a pattern.</p>
<pre>
<strong>$ find devel/source_path  -name '.git' -prune -o -type f -print</strong>
</pre>
<p>The <kbd>-name ".git" -prune</kbd> is the pruning section, which specifies that <kbd>.git</kbd> directories should be excluded. The <kbd>-type f -print</kbd> section describes the action to be performed.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Playing with xargs</h1>
            </header>

            <article>
                
<p>Unix commands accept data either from the standard input (<kbd>stdin</kbd>) or as command line arguments. Previous examples have shown how to pass data from one application's standard output to another's standard input with a pipe.</p>
<p>We can invoke applications that accept command-line arguments in other ways. The simplest is to use the back-tic symbol to run a command and use its output as a command line:</p>
<pre>
<strong>$ gcc `find '*.c'`</strong>
</pre>
<p>This solution works fine in many situations, but if there are a lot of files to be processed, you'll see the dreaded <kbd>Argument list too long</kbd> error message. The <kbd>xargs</kbd> program solves this problem.</p>
<p>The <kbd>xargs</kbd> command reads a list of arguments from <kbd>stdin</kbd> and executes a command using these arguments in the command line. The <kbd>xargs</kbd> command can also convert any one-line or multiple-line text inputs into other formats, such as multiple lines (specified number of columns) or a single line, and vice versa.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>xargs</kbd> command should be the first command to appear after a pipe operator. It uses standard input as the primary data source and executes another command using the values it reads from <kbd>stdin</kbd> as command-line arguments for the new command. This example will search for the main string in a collection of C files:</p>
<pre>
<strong>ls *.c | xargs grep main</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The <kbd>xargs</kbd> command supplies arguments to a target command by reformatting the data received through <kbd>stdin</kbd>. By default, <kbd>xargs</kbd> will execute the <kbd>echo</kbd> command. In many respects, the <kbd>xargs</kbd> command is similar to the actions performed by the <kbd>find</kbd> command's <kbd>-exec</kbd> option:</p>
<ul>
<li>Converting multiple lines of input to a single-line output:</li>
</ul>
<p style="padding-left: 60px">Xarg's default <kbd>echo</kbd> command can be used to convert multiple-line input to single-line text, like this:</p>
<pre>
          <strong>$ cat example.txt # Example file</strong>
<strong>          1 2 3 4 5 6 </strong>
<strong>          7 8 9 10 </strong>
<strong>          11 12</strong>
 
<strong>          $ cat example.txt | xargs</strong>
<strong>          1 2 3 4 5 6 7 8 9 10 11 12</strong>
</pre>
<ul>
<li>Converting single-line into multiple-line output:</li>
</ul>
<p style="padding-left: 60px">The <kbd>-n</kbd> argument to <kbd>xargs</kbd> limits the number of elements placed on each command line invocation. This recipe splits the input into multiple lines of <em>N</em> items each:</p>
<pre>
          <strong>$ cat example.txt | xargs -n 3</strong>
<strong>          1 2 3 </strong>
<strong>          4 5 6 </strong>
<strong>          7 8 9 </strong>
<strong>          10 11 12</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>The <kbd>xargs</kbd> command works by accepting input from <kbd>stdin</kbd>, parsing the data into individual elements, and invoking a program with these elements as the final command line arguments. By default, <kbd>xargs</kbd> will split the input based on whitespace and execute <kbd>/bin/echo</kbd>.</p>
<p>Splitting the input into elements based on whitespace becomes an issue when file and folder names have spaces (or even newlines) in them. The <kbd>My Documents</kbd> folder would be parsed into two elements <kbd>My</kbd> and <kbd>Documents</kbd>, neither of which exists.</p>
<p>Most problems have solutions and this is no exception.</p>
<p>We can define the delimiter used to separate arguments. To specify a custom delimiter for input, use the <kbd>-d</kbd> option:</p>
<pre>
<strong>$ echo "split1Xsplit2Xsplit3Xsplit4" | xargs -d X</strong>
<strong>split1 split2 split3 split4</strong>
</pre>
<p>In the preceding code, <kbd>stdin</kbd> contains a string consisting of multiple <kbd>X</kbd> characters. We define <kbd>X</kbd> to be the input delimiter with the <kbd>-d option</kbd>.</p>
<p>Using <kbd>-n</kbd> along with the previous command, we can split the input into multiple lines of two words each as follows:</p>
<pre>
<strong>$ echo "splitXsplitXsplitXsplit" | xargs -d X -n 2</strong>
<strong>split split</strong>
<strong>split split</strong>
</pre>
<p>The <kbd>xargs</kbd> command integrates well with the find command. The output from find can be piped to <kbd>xargs</kbd> to perform more complex actions than the <kbd>-exec</kbd> option can handle. If the filesystem has files with spaces in the name, the find command's <kbd>-print0</kbd> option will use a <kbd>0</kbd> (NULL) to delimit the elements, which works with the <kbd>xargs -0</kbd> option to parse these. The following example searches for <kbd>.docx</kbd> files on a Samba mounted filesystem, where names with capital letters and spaces are common. It uses <kbd>grep</kbd> to report files with images:</p>
<pre>
$ <strong>find /smbMount -iname '*.docx' -print0 | xargs -0 grep -L image</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>The previous examples showed how to use <kbd>xargs</kbd> to organize a set of data. The next examples show how to format sets of data on a command line.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Passing formatted arguments to a command by reading stdin</h1>
            </header>

            <article>
                
<p>Here is a small <kbd>echo</kbd> script to make it obvious as to how <kbd>xargs</kbd> provides command arguments:</p>
<pre>
#!/bin/bash 
#Filename: cecho.sh 

echo $*'#'  
</pre>
<p>When arguments are passed to the <kbd>cecho.sh</kbd> shell, it will print the arguments terminated by the <kbd>#</kbd> character. Consider this example:</p>
<pre>
    <strong>$ ./cecho.sh arg1 arg2</strong>
<strong>    arg1 arg2 #</strong>
</pre>
<p>Here's a common problem:</p>
<ul>
<li>I have a list of elements in a file (one per line) to be provided to a command (say, <kbd>cecho.sh</kbd>). I need to apply the arguments in several styles. In the first method, I need one argument for each invocation, like this:</li>
</ul>
<pre>
<strong>        ./cecho.sh arg1 </strong>
<strong>        ./cecho.sh arg2 </strong>
<strong>        ./cecho.sh arg3</strong> 
</pre>
<ul>
<li>Next, I need to provide one or two arguments each for each execution of the command, like this:</li>
</ul>
<pre>
<strong>        ./cecho.sh arg1 arg2 </strong>
<strong>        ./cecho.sh arg3</strong> 
</pre>
<ul>
<li>Finally, I need to provide all arguments at once to the command:</li>
</ul>
<pre>
<strong>        ./cecho.sh arg1 arg2 arg3</strong> 
</pre>
<p>Run the <kbd>cecho.sh</kbd> script and note the output before going through the following section. The <kbd>xargs</kbd> command can format the arguments for each of these requirements. The list of arguments is in a file called <kbd>args.txt</kbd>:</p>
<pre>
<strong>$ cat args.txt</strong>
<strong>arg1</strong>
<strong>arg2</strong>
<strong>arg3</strong>
</pre>
<p>For the first form, we execute the command multiple times with one argument per execution. The <kbd>xargs -n</kbd> option can limit the number of command line arguments to one:</p>
<pre>
<strong>$ cat args.txt | xargs -n 1 ./cecho.sh</strong>
<strong>arg1 #</strong>
<strong>arg2 #</strong>
<strong>arg3 #</strong>
</pre>
<p>To limit the number of arguments to two or fewer, execute this:</p>
<pre>
<strong>$ cat args.txt | xargs -n 2 ./cecho.sh </strong>
<strong>arg1 arg2 #</strong>
<strong>arg3 #</strong>
</pre>
<p>Finally, to execute the command at once with all the arguments, do not use any <kbd>-n</kbd> argument:</p>
<pre>
<strong>$ cat args.txt | xargs ./cecho.sh</strong>
<strong>arg1 arg2 arg3 #</strong>
</pre>
<p>In the preceding examples, the arguments added by <kbd>xargs</kbd> were placed at the end of the command. However, we may need to have a constant phrase at the end of the command and want <kbd>xargs</kbd> to substitute its argument in the middle, like this:</p>
<pre>
<strong>./cecho.sh -p arg1 -l</strong>
</pre>
<p>In the preceding command execution, <kbd>arg1</kbd> is the only variable text. All others should remain constant. The arguments from <kbd>args.txt</kbd> should be applied like this:</p>
<pre>
<strong>./cecho.sh -p arg1 -l</strong>
<strong>./cecho.sh -p arg2 -l</strong>
<strong>./cecho.sh -p arg3 -l</strong>
</pre>
<p>The <kbd>xargs-I</kbd> option specifies a replacement string to be replaced with the arguments xargs parses from the input. When <kbd>-I</kbd> is used with <kbd>xargs</kbd>, it will execute as one command execution per argument. This example solves the problem:</p>
<pre>
<strong>$ cat args.txt | xargs -I {} ./cecho.sh -p {} -l</strong>
<strong>-p arg1 -l #</strong>
<strong>-p arg2 -l #</strong>
<strong>-p arg3 -l #</strong>
</pre>
<p>The <kbd>-I {}</kbd> specifies the replacement string. For each of the arguments supplied for the command, the <kbd>{}</kbd> string will be replaced with arguments read through <kbd>stdin</kbd>.</p>
<div class="packt_infobox">When used with <kbd>-I</kbd>, the command is executed in a loop. When there are three arguments, the command is executed three times along with the <kbd>{}</kbd> command. Each time, <kbd>{}</kbd> is replaced with arguments one by one.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Using xargs with find</h1>
            </header>

            <article>
                
<p>The <kbd>xargs</kbd> and <kbd>find</kbd> command can be combined to perform tasks. However, take care to combine them carefully. Consider this example:</p>
<pre>
<strong>$ find . -type f -name "*.txt"  -print | xargs rm -f </strong>
</pre>
<p>This is dangerous. It may cause removal of unexpected files. We cannot predict the delimiting character (whether it is <kbd>'\n'</kbd> or <kbd>' '</kbd>) for the output of the <kbd>find</kbd> command. If any filenames contain a space character (<kbd>' '</kbd>) <kbd>xargs</kbd> may misinterpret it as a delimiter. For example, <kbd>bashrc text.txt</kbd> would be misinterpreted by <kbd>xargs</kbd> as <kbd>bashrc</kbd> and <kbd>text.txt</kbd>. The previous command would not delete <kbd>bashrc text.txt</kbd>, but would delete <kbd>bashrc</kbd>.</p>
<p>Use the <kbd>-print0</kbd> option of <kbd>find</kbd> to produce an output delimited by the null character (<kbd>'\0'</kbd>); you use <kbd>find</kbd> output as <kbd>xargs</kbd> input.</p>
<p>This command will <kbd>find</kbd> and remove all <kbd>.txt</kbd> files and nothing else:</p>
<pre>
<strong>$ find . -type f -name "*.txt" -print0 | xargs -0 rm -f</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Counting the number of lines of C code in a source code directory</h1>
            </header>

            <article>
                
<p>At some point, most programmers need to count the <strong>Lines of Code</strong> (<strong>LOC</strong>) in their C program files The code for this task is as follows:</p>
<pre>
<strong>$ find source_code_dir_path -type f -name "*.c" -print0 | xargs -0 wc -l</strong> 
</pre>
<div class="packt_infobox">If you want more statistics about your source code, a utility called <kbd>SLOCCount</kbd>, is very useful. Modern GNU/Linux distributions usually have packages or you can get it from <a href="http://www.dwheeler.com/sloccount/" target="_blank"><span class="URLPACKT">http://www.dwheeler.com/sloccount/</span></a>.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">While and subshell trick with stdin</h1>
            </header>

            <article>
                
<p>The <kbd>xargs</kbd> command places arguments at the end of a command; thus, <kbd>xargs</kbd> cannot supply arguments to multiple sets of commands. We can create a subshell to handle complex situations. The subshell can use a <kbd>while</kbd> loop to read arguments and execute commands in a trickier way, like this:</p>
<pre>
<strong>$ cat files.txt  | ( while read arg; do cat $arg; done )</strong>
<strong># Equivalent to cat files.txt | xargs -I {} cat {}</strong>
</pre>
<p>Here, by replacing <kbd>cat $arg</kbd> with any number of commands using a <kbd>while</kbd> loop, we can perform many command actions with the same arguments. We can pass the output to other commands without using pipes. Subshell <kbd>( )</kbd> tricks can be used in a variety of problematic environments. When enclosed within subshell operators, it acts as a single unit with multiple commands inside, like so:</p>
<pre>
<strong>$ cmd0 | ( cmd1;cmd2;cmd3) | cmd4</strong>
</pre>
<p>If <kbd>cmd1</kbd> is <kbd>cd /</kbd> within the subshell, the path of the working directory changes. However, this change resides inside the subshell only. The <kbd>cmd4</kbd> command will not see the directory change.</p>
<p>The shell accepts a <kbd>-c</kbd> option to invoke a subshell with a command-line script. This can be combined with <kbd>xargs</kbd> to solve the problem of needing multiple substitutions. The following example finds all <kbd>C</kbd> files and echoes the name of each file, preceded by a newline (the <kbd>-e</kbd> option enables backslash substitutions). Immediately after the filename is a list of all the times <kbd>main</kbd> appears in that file:</p>
<pre>
<strong>find . -name '*.c' | xargs -I ^ sh -c "echo -ne '\n ^: '; grep main ^"</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Translating with tr</h1>
            </header>

            <article>
                
<p>The <kbd>tr</kbd> command is a versatile tool in the Unix command–warrior's kit. It is used to craft elegant one-liner commands. It performs substitution of characters, deletes selected characters, and can squeeze repeated characters from the standard input. Tr is short for <strong>translate</strong>, since it translates a set of characters to another set. In this recipe, we will see how to use <kbd>tr</kbd> to perform basic translation between sets.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>tr</kbd> command accepts input through <strong>stdin</strong> (<strong>standard input</strong>) and cannot accept input through command-line arguments. It has this invocation format:</p>
<pre>
<strong>tr [options] set1 set2</strong>
</pre>
<p>Input characters from <kbd>stdin</kbd> are mapped from the first character in <kbd>set1</kbd> to the first character in <kbd>set2</kbd>, and so on and the output is written to <kbd>stdout</kbd> (standard output). <kbd>set1</kbd> and <kbd>set2</kbd> are character classes or a set of characters. If the length of sets is unequal, <kbd>set2</kbd> is extended to the length of <kbd>set1</kbd> by repeating the last character; otherwise if the length of <kbd>set2</kbd> is greater than that of <kbd>set1</kbd>, all the characters exceeding the length of <kbd>set1</kbd> are ignored from <kbd>set2</kbd>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>To perform translation of characters in the input from uppercase to lowercase, use this command:</p>
<pre>
<strong>$ echo "HELLO WHO IS THIS" | tr 'A-Z' 'a-z'</strong>
<strong>hello who is this</strong>
</pre>
<p>The <kbd>'A-Z'</kbd> and <kbd>'a-z'</kbd> are the sets. We can specify custom sets as needed by appending characters or character classes.</p>
<p>The <kbd>'ABD-}'</kbd>, <kbd>'aA.,'</kbd>, <kbd>'a-ce-x'</kbd>, <kbd>'a-c0-9'</kbd>, and so on are valid sets. We can define sets easily. Instead of writing continuous character sequences, we can use the <kbd>'startchar-endchar'</kbd> format. It can also be combined with any other characters or character classes. If <kbd>startchar-endchar</kbd> is not a valid continuous character sequence, they are then taken as a set of three characters (for example, <kbd>startchar</kbd>, <kbd>-</kbd>, and <kbd>endchar</kbd>). You can also use special characters such as <kbd>'\t'</kbd>, <kbd>'\n'</kbd>, or any ASCII characters.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Using <kbd>tr</kbd> with the concept of sets, we can map characters from one set to another set easily. Let's go through an example on using <kbd>tr</kbd> to encrypt and decrypt numeric characters:</p>
<pre>
<strong>$ echo 12345 | tr '0-9' '9876543210'</strong>
<strong>87654 #Encrypted</strong>

<strong>$ echo 87654 | tr '9876543210' '0-9'</strong>
<strong>12345 #Decrypted</strong>
</pre>
<p>The <kbd>tr</kbd> command can be used to encrypt text. <strong>ROT13</strong> is a well-known encryption algorithm. In the ROT13 scheme, characters are shifted by 13 positions, thus the same function can encrypt and decrypt text:</p>
<pre>
<strong>$ echo "tr came, tr saw, tr conquered." | tr 'a-zA-Z' 'n-za-mN-ZA-M'</strong>
</pre>
<p>The output will be the following:</p>
<pre>
<strong>ge pnzr, ge fnj, ge pbadhrerq.</strong>
</pre>
<p>By sending the encrypted text again to the same ROT13 function, we get this:</p>
<pre>
<strong>$ echo ge pnzr, ge fnj, ge pbadhrerq. | tr 'a-zA-Z' 'n-za-mN-ZA-M'</strong>
</pre>
<p>The output will be the following:</p>
<pre>
<strong>tr came, tr saw, tr conquered.</strong>
</pre>
<p>The <kbd>tr</kbd> can convert each tab character to a single space, as follows:</p>
<pre>
<strong>$ tr '\t' ' ' &lt; file.txt</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>We saw some basic translations using the <kbd>tr</kbd> command. Let's see what else can <kbd>tr</kbd> help us achieve.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Deleting characters using tr</h1>
            </header>

            <article>
                
<p>The <kbd>tr</kbd> command has an option <kbd>-d</kbd> to delete a set of characters that appear on <kbd>stdin</kbd> using the specified set of characters to be deleted, as follows:</p>
<pre>
<strong>$ cat file.txt | tr -d  '[set1]'</strong>
<strong>#Only set1 is used, not set2</strong>
</pre>
<p>Consider this example:</p>
<pre>
<strong>$ echo "Hello 123 world 456" | tr -d '0-9'</strong>
<strong>Hello world</strong>
<strong># Removes the numbers from stdin and print</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Complementing character sets</h1>
            </header>

            <article>
                
<p>We can use a set to complement <kbd>set1</kbd> using the <kbd>-c</kbd> flag. <kbd>set2</kbd> is optional in the following command:</p>
<pre>
<strong>tr -c [set1] [set2]</strong>
</pre>
<p>If only <kbd>set1</kbd> is present, <kbd>tr</kbd> will delete all characters that are not in <kbd>set1</kbd>. If <kbd>set2</kbd> is also present, <kbd>tr</kbd> will translate characters that aren't in <kbd>set1</kbd> into values from <kbd>set2</kbd>. If you use the <kbd>-c</kbd> option by itself, you must use <kbd>set1</kbd> and <kbd>set2</kbd>. If you combine the <kbd>-c</kbd> and <kbd>-d</kbd> options, you only use <kbd>set1</kbd> and all other characters will be deleted.</p>
<p>The following example deletes all the characters from the input text, except the ones specified in the complement set:</p>
<pre>
<strong>$ echo hello 1 char 2 next 4 | tr -d -c '0-9 \n'</strong>
<strong>124</strong>
</pre>
<p>This example replaces all characters that aren't in <kbd>set1</kbd> with spaces:</p>
<pre>
<strong>$ echo hello 1 char 2 next 4 | tr -c '0-9' ' '</strong>
<strong>      1      2     4</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Squeezing characters with tr</h1>
            </header>

            <article>
                
<p>The <kbd>tr</kbd> command can perform many text-processing tasks. For example, it can remove multiple occurrences of a character in a string. The basic form for this is as follows:</p>
<pre>
<strong>tr -s '[set of characters to be squeezed]' </strong>
</pre>
<p>If you commonly put two spaces after a period, you'll need to remove extra spaces without removing duplicated letters:</p>
<pre>
<strong>$ echo "GNU is       not     UNIX.  Recursive   right ?" | tr -s ' '</strong>
<strong>GNU is not UNIX. Recursive right ?</strong>
</pre>
<p>The <kbd>tr</kbd> command can also be used to get rid of extra newlines:</p>
<pre>
<strong>$ cat multi_blanks.txt | tr -s '\n'</strong>
<strong>line 1</strong>
<strong>line 2</strong>
<strong>line 3</strong>
<strong>line 4</strong>
</pre>
<p>In the preceding usage of <kbd>tr</kbd>, it removes the extra <kbd>'\n'</kbd> characters. Let's use <kbd>tr</kbd> in a tricky way to add a given list of numbers from a file, as follows:</p>
<pre>
<strong>$ cat sum.txt</strong>
<strong>1</strong>
<strong>2</strong>
<strong>3</strong>
<strong>4</strong>
<strong>5</strong>

<strong>$ cat sum.txt | echo $[ $(tr '\n' '+' ) 0 ]</strong>
<strong>15</strong>
</pre>
<p>How does this hack work?</p>
<p>Here, the <kbd>tr</kbd> command replaces <kbd>'\n'</kbd> with the <kbd>'+'</kbd> character, hence, we form the string <kbd>1+2+3+..5+</kbd><kbd>,</kbd> but at the end of the string we have an extra <kbd>+</kbd> operator. In order to nullify the effect of the <kbd>+</kbd> operator, <kbd>0</kbd> is appended.</p>
<p>The <kbd>$[ operation ]</kbd> performs a numeric operation. Hence, it forms this string:</p>
<pre>
<strong>echo $[ 1+2+3+4+5+0 ]</strong>
</pre>
<p>If we used a loop to perform the addition by reading numbers from a file, it would take a few lines of code. With <kbd>tr</kbd>, a one–liner does the trick.</p>
<p>Even trickier is when we have a file with letters and numbers and we want to sum the numbers:</p>
<pre>
<strong>$ cat test.txt</strong>
<strong>first 1</strong>
<strong>second 2</strong>
<strong>third 3</strong>
</pre>
<p>We can use <kbd>tr</kbd> to strip out the letters with the <kbd>-d</kbd> option, then replace the spaces with <kbd>+</kbd>:</p>
<pre>
<strong>$ cat test.txt | tr -d [a-z] | echo "total: $[$(tr ' ' '+')]"</strong>
<strong>total: 6</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Character classes</h1>
            </header>

            <article>
                
<p>The <kbd>tr</kbd> command can use different character classes as sets. Here are the supported character classes:</p>
<ul>
<li><kbd>alnum</kbd>: Alphanumeric characters</li>
<li><kbd>alpha</kbd>: Alphabetic characters</li>
<li><kbd>cntrl</kbd>: Control (nonprinting) characters</li>
<li><kbd>digit</kbd>: Numeric characters</li>
<li><kbd>graph</kbd>: Graphic characters</li>
<li><kbd>lower</kbd>: Lowercase alphabetic characters</li>
<li><kbd>print</kbd>: Printable characters</li>
<li><kbd>punct</kbd>: Punctuation characters</li>
<li><kbd>space</kbd>: Whitespace characters</li>
<li><kbd>upper</kbd>: Uppercase characters</li>
<li><kbd>xdigit</kbd>: Hexadecimal characters</li>
</ul>
<p>We can select the required classes, like this:</p>
<pre>
<strong>tr [:class:] [:class:]</strong>
</pre>
<p>Consider this example:</p>
<pre>
<strong>tr '[:lower:]' '[:upper:]'</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Checksum and verification</h1>
            </header>

            <article>
                
<p>Checksum programs are used to generate a relatively small unique key from files. We can recalculate the key to confirm that a file has not changed. Files may be modified deliberately (adding a new user changes the password file), accidentally (a data read error from a CD-ROM drive), or maliciously (a virus is inserted). Checksums let us verify that a file contains the data we expect it to.</p>
<p>Checksums are used by backup applications to check whether a file has been modified and needs to be backed up.</p>
<p>Most software distributions also have a checksum file available. Even robust protocols such as TCP can allow a file to be modified in transit. Hence, we need to know whether the received file is the original one or not by applying some kind of test.</p>
<p>By comparing the checksum of the file we downloaded with the checksum calculated by the distributer, we can verify that the received file is correct. If the checksum calculated from the original file at the source location matches the one calculated at the destination, the file has been received successfully.</p>
<p>Some system validation suites maintain a checksum of the critical files. If malware modifies a file, we can detect this from the changed checksum.</p>
<p>In this recipe, we will see how to compute checksums to verify the integrity of data.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>Unix and Linux support several checksum programs, but the most robust and widely used algorithms are <strong>MD5</strong> and <strong>SHA-1</strong>. The <strong>ms5sum</strong> and <strong>sha1sum</strong> programs generate checksum strings by applying the corresponding algorithm to the data. Let's see how to generate a checksum from a file and verify the integrity of that file.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>To compute the md5sum, use the following command:</p>
<pre>
<strong>$ md5sum filename</strong>
<strong>68b329da9893e34099c7d8ad5cb9c940 filename</strong>
</pre>
<p>The <kbd>md5sum</kbd> is a 32-character hexadecimal string as given.</p>
<p>We can redirect the checksum output to a file for later use, as follows:</p>
<pre>
<strong>$ md5sum filename &gt; file_sum.md5</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>The syntax for the <kbd>md5sum</kbd> checksum calculation is as follows:</p>
<pre>
<strong>$ md5sum file1 file2 file3 ..</strong>
</pre>
<p>When multiple files are used, the output will contain a checksum for each of the files, one checksum report per line:</p>
<pre>
<strong>[checksum1]   file1</strong>
<strong>[checksum1]   file2</strong>
<strong>[checksum1]   file3</strong>
</pre>
<p>The integrity of a file can be verified with the generated file, like this:</p>
<pre>
<strong>$ md5sum -c file_sum.md5</strong>
<strong># It will output a message whether checksum matches or not</strong>
</pre>
<p>If we need to check all the files using all <kbd>.md5</kbd> information available, use this:</p>
<pre>
<strong>$ md5sum -c *.md5</strong>
</pre>
<p>SHA-1 is another commonly used checksum algorithm. It generates a 40-character hex code from the input. The <kbd>sha1sum</kbd> command calculates an SHA-1 <kbd>checksum</kbd>. Its usage is similar to <kbd>md5sum</kbd>. Simply replace <kbd>md5sum</kbd> with <kbd>sha1sum</kbd> in all the commands previously mentioned. Instead of <kbd>file_sum.md5</kbd>, change the output filename to <kbd>file_sum.sha1</kbd>.</p>
<p>Checksums are useful to verify the integrity of files downloaded from the Internet. ISO images are susceptible to erroneous bits. A few wrong bits and the ISO may be unreadable, or, worse, it might install applications that fail in strange ways. Most file repositories include an <kbd>md5</kbd> or <kbd>sha1</kbd> file you can use to verify that files were downloaded correctly.</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/B05265_02_01_New.png"/></div>
<p>This is the MD5 sum checksum that is created:</p>
<pre>
<strong>3f50877c05121f7fd8544bef2d722824 *ubuntu-16.10-desktop-amd64.iso</strong>
<strong>e9e9a6c6b3c8c265788f4e726af25994 *ubuntu-16.10-desktop-i386.iso</strong>
<strong>7d6de832aee348bacc894f0a2ab1170d *ubuntu-16.10-server-amd64.iso</strong>
<strong>e532cfbc738876b353c7c9943d872606 *ubuntu-16.10-server-i386.iso</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>Checksums are also useful when used with a number of files. Let's see how to apply checksums to a collection of files and verify the accuracy.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Checksum for directories</h1>
            </header>

            <article>
                
<p>Checksums are calculated for files. Calculating the checksum for a directory requires recursively calculating the checksums for all the files in the directory.</p>
<p>The <kbd>md5deep</kbd> or <kbd>sha1deep</kbd> commands traverse a file tree and calculate checksums for all files. These programs may not be installed on your system. Use <kbd>apt-get</kbd> or <kbd>yum</kbd> to install the <kbd>md5deep</kbd> package. An example of this command is as follows:</p>
<pre>
<strong>$ md5deep -rl directory_path &gt; directory.md5</strong>
</pre>
<p>The <kbd>-r</kbd> option allows md5deep to recurse into sub-directories. The <kbd>-l</kbd> option enables displaying the relative path, instead of the default absolute path.</p>
<pre>
<strong># <kbd>-r</kbd> to enable recursive traversal</strong>
<strong># <kbd>-l</kbd> to use relative path. By default it writes absolute file
path in output</strong>
</pre>
<p>The <kbd>find</kbd> and <kbd>md5sum</kbd> commands can be used to calculate checksums recursively:</p>
<pre>
<strong>$ find directory_path -type f -print0 | xargs -0 md5sum &gt;&gt; directory.md5</strong>
</pre>
<p>To verify, use this command:</p>
<pre>
<strong>$ md5sum -c directory.md5</strong>
</pre>
<ul>
<li>The <strong>md5</strong> and <strong>SHA-1 checksums</strong> are unidirectional hash algorithms, which cannot be reversed to form the original data. These are also used to generate a unique key from a given data:</li>
</ul>
<pre>
        <strong>$ md5sum file</strong>
<strong>        8503063d5488c3080d4800ff50850dc9  file</strong>
<strong>        $ sha1sum file</strong>
<strong>        1ba02b66e2e557fede8f61b7df282cd0a27b816b  file</strong>
</pre>
<p style="padding-left: 60px"> These hashes are commonly used to store passwords. Only the hash for a    password is stored. When a user needs to be authenticated, the password is read  and converted to the hash and that hash is compared to the stored hash. If they  are the same, the password is authenticated and access is provided. Storing  plain–text password strings is risky and poses a security risk.</p>
<div class="packt_infobox">Although commonly used, md5sum and SHA-1 are no longer considered secure. This is because the rise in computing power in recent times that makes it easier to crack them. It is recommended that you use tools such as <kbd>bcrypt</kbd> or <strong>sha512sum</strong> instead. Read more about this at <a href="http://codahale.com/how-to-safely-store-a-password/" target="_blank"><span class="URLPACKT">http://codahale.com/how-to-safely-store-a-password/</span></a>.</div>
<ul>
<li>Shadow-like hash (salted hash)</li>
</ul>
<p style="padding-left: 60px">  The next recipe shows how to generate a shadow-like salted hash for passwords.   The hash for user passwords in Linux is stored in the <kbd>/etc/shadow</kbd> file. A            typical line in <kbd>/etc/shadow</kbd> will look like this:</p>
<pre style="padding-left: 60px">
<strong>                    test:$6$fG4eWdUi$ohTKOlEUzNk77.4S8MrYe07NTRV4M3LrJnZP9p.qc1bR5c.
EcOruzPXfEu1uloBFUa18ENRH7F70zhodas3cR.:14790:0:99999:7:::</strong> 
</pre>
<p style="padding-left: 60px"><kbd>$6$fG4eWdUi$ohTKOlEUzNk77.4S8MrYe07NTRV4M3LrJnZP9p.qc1bR5c.EcOruzPXfEu1uloBFUa18ENRH7F70zhodas3cR</kbd> is the hash corresponding to its password.</p>
<p style="padding-left: 60px">In some situations, we need to write scripts to edit passwords or add users. In that case, we must generate a shadow password string and write a similar line to the preceding one to the shadow file. We can generate a shadow password using <kbd>openssl</kbd>.</p>
<p style="padding-left: 60px">Shadow passwords are usually salted passwords. <kbd>SALT</kbd> is an extra string used to obfuscate and make the encryption stronger. Salt consists of random bits that are used as one of the inputs to a key derivation function that generates the salted hash for the password.</p>
<div class="packt_infobox">For more details on salt, refer to this Wikipedia page at <span class="URLPACKT"><a href="http://en.wikipedia.org/wiki/Salt_(cryptography)" target="_blank">h t t p ://e n . w i k i p e d i a . o r g /w i k i /S a l t _ (c r y p t o g r a p h y )</a>.</span></div>
<pre style="padding-left: 60px">
<strong>$ opensslpasswd -1 -salt SALT_STRING PASSWORD</strong>
<strong>$1$SALT_STRING$323VkWkSLHuhbt1zkSsUG.</strong>
</pre>
<p style="padding-left: 60px">Replace <kbd>SALT_STRING</kbd> with a random string and <kbd>PASSWORD</kbd> with the password you want to use.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Cryptographic tools and hashes</h1>
            </header>

            <article>
                
<p>Encryption techniques are used to protect data from unauthorized access. Unlike the checksum algorithms we just discussed, encryption programs can reconstruct the original data with no loss. There are many algorithms available and we will discuss those most commonly used in the Linux/Unix world.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>Let's see how to use tools such as <kbd>crypt</kbd>, <kbd>gpg</kbd>, and <kbd>base64</kbd>:</p>
<ul>
<li>The <kbd>crypt</kbd> command is not commonly installed on Linux systems. It's a simple and relatively insecure cryptographic utility that accepts input from <kbd>stdin</kbd>, requests a <kbd>passphrase</kbd>, and sends encrypted output to <kbd>stdout</kbd>:</li>
</ul>
<pre>
        <strong>$ crypt &lt;input_file &gt;output_file</strong>
<strong>        Enter passphrase:</strong>
</pre>
<p style="padding-left: 60px">We can provide a passphrase on the command line:</p>
<pre>
        <strong>$ crypt PASSPHRASE &lt;input_file &gt;encrypted_file</strong>
</pre>
<p style="padding-left: 60px">In order to decrypt the file, use this:</p>
<pre>
        <strong>$ crypt PASSPHRASE -d &lt;encrypted_file &gt;output_file</strong>
</pre>
<ul>
<li><kbd>gpg</kbd> (GNU privacy guard) is a widely used tool for protecting files to ensure that data is not read until it reaches its intended destination.</li>
</ul>
<div class="packt_infobox"><kbd>gpg</kbd> signatures are also widely used in e-mail communications to "sign" e-mail messages, proving the authenticity of the sender.</div>
<p style="padding-left: 90px">In order to encrypt a file with <kbd>gpg</kbd>, use this:</p>
<pre>
          <strong>$ gpg -c filename</strong>
</pre>
<p style="padding-left: 90px"> This command reads the passphrase interactively and generates <kbd>filename.gpg</kbd>. In order to decrypt a <kbd>gpg</kbd> file, use the following command:</p>
<pre>
          <strong>$ gpg filename.gpg</strong>
</pre>
<p style="padding-left: 90px">This command reads a passphrase and decrypts the file.</p>
<div class="packt_infobox">We are not covering <kbd>gpg</kbd> in much detail in this book. For more information, refer to <a href="http://en.wikipedia.org/wiki/GNU_Privacy_Guard" target="_blank"><span class="URLPACKT">http://en.wikipedia.org/wiki/GNU_Privacy_Guard</span></a>.</div>
<ul>
<li><strong>Base64</strong> is a group of similar encoding schemes that represent binary data in an ASCII string format by translating it into a <strong>radix-64</strong> representation. These programs are used to transmit binary data via e-mail. The <kbd>base64</kbd> command encodes and decodes the Base64 string. To encode a binary file into the Base64 format, use this:</li>
</ul>
<pre>
        <strong>$ base64 filename &gt; outputfile</strong>
</pre>
<p style="padding-left: 60px"> Alternatively, use this command:</p>
<pre>
        <strong>$ cat file | base64 &gt; outputfile</strong>
</pre>
<p style="padding-left: 60px"> It can read from <kbd>stdin</kbd>.</p>
<p style="padding-left: 60px"> Decode Base64 data as follows:</p>
<pre>
        <strong>$ base64 -d file &gt; outputfile</strong>
</pre>
<p style="padding-left: 60px">Alternatively, use this:</p>
<pre>
        <strong>$ cat base64_file | base64 -d &gt; outputfile</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Sorting unique and duplicate lines</h1>
            </header>

            <article>
                
<p>Sorting text files is a common task. The <kbd>sort</kbd> command sorts text files and <kbd>stdin</kbd>. It can be coupled with other commands to produce the required output. <kbd>uniq</kbd> is often used with <kbd>sort</kbd> to extract unique (or duplicate) lines. The following recipes illustrate some sort and <kbd>uniq</kbd> use cases.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>sort</kbd> and <kbd>uniq</kbd> commands accept input as filenames or from <kbd>stdin</kbd> (standard input) and output the result by writing to <kbd>stdout</kbd>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<ol>
<li>We can sort a set of files (for example, <kbd>file1.txt</kbd> and <kbd>file2.txt</kbd>), like this:</li>
</ol>
<pre>
        <strong>$ sort file1.txt file2.txt &gt; sorted.txt</strong>
</pre>
<p style="padding-left: 60px"> Alternatively, use this:</p>
<pre>
        <strong>$ sort file1.txt file2.txt -o sorted.txt</strong>
</pre>
<ol start="2">
<li>For a numerical sort, we use this:</li>
</ol>
<pre>
        <strong>$ sort -n file.txt</strong>
</pre>
<ol start="3">
<li>To sort in the reverse order, we use the following command:</li>
</ol>
<pre>
        <strong>$ sort -r file.txt</strong>
</pre>
<ol start="4">
<li>To sort by months (in the order Jan, Feb, March,...), use this:</li>
</ol>
<pre>
        <strong>$ sort -M months.txt</strong>
</pre>
<ol start="5">
<li>To merge two already sorted files, use this command:</li>
</ol>
<pre>
        <strong>$ sort -m sorted1 sorted2</strong>
</pre>
<ol start="6">
<li>To find the unique lines from a sorted file, use this:</li>
</ol>
<pre>
        <strong>$ sort file1.txt file2.txt | uniq</strong>
</pre>
<ol start="7">
<li>To check whether a file has already been sorted, use the following code:</li>
</ol>
<pre>
        #!/bin/bash 
        #Desc: Sort 
        sort -C filename ; 
        if [ $? -eq 0 ]; then 
           echo Sorted; 
        else 
           echo Unsorted; 
        fi 
</pre>
<p style="padding-left: 60px">Replace <kbd>filename</kbd> with the file you want to check and run the script.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>As shown in the examples, <kbd>sort</kbd> accepts numerous parameters to define how the data is to be sorted. The sort command is useful with the <kbd>uniq</kbd> command, which expects sorted input.</p>
<p>There are numerous scenarios where the <kbd>sort</kbd> and <kbd>uniq</kbd> commands can be used. Let's go through the various options and usage techniques.</p>
<p>To check whether a file is already sorted, we exploit the fact that <kbd>sort</kbd> returns an exit code (<kbd>$?</kbd>) of 0 if the file is sorted and nonzero otherwise.</p>
<pre>
<strong>if sort -c fileToCheck ; then echo sorted ; else echo unsorted ; fi</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>These were some basic usages of the <kbd>sort</kbd> command. Here are sections for using it to accomplish complex tasks:</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Sorting according to keys or columns</h1>
            </header>

            <article>
                
<p>We can use a column with sort if the input data is formatted like this:</p>
<pre>
<strong>$ cat data.txt</strong>
<strong>1  mac    2000</strong>
<strong>2  winxp    4000</strong>
<strong>3  bsd    1000</strong>
<strong>4  linux    1000</strong>
</pre>
<p>We can sort this in many ways; currently it is sorted numerically, by the serial number (the first column). We can also sort by the second or third column.</p>
<p>The <kbd>-k</kbd> option specifies the characters to sort by. A single digit specifies the column. The <kbd>-r</kbd> option specifies sorting in reverse order. Consider this example:</p>
<pre>
<strong># Sort reverse by column1</strong>
<strong>$ sort -nrk 1  data.txt</strong>
<strong>4  linux    1000 </strong>
<strong>3  bsd    1000 </strong>
<strong>2  winxp    4000 </strong>
<strong>1  mac    2000 </strong>
<strong># -nr means numeric and reverse</strong>

<strong># Sort by column 2</strong>
<strong>$ sort -k 2  data.txt</strong>
<strong>3  bsd    1000 </strong>
<strong>4  linux    1000 </strong>
<strong>1  mac    2000 </strong>
<strong>2  winxp    4000</strong>
</pre>
<div class="packt_infobox">Always be careful about the -n option for numeric sort. The sort command treats alphabetical sort and numeric sort differently. Hence, in order to specify numeric sort, the <kbd>-n</kbd> option should be provided.</div>
<p>When <kbd>-k</kbd> is followed by a single integer, it specifies a column in the text file. Columns are separated by space characters. If we need to specify keys as a group of characters (for example, characters 4-5 of column 2), we define the range as two integers separated by a period to define a character position, and join the first and last character positions with a comma:</p>
<pre>
<strong>$ cat data.txt</strong>


<strong>1 alpha 300</strong>
<strong>2 beta 200</strong>
<strong>3 gamma 100</strong>
<strong>$ sort -bk 2.3,2.4 data.txt   ;# Sort m, p, t</strong>
<strong>3 gamma 100</strong>
<strong>1 alpha 300</strong>
<strong>2 beta 200</strong>
</pre>
<p>The highlighted characters are to be used as numeric keys. To extract them, use their positions in the lines as the key format (in the previous example, they are <kbd>2</kbd> and <kbd>3</kbd>).</p>
<p>To use the first character as the key, use this:</p>
<pre>
<strong>$ sort -nk 1,1 data.txt</strong>
</pre>
<p>To make the sort's output <kbd>xargs</kbd> compatible with the <kbd>\0</kbd> terminator, use this command:</p>
<pre>
<strong>$ sort -z data.txt | xargs -0</strong>
<strong># Use zero terminator to make safe use with xargs</strong>
</pre>
<p>Sometimes, the text may contain unnecessary extraneous characters such as spaces. To sort them in dictionary order, ignoring punctuations and folds, use this:</p>
<pre>
<strong>$ sort -bd unsorted.txt</strong>
</pre>
<p>The <kbd>-b</kbd> option is used to ignore leading blank lines from the file and the <kbd>-d</kbd> option specifies sorting in dictionary order.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">uniq</h1>
            </header>

            <article>
                
<p>The <kbd>uniq</kbd> command finds the unique lines in a given input (<kbd>stdin</kbd> or a filename command line argument) and either reports or removes the duplicated lines.</p>
<p>This command only works with sorted data. Hence, <kbd>uniq</kbd> is often used with the <kbd>sort</kbd> command.</p>
<p>To produce the unique lines (all lines in the input are printed and duplicate lines are printed once), use this:</p>
<pre>
<strong>$ cat sorted.txt</strong>
<strong>bash </strong>
<strong>foss </strong>
<strong>hack </strong>
<strong>hack</strong>

<strong>$ uniq sorted.txt</strong>
<strong>bash </strong>
<strong>foss </strong>
<strong>hack </strong>
</pre>
<p>Alternatively, use this:</p>
<pre>
<strong>$ sort unsorted.txt | uniq</strong>
</pre>
<p>Display only unique lines (the lines that are not repeated or duplicated in the input file):</p>
<pre>
<strong>$ uniq -u sorted.txt</strong>
<strong>bash</strong>
<strong>foss</strong>
</pre>
<p>Alternatively, use this command:</p>
<pre>
<strong>$ sort unsorted.txt | uniq -u</strong>
</pre>
<p>To count how many times each of the lines appears in the file, use the following command:</p>
<pre>
<strong>$ sort unsorted.txt | uniq -c</strong>
<strong>  1 bash</strong>
<strong>  1 foss</strong>
<strong>  2 hack</strong>
</pre>
<p>To find duplicate lines in the file, use this:</p>
<pre>
<strong>$ sort unsorted.txt  | uniq -d</strong>
<strong>hack</strong>
</pre>
<p>To specify keys, we can use a combination of the <kbd>-s</kbd> and <kbd>-w</kbd> arguments:</p>
<ul>
<li><kbd>-s</kbd>: This specifies the number for the first <em>N</em> characters to be skipped</li>
<li><kbd>-w</kbd>: This specifies the maximum number of characters to be compared</li>
</ul>
<p>The following example describes using the comparison key as the index for the <kbd>uniq</kbd> operation:</p>
<pre>
<strong>$ cat data.txt</strong>
<strong>u:01:gnu </strong>
<strong>d:04:linux </strong>
<strong>u:01:bash </strong>
<strong>u:01:hack</strong>
</pre>
<p>To test only the bold characters (skip the first two characters and use the next two) we use <kbd>-s 2</kbd> to skip the first characters and <kbd>-w 2</kbd> to use the next two:</p>
<pre>
<strong>$ sort data.txt | uniq -s 2 -w 2</strong>
<strong>d:04:linux </strong>
<strong>u:01:bash </strong>
</pre>
<p>When the output from one command is passed as input to the <kbd>xargs</kbd> command, it's best to use a zero-byte terminator for each element of data. Passing output from <kbd>uniq</kbd> to <kbd>xargs</kbd> is no exception to this rule. If a zero-byte terminator is not used, the default space characters are used to split the arguments in the <kbd>xargs</kbd> command. For example, a line with the text <kbd>this is a line</kbd> from <kbd>stdin</kbd> will be taken as four separate arguments by the <kbd>xargs</kbd> command instead of a single line. When a zero-byte terminator, <kbd>\0</kbd>, is used as the delimiter character, the full line including spaces is interpreted as a single argument.</p>
<p>The <kbd>-z</kbd> option generates zero-byte-terminated output:</p>
<pre>
<strong>$ uniq -z file.txt</strong>
</pre>
<p>This command removes all the files, with filenames read from <kbd>files.txt</kbd>:</p>
<pre>
<strong>$ uniq -z file.txt | xargs -0 rm</strong>
</pre>
<p>If a filename appears multiple time, the <kbd>uniq</kbd> command writes the filename only once to <kbd>stdout</kbd>, thus avoiding a <kbd>rm: cannot remove FILENAME: No such file or directory</kbd> error.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Temporary file naming and random numbers</h1>
            </header>

            <article>
                
<p>Shell scripts often need to store temporary data. The most suitable location to do this is <kbd>/tmp</kbd> (which will be cleaned out by the system on reboot). There are two methods to generate standard filenames for temporary data.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The <kbd>mktemp</kbd> command will create a unique temporary file or folder name:</p>
<ol>
<li>Create a temporary file:</li>
</ol>
<pre>
        <strong>$ filename=`mktemp`</strong>
<strong>        $ echo $filename</strong>
<strong>        /tmp/tmp.8xvhkjF5fH</strong>
</pre>
<p style="padding-left: 60px">This creates a temporary file, stores the name in filename, and then displays the name.</p>
<ol start="2">
<li>Create a temporary directory:</li>
</ol>
<pre>
        <strong>$ dirname=`mktemp -d`</strong>
<strong>        $ echo $dirname</strong>
<strong>        tmp.NI8xzW7VRX</strong>
</pre>
<p style="padding-left: 60px">This creates a temporary directory, stores the name in filename, and displays the name.</p>
<div style="margin-left: 2em">
<ul>
<li>To generate a filename without creating a file or directory, use this:</li>
</ul>
</div>
<pre>
                <strong>$ tmpfile=`mktemp -u`</strong>
<strong>                $ echo $tmpfile</strong>
<strong>                /tmp/tmp.RsGmilRpcT</strong>
</pre>
<p style="padding-left: 120px">Here, the filename is stored in <kbd>$tmpfile</kbd>, but the file won't be created.</p>
<div style="margin-left: 2em">
<ul>
<li>To create the temporary filename based on a template, use this:</li>
</ul>
</div>
<pre>
                <strong>$mktemp test.XXX</strong>
<strong>                test.2tc</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>The <kbd>mktemp</kbd> command is straightforward. It generates a file with a unique name and returns its filename (or directory name, in the case of directories).</p>
<p>When providing custom templates, <kbd>X</kbd> will be replaced by a random alphanumeric character. Also note that there must be at least three <kbd>X</kbd> characters in the template for <kbd>mktemp</kbd> to work.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Splitting files and data</h1>
            </header>

            <article>
                
<p>Splitting a large file into smaller pieces is sometimes necessary. Long ago, we had to split files to transport large datasets on floppy disks. Today, we split files for readability, for generating logs, or for working around size-restrictions on e-mail attachments. These recipes will demonstrate ways of splitting files in different chunks.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The split command was created to split files. It accepts a filename as an argument and creates a set of smaller files in which the first part of the original file is in the alphabetically first new file, the next set in the alphabetically next file, and so on.</p>
<p>For example, a 100 KB file can be divided into smaller files of 10k each by specifying the split size. The split command supports <kbd>M</kbd> for MB, <kbd>G</kbd> for GB, <kbd>c</kbd> for byte, and <kbd>w</kbd> for word.</p>
<pre>
<strong>$ split -b 10k data.file</strong>
<strong>$ ls</strong>
<strong>data.file  xaa  xab  xac  xad  xae  xaf  xag  xah  xai  xaj</strong>
</pre>
<p>The preceding code will split <kbd>data.file</kbd> into ten files of <kbd>10k</kbd> each. The new files are named <kbd>xab</kbd>, <kbd>xac</kbd>, <kbd>xad</kbd>, and so on. By default, split uses alphabetic suffixes. To use numeric suffixes, use the <kbd>-d</kbd> argument. It is also possible to specify a suffix length using <kbd>-a</kbd> length:</p>
<pre>
<strong>$ split -b 10k data.file -d -a 4</strong>

<strong>$ ls</strong>
<strong>data.file x0009  x0019  x0029  x0039  x0049  x0059  x0069  x0079</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>The <kbd>split</kbd> command has more options. Let's go through them.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Specifying a filename prefix for the split files</h1>
            </header>

            <article>
                
<p>All the previous split filenames start with x. If we are splitting more than one file, we'll want to name the pieces, so it's obvious which goes with which. We can use our own filename prefix by providing a prefix as the last argument.</p>
<p>Let's run the previous command with the <kbd>split_file</kbd> prefix:</p>
<pre>
<strong>$ split -b 10k data.file -d -a 4 split_file</strong>
<strong>$ ls</strong>
<strong>data.file       split_file0002  split_file0005  split_file0008
strtok.c</strong>
<strong>split_file0000  split_file0003  split_file0006  split_file0009</strong>
<strong>split_file0001  split_file0004  split_file0007</strong>
</pre>
<p>To split files based on the number of lines in each split rather than chunk size, use this:</p>
<pre>
<strong>-l no_of_lines:</strong>
<strong> # Split into files of 10 lines each.</strong>
<strong> $ split -l 10 data.file </strong>
</pre>
<p>The <kbd>csplit</kbd> utility splits files based on context instead of size. It can split based on line count or regular expression pattern. It's particularly useful for splitting log files.</p>
<p>Look at the following example log:</p>
<pre>
<strong>$ cat server.log</strong>
<strong>SERVER-1 </strong>
<strong>[connection] 192.168.0.1 success </strong>
<strong>[connection] 192.168.0.2 failed </strong>
<strong>[disconnect] 192.168.0.3 pending </strong>
<strong>[connection] 192.168.0.4 success </strong>
<strong>SERVER-2 </strong>
<strong>[connection] 192.168.0.1 failed </strong>
<strong>[connection] 192.168.0.2 failed </strong>
<strong>[disconnect] 192.168.0.3 success </strong>
<strong>[connection] 192.168.0.4 failed </strong>
<strong>SERVER-3 </strong>
<strong>[connection] 192.168.0.1 pending </strong>
<strong>[connection] 192.168.0.2 pending </strong>
<strong>[disconnect] 192.168.0.3 pending </strong>
<strong>[connection] 192.168.0.4 failed</strong>
</pre>
<p>We may need to split the files into <kbd>server1.log</kbd>, <kbd>server2.log</kbd>, and <kbd>server3.log</kbd> from the contents for each <kbd>SERVER</kbd> in each file. This can be done as follows:</p>
<pre>
<strong>$ csplit server.log /SERVER/ -n 2 -s {*}  -f server -b "%02d.log"       $ rm server00.log </strong>
<strong>$ ls</strong>
<strong>server01.log  server02.log  server03.log  server.log</strong>
</pre>
<p>The details of the command are as follows:</p>
<ul>
<li><kbd>/SERVER/</kbd>: This is the line used to match a line by which a split is to be carried out.</li>
<li><kbd>/[REGEX]/</kbd>: This is the format. It copies from the current line (first line) up to the matching line that contains <kbd>SERVER</kbd> excluding the match line.</li>
<li><kbd>{*}</kbd>: This specifies repeating a split based on the match up to the end of the file. We can specify the number of times it is to be continued by placing a number between the curly braces.</li>
<li><kbd>-s</kbd>: This is the flag to make the command silent rather than printing other messages.</li>
<li><kbd>-n</kbd>: This specifies the number of digits to be used as suffix. <kbd>01</kbd>, <kbd>02</kbd>, <kbd>03</kbd>, and so on.</li>
<li><kbd>-f</kbd>: This specifies the filename prefix for split files (<kbd>server</kbd> is the prefix in the previous example).</li>
<li><kbd>-b</kbd>: This specifies the suffix format. <kbd>"%02d.log"</kbd> is similar to the <kbd>printf</kbd> argument format in C, Here, the <em>filename = prefix + suffix</em>, that is, <kbd>"server" + "%02d.log"</kbd>.</li>
</ul>
<p>We remove <kbd>server00.log</kbd> since the first split file is an empty file (the match word is the first line of the file).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Slicing filenames based on extensions</h1>
            </header>

            <article>
                
<p>Many shell scripts perform actions that involve modifying filenames. They may need to rename the files and preserve the extension, or convert files from one format to another and change the extension, while preserving the name, extracting a portion of the filename, and so on.</p>
<p>The shell has built-in features for manipulating filenames.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The <kbd>%</kbd> operator will extract the name from <kbd>name.extension</kbd>. This example extracts <kbd>sample</kbd> from <kbd>sample.jpg</kbd>:</p>
<pre>
file_jpg="sample.jpg" 
name=${file_jpg%.*} 
echo File name is: $name 
</pre>
<p>The output is this:</p>
<pre>
<strong>File name is: sample</strong>
</pre>
<p>The <kbd>#</kbd> operator will extract the extension:</p>
<p>Extract <kbd>.jpg</kbd> from the filename stored in the <kbd>file_jpg</kbd> variable:</p>
<pre>
extension=${file_jpg#*.} 
echo Extension is: jpg 
</pre>
<p>The output is as follows:</p>
<pre>
<strong>Extension is: jpg</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>To extract the name from the filename formatted as <kbd>name.extension</kbd>, we use the <kbd>%</kbd> operator.</p>
<p><kbd>${VAR%.*}</kbd> is interpreted as follows:</p>
<ul>
<li>Remove the string match from <kbd>$VAR</kbd> for the wildcard pattern that appears to the right of <kbd>%</kbd> (<kbd>.*</kbd> in the previous example). Evaluating from right to left finds the wildcard match.</li>
<li>Store the filename as <kbd>VAR=sample.jpg</kbd>. Therefore, the wildcard match for<kbd>.*</kbd> from right to left is <kbd>.jpg</kbd>. Thus, it is removed from the <kbd>$VAR</kbd> string and the output is <kbd>sample</kbd>.</li>
</ul>
<p><kbd>%</kbd> is a nongreedy operation. It finds the minimal match for the wildcard from right to left. The <kbd>%%</kbd> operator is similar to <kbd>%</kbd>, but it is greedy. This means that it finds the maximal match of the string for the wildcard. Consider this example, where we have this:</p>
<pre>
<strong>VAR=hack.fun.book.txt</strong>
</pre>
<p>Use the <kbd>%</kbd> operator for a nongreedy match from right to left and match <kbd>.txt</kbd>:</p>
<pre>
<strong>$ echo ${VAR%.*}</strong>
</pre>
<p>The output will be: <kbd>hack.fun.book</kbd>.</p>
<p>Use the <kbd>%%</kbd> operator for a greedy match, and match <kbd>.fun.book.txt</kbd>:</p>
<pre>
<strong>$ echo ${VAR%%.*}</strong>
</pre>
<p>The output will be: <kbd>hack</kbd>.</p>
<p>The <kbd>#</kbd> operator extracts the extension from the filename. It is similar to <kbd>%</kbd>, but it evaluates from left to right.</p>
<p><kbd>${VAR#*.}</kbd> is interpreted as follows:</p>
<ul>
<li>Remove the string match from <kbd>$VARIABLE</kbd> for the wildcard pattern match that appears to the right of <kbd>#</kbd> (<kbd>*.</kbd> in the previous example). Evaluating from the left to right should make the wildcard match.</li>
</ul>
<p>Similarly, as in the case of <kbd>%%</kbd>, the operator ## is a greedy equivalent to #.</p>
<p>It makes greedy matches by evaluating from left to right and removes the match string from the specified variable. Let's use this example:</p>
<pre>
<strong>VAR=hack.fun.book.txt</strong>
</pre>
<p>The <kbd>#</kbd> operator performs a nongreedy match from left to right and matches <kbd>hack</kbd>:</p>
<pre>
<strong>$ echo ${VAR#*.} </strong>
</pre>
<p>The output will be: <kbd>fun.book.txt</kbd>.</p>
<p>The <kbd>##</kbd> operator performs a greedy match from left to right and matches <kbd>hack.fun.book</kbd>:</p>
<pre>
<strong>$ echo ${VAR##*.}</strong>
</pre>
<p>The output will be: <kbd>txt</kbd>.</p>
<div class="packt_infobox">The <kbd>##</kbd> operator is preferred over the <kbd>#</kbd> operator to extract the extension from a filename, since the filename may contain multiple <kbd>.</kbd> characters. Since <kbd>##</kbd> makes a greedy match, it always extracts extensions only.</div>
<p>Here is a practical example to extract different portions of a domain name such as URL=<kbd>www.google.com</kbd>:</p>
<pre>
    
<strong>$ echo ${URL%.*} # Remove rightmost .*</strong>
<strong>www.google</strong>

<strong>$ echo ${URL%%.*} # Remove right to leftmost  .* (Greedy operator)</strong>
<strong>www</strong>


<strong>$ echo ${URL#*.} # Remove leftmost  part before *.</strong>
<strong>google.com</strong>


<strong>$ echo ${URL##*.} # Remove left to rightmost  part before *.
(Greedy operator) </strong><strong>com</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Renaming and moving files in bulk</h1>
            </header>

            <article>
                
<p>We frequently need to move and perhaps rename a set of files. System housekeeping often requires moving files with a common prefix or file type to a new folder. Images downloaded from a camera may need to be renamed and sorted. Music, video, and e-mail files all need to be reorganized eventually.</p>
<p>There are custom applications for many of these operations, but we can write our own custom scripts to do it <strong>our</strong> way.</p>
<p>Let's see how to write scripts to perform these kinds of operation.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>rename</kbd> command changes filenames using Perl regular expressions. By combining the <kbd>find</kbd>, <kbd>rename</kbd>, and <kbd>mv</kbd> commands, we can perform a lot of things.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The following script uses find to locate PNG and JPEG files, then uses the <kbd>##</kbd> operator and <kbd>mv</kbd> to rename them as <kbd>image-1.EXT</kbd>, <kbd>image-2.EXT</kbd>, and so on. This changes the file's name, but not its extension:</p>
<pre>
#!/bin/bash 
#Filename: rename.sh 
#Desc: Rename jpg and png files 

count=1; 
for img in `find . -iname '*.png' -o -iname '*.jpg' -type f -maxdepth 1` 
do 
  new=image-$count.${img##*.} 

  echo "Renaming $img to $new" 
  mv "$img" "$new" 
  let count++ 

done  
</pre>
<p>The output is as follows:</p>
<pre>
<strong>$ ./rename.sh</strong>
<strong>Renaming hack.jpg to image-1.jpg</strong>
<strong>Renaming new.jpg to image-2.jpg</strong>
<strong>Renaming next.png to image-3.png</strong>
</pre>
<p>The preceding script renames all the <kbd>.jpg</kbd> and <kbd>.png</kbd> files in the current directory to new filenames in the format <kbd>image-1.jpg</kbd>, <kbd>image-2.jpg</kbd>, <kbd>image-3.png</kbd>, <kbd>image-4.png</kbd>, and so on.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>The previous script uses a <kbd>for</kbd> loop to iterate through the names of all files ending with a <kbd>.jpg</kbd> or <kbd>.png</kbd> extension. The <kbd>find</kbd> command performs this search, using the <kbd>-o</kbd> option to specify multiple <kbd>-iname</kbd> options for case-insensitive matches. The <kbd>-maxdepth 1</kbd> option restricts the search to the current directory, not any subdirectories.</p>
<p>The <kbd>count</kbd> variable is initialized to <kbd>1</kbd> to track the image number. Then the script renames the file using the <kbd>mv</kbd> command. The new name of the file is constructed using <kbd>${img##*.}</kbd>, which parses the extension of the filename currently being processed (refer to the <em>Slicing filenames based on extensions</em> recipe in this chapter for an interpretation of <kbd>${img##*.}</kbd>).</p>
<p><kbd>let count++</kbd> is used to increment the file number for each execution of the loop.</p>
<p>Here are other ways to perform rename operations:</p>
<ul>
<li>Rename <kbd>*.JPG</kbd> to <kbd>*.jpg</kbd> like this:</li>
</ul>
<pre>
        <strong>$ rename *.JPG *.jpg</strong>
</pre>
<ul>
<li>Use this to replace spaces in the filenames with the <kbd>"_"</kbd> character:</li>
</ul>
<pre>
        <strong>$ rename 's/ /_/g' *</strong>
</pre>
<p style="padding-left: 60px"><kbd># 's/ /_/g'</kbd> is the replacement part in the filename and <kbd>*</kbd> is the wildcard for the target files. It can be <kbd>*.txt</kbd> or any other wildcard pattern.</p>
<ul>
<li>Use these to convert any filenames from uppercase to lowercase and vice versa:</li>
</ul>
<pre>
        <strong>$ rename 'y/A-Z/a-z/' *</strong>
<strong>        $ rename 'y/a-z/A-Z/' *</strong>
</pre>
<ul>
<li>Use this to recursively move all the <kbd>.mp3</kbd> files to a given directory:</li>
</ul>
<pre>
        <strong>$ find path -type f -name "*.mp3" -exec mv {} target_dir \;</strong>
</pre>
<ul>
<li>Use this to recursively rename all the files by replacing spaces with the <kbd>_</kbd> character:</li>
</ul>
<pre>
        <strong>$ find path -type f -exec rename 's/ /_/g' {} \;</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Spell–checking and dictionary manipulation</h1>
            </header>

            <article>
                
<p>Most Linux distributions include a dictionary file. However, very few people are aware of this, thus spelling errors abound. The <kbd>aspell</kbd> command-line utility is a spell checker. Let's go through a few scripts that make use of the dictionary file and the spell checker.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The <kbd>/usr/share/dict/</kbd> directory contains one or perhaps more dictionary files, which are text files with a list of words. We can use this list to check whether a word is a dictionary word or not:</p>
<pre>
<strong>$ ls /usr/share/dict/ </strong>
<strong>american-english  british-english</strong>
</pre>
<p>To check whether the given word is a dictionary word, use the following script:</p>
<pre>
#!/bin/bash 
#Filename: checkword.sh 
word=$1 
grep "^$1$" /usr/share/dict/british-english -q  
if [ $? -eq 0 ]; then 
  echo $word is a dictionary word; 
else 
  echo $word is not a dictionary word; 
fi 
</pre>
<p>The usage is as follows:</p>
<pre>
<strong>$ ./checkword.sh ful </strong>
<strong>ful is not a dictionary word </strong>

<strong>$ ./checkword.sh fool </strong>
<strong>fool is a dictionary word</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>In <kbd>grep</kbd>, <kbd>^</kbd> is the word-start marker character and the <kbd>$</kbd> character is the word-end marker. The <kbd>-q</kbd> option suppresses any output, making the <kbd>grep</kbd> command quiet.</p>
<p>Alternatively, we can use the spell–check, <kbd>aspell</kbd>, to check whether a word is in a dictionary or not:</p>
<pre>
#!/bin/bash  
#Filename: aspellcheck.sh 
word=$1  

output=`echo \"$word\" | aspell list`  

if [ -z $output ]; then  
        echo $word is a dictionary word;  
else  
        echo $word is not a dictionary word;  
fi  
</pre>
<p>The <kbd>aspell list</kbd> command returns output text when the given input is not a dictionary word, and does not output anything when the input is a dictionary word. A <kbd>-z</kbd> command checks whether <kbd>$output</kbd> is an empty string or not.</p>
<p>The <kbd>look</kbd> command will display lines that begin with a given string. You might use it to find the lines in a log file that start with a given date, or to find words in the dictionary that start with a given string. By default, <kbd>look</kbd> searches <kbd>/usr/share/dict/words</kbd>, or you can provide a file to search.</p>
<pre>
<strong>$ look word</strong>
</pre>
<p>Alternatively, this can be used:</p>
<pre>
<strong>$ grep "^word" filepath</strong>
</pre>
<p>Consider this example:</p>
<pre>
<strong>$ look android</strong>
<strong>android</strong>
<strong>android's</strong>
<strong>androids</strong>
</pre>
<p>Use this to find lines with a given date in <kbd>/var/log/syslog</kbd>:</p>
<pre>
<strong>$look 'Aug 30' /var/log/syslog</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Automating interactive input</h1>
            </header>

            <article>
                
<p>We looked at commands that accept arguments on the command line. Linux also supports many interactive applications ranging from <kbd>passwd</kbd> to <kbd>ssh</kbd>.</p>
<p>We can create our own interactive shell scripts. It's easier for casual users to interact with a set of prompts rather than remember command line flags and the proper order. For instance, a script to back up a user's work, but not to back up and lock files, might look like this:</p>
<pre>
<strong>$ backupWork.sh</strong>
</pre>
<ul>
<li>What folder should be backed up? <kbd>notes</kbd></li>
<li>What type of files should be backed up? <kbd>.docx</kbd></li>
</ul>
<p>Automating interactive applications can save you time when you need to rerun the same application and frustration while you're developing one.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The first step to automating a task is to run it and note what you do. The script command discussed earlier may be of use.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>Examine the sequence of interactive inputs. From the previous code, we can formulate the steps of the sequence like this:</p>
<pre>
notes[Return]docx[Return] 
</pre>
<p>In addition to the preceding steps, type <kbd>notes</kbd>, press <kbd>Return</kbd>, type <kbd>docx</kbd>, and finally press <kbd>Return</kbd> to convert into a single string like this:</p>
<pre>
    <strong>"notes\ndocx\n"</strong>
</pre>
<p>The <kbd>\n</kbd> character is sent when we press <span class="KeyPACKT">Return</span>. By appending the return (<kbd>\n</kbd>) characters, we get the string that is passed to <kbd>stdin</kbd> (standard input).</p>
<p>By sending the equivalent string for the characters typed by the user, we can automate passing input to the interactive processes.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>Let's write a script that reads input interactively for an automation example:</p>
<pre>
#!/bin/bash 
# backup.sh 
# Backup files with suffix. Do not backup temp files that start with ~ 
read -p " What folder should be backed up: " folder 
read -p " What type of files should be backed up: " suffix 
find $folder -name "*.$suffix" -a ! -name '~*' -exec cp {} \   
    $BACKUP/$LOGNAME/$folder 
echo "Backed up files from $folder to $BACKUP/$LOGNAME/$folder" 
</pre>
<p>Let's automate the sending of input to the command:</p>
<pre>
<strong>$ echo -e "notes\ndocx\n" | ./backup.sh </strong>
<strong>Backed up files from notes to /BackupDrive/MyName/notes</strong>
</pre>
<p>This style of automating an interactive script can save you a lot of typing during developing and debugging. It also insures that you perform the same test each time and don't end up chasing a phantom bug because you mis-typed.</p>
<p>We used <kbd>echo -e</kbd> to produce the input sequence. The <kbd>-e</kbd> option signals to <kbd>echo</kbd> to interpret escape sequences. If the input is large we can use an input file and the redirection operator to supply input:</p>
<pre>
<strong>$ echo -e "notes\ndocx\n"  &gt; input.data</strong>
<strong>$ cat input.data</strong>
<strong>notes</strong>
<strong>docx</strong>
</pre>
<p>You can manually craft the input file without the <kbd>echo</kbd> commands by hand–typing. Consider this example:</p>
<pre>
<strong>$ ./interactive.sh &lt; input.data</strong>
</pre>
<p>This redirects interactive input data from a file.</p>
<p>If you are a reverse engineer, you may have played with buffer overflow exploits. To exploit them we need to redirect a shell code such as <kbd>\xeb\x1a\x5e\x31\xc0\x88\x46</kbd>, which is written in hex. These characters cannot be typed directly on the keyboard as keys for these characters are not present. Therefore, we use:</p>
<pre>
<strong>echo -e \xeb\x1a\x5e\x31\xc0\x88\x46"</strong>
</pre>
<p>This will redirect the byte sequence to a vulnerable executable.</p>
<p>These echo and redirection techniques automate interactive input programs. However, these techniques are fragile, in that there is no validity checking and it's assumed that the target application will always accept data in the same order. If the program asks for input in a changing order, or some inputs are not always required, these methods fail.</p>
<p>The expect program can perform complex interactions and adapt to changes in the target application. This program is in worldwide use to control hardware tests, validate software builds, query router statistics, and much more.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>The expect application is an interpreter similar to the shell. It's based on the TCL language. We'll discuss the spawn, expect, and send commands for simple automation. With the power of the TCL language behind it, expect can do much more complex tasks. You can learn more about the TCL language at the <span class="URLPACKT"><a href="http://www.tcl.tk">www.tcl.tk</a> website</span>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Automating with expect</h1>
            </header>

            <article>
                
<p><kbd>expect</kbd> does not come by default on all Linux distributions. You may have to install the expect package with your package manager (<kbd>apt-get</kbd> or <kbd>yum</kbd>).</p>
<p>Expect has three main commands:</p>
<table>
<tbody>
<tr>
<td>
<div class="CDPAlignCenter CDPAlign"><strong>Commands</strong></div>
</td>
<td>
<div class="CDPAlignCenter CDPAlign"><strong>Description</strong></div>
</td>
</tr>
<tr>
<td><kbd>spawn</kbd></td>
<td>Runs the new target application.</td>
</tr>
<tr>
<td><kbd>expect</kbd></td>
<td>Watches for a pattern to be sent by the target application.</td>
</tr>
<tr>
<td><kbd>send</kbd></td>
<td>Sends a string to the target application.</td>
</tr>
</tbody>
</table>
<p>The following example spawns the backup script and then looks for the patterns <kbd>*folder*</kbd> and <kbd>*file*</kbd> to determine if the backup script is asking for a folder name or a filename. It will then send the appropriate reply. If the backup script is rewritten to request files first and then folders, this automation script still works.</p>
<pre>
#!/usr/bin/expect  
#Filename: automate_expect.tcl 
spawn ./backup .sh  
expect { 
  "*folder*" { 
     send "notes\n" 
     exp_continue 
   } 
  "*type*" { 
     send "docx\n" 
     exp_continue 
  } 
} 
</pre>
<p>Run it as: </p>
<pre>
<strong>$ ./automate_expect.tcl </strong>
</pre>
<p>The <kbd>spawn</kbd> command's parameters are the target application and arguments to be automated.</p>
<p>The <kbd>expect</kbd> command accepts a set of patterns to look for and an action to perform when that pattern is matched. The action is enclosed in curly braces.</p>
<p>The <kbd>send</kbd> command is the message to be sent. This is similar to echo <kbd>-n -e</kbd> in that it does not automatically include the newline and does understand backslash symbols.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Making commands quicker by running parallel processes</h1>
            </header>

            <article>
                
<p>Computing power constantly increases not only because processors have higher clock cycles but also because they have multiple cores. This means that in a single hardware processor there are multiple logical processors. It's like having several computers, instead of just one.</p>
<p>However, multiple cores are useless unless the software makes use of them. For example, a program that does huge calculations may only run on one core while the others will sit idle. The software has to be aware and take advantage of the multiple cores if we want it to be faster.</p>
<p>In this recipe, we will see how we can make our commands run faster.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>Let's take an example of the <kbd>md5sum</kbd> command we discussed in the previous recipes. This command performs complex computations, making it CPU-intensive. If we have more than one file that we want to generate a checksum for, we can run multiple instances of <kbd>md5sum</kbd> using a script like this:</p>
<pre>
#/bin/bash 
#filename: generate_checksums.sh 
PIDARRAY=() 
for file in File1.iso File2.iso 
do 
  md5sum $file &amp; 
  PIDARRAY+=("$!") 
done 
wait ${PIDARRAY[@]} 
</pre>
<p>When we run this, we get the following output:</p>
<pre>
<strong>$ ./generate_checksums.sh </strong>
<strong>330dcb53f253acdf76431cecca0fefe7  File1.iso</strong>
<strong>bd1694a6fe6df12c3b8141dcffaf06e6  File2.iso</strong>
</pre>
<p>The output will be the same as running the following command:</p>
<pre>
<strong>md5sum File1.iso File2.iso</strong>
</pre>
<p>However, if the <kbd>md5sum</kbd> commands run simultaneously, you'll get the results quicker if you have a multi–core processor (you can verify this using the <kbd>time</kbd> command).</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How it works...</h1>
            </header>

            <article>
                
<p>We exploit the Bash operand <kbd>&amp;</kbd>, which instructs the shell to send the command to the background and continue with the script. However, this means our script will exit as soon as the loop completes, while the <kbd>md5sum</kbd> processes are still running in the background. To prevent this, we get the PIDs of the processes using <kbd>$!</kbd>, which in Bash holds the PID of the last background process. We append these PIDs to an array and then use the <kbd>wait</kbd> command to wait for these processes to finish.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">There's more...</h1>
            </header>

            <article>
                
<p>The Bash <kbd>&amp;</kbd> operand works well for a small number of tasks. If you had a hundred files to checksum, the script would try to start a hundred processes and might force your system into swapping, which would make the tasks run slower.</p>
<p>The GNU parallel command is not part of all installations, but again it can be loaded with your package manager. The parallel command optimizes the use of your resources without overloading any of them.</p>
<p>The parallel command reads a list of files on <kbd>stdin</kbd> and uses options similar to the find command's <kbd>-exec</kbd> argument to process these files. The <kbd>{}</kbd> symbol represents the file to be processed, and the <kbd>{.}</kbd> symbol represents the filename without a suffix.</p>
<p>The following command uses <strong>Imagemagick's </strong><kbd>convert</kbd> command to make new, resized images of all the images in a folder:</p>
<pre>
<strong>ls *jpg | parallel convert {} -geometry 50x50 {.}Small.jpg</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Examining a directory, files and subdirectories in it</h1>
            </header>

            <article>
                
<p>One of the commonest problems we deal with is finding misplaced files and sorting out mangled file hierarchies. This section will discuss tricks for examining a portion of the filesystem and presenting the contents.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Getting ready</h1>
            </header>

            <article>
                
<p>The <kbd>find</kbd> command and loops we discussed give us tools to examine and report details in a directory and its contents.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">How to do it...</h1>
            </header>

            <article>
                
<p>The next recipes show two ways to examine a directory. First we'll display the hierarchy as a tree, then we'll see how to generate a summary of files and folders under a directory.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Generating a tree view of a directory.</h1>
            </header>

            <article>
                
<p>Sometimes it's easier to visualize a file system if it's presented graphically.</p>
<p>The next recipe pulls together several of the tools we discussed. It uses the find command to generate a list of all the files and sub-folders under the current folder.</p>
<p>The <kbd>-exec</kbd> option creates a subshell which uses echo to send the filenames to the <kbd>tr</kbd> command's <kbd>stdin</kbd>. There are two <kbd>tr</kbd> commands. The first deletes all alphanumeric characters, and any dash (<kbd>-</kbd>), underbar (<kbd>_</kbd>), or period (<kbd>.</kbd>). This passes only the slashes (<kbd>/</kbd>) in the path to the second <kbd>tr</kbd> command, which translates those slashes to spaces. Finally, the <kbd>basename</kbd> command strips the leading path from the filename and displays it.</p>
<p>Use these to view a tree of the folders in <kbd>/var/log</kbd>:</p>
<pre>
<strong>$ cd /var/log
$ find . -exec sh -c 'echo -n {} | tr -d "[:alnum:]_.\-" | \
    tr "/" " "; basename {}' \;</strong>
</pre>
<p>This output is generated:</p>
<pre>
<strong>mail</strong>
<strong>  statistics</strong>
<strong>gdm</strong>
<strong>  ::0.log</strong>
<strong>  ::0.log.1</strong>
<strong>cups</strong>
<strong>      error_log</strong>
<strong>      access_log</strong>
<strong>  ... access_l</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    

        <section>

            <header>
                <h1 class="header-title">Generating a summary of files and sub-directories</h1>
            </header>

            <article>
                
<p>We can generate a list of subdirectories, and the number of files in them, with a combination of the <kbd>find</kbd> command, <kbd>echo</kbd>, and <kbd>wc</kbd> commands, which will be discussed in greater detail in the next chapter.</p>
<p>Use the following to get a summary of files in the current folder:</p>
<pre>
for d in `find . -type d`;  
  do  
  echo `find $d -type f | wc -l` files in $d;  
done 
</pre>
<p>If this script is run in <kbd>/var/log</kbd>, it will generate output like this:</p>
<pre>
<strong>103 files in .</strong>
<strong>17 files in ./cups</strong>
<strong>0 files in ./hp</strong>
<strong>0 files in ./hp/tmp</strong>
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </body></html>