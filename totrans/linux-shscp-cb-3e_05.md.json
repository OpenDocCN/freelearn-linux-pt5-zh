["```\n$ wget URL\n\n```", "```\n$ wget knopper.net\n--2016-11-02 21:41:23--  http://knopper.net/\nResolving knopper.net... 85.214.68.145\nConnecting to knopper.net|85.214.68.145|:80...\nconnected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6899 (6.7K) [text/html]\nSaving to: \"index.html.1\"\n\n100% [=============================]45.5K=0.1s\n\n2016-11-02 21:41:23 (45.5 KB/s) - \"index.html.1\" saved\n[6899/6899]\n\n```", "```\n$ wget URL1 URL2 URL3 ..\n\n```", "```\n$ wget http://www.knopper.net -O knopper.html.\n\n```", "```\n$ wget ftp://ftp.example.com/somefile.img -O dloaded_file.img -o log\n\n```", "```\n$ wget -t 5 URL\n\n```", "```\n$ wget -t 0 URL\n\n```", "```\n$ wget  --limit-rate 20k http://example.com/file.iso\n\n```", "```\n$ wget -Q 100m http://example.com/file1 http://example.com/file2\n\n```", "```\n$ wget -c URL\n\n```", "```\n$ wget --mirror --convert-links exampledomain.com\n\n```", "```\n$ wget -r -N -l -k DEPTH URL\n\n```", "```\n$ wget --user username --password pass URL\n\n```", "```\n# yum install lynx\n\n```", "```\n apt-get install lynx\n\n```", "```\n$ lynx URL -dump > webpage_as_text.txt\n\n```", "```\n$lynx -dump http://google.com > plain_text_page.txt\n\n```", "```\n    $ cat plain_text_page.txt\n Search [1]Images [2]Maps [3]Play [4]YouTube [5]News [6]Gmail   \n    [7]Drive\n [8]More »\n [9]Web History | [10]Settings | [11]Sign in\n\n [12]St. Patrick's Day 2017\n\n _______________________________________________________\n Google Search  I'm Feeling Lucky    [13]Advanced search\n [14]Language tools\n\n [15]Advertising Programs     [16]Business Solutions     [17]+Google\n [18]About Google\n\n © 2017 - [19]Privacy - [20]Terms\n\nReferences\n...\n\n```", "```\n        $ curl URL\n\n```", "```\n        $ curl www.knopper.net/index.htm --silent -O\n\n```", "```\n        $curl www.knopper.net -o knoppix_index.html\n % Total % Received % Xferd  Avg  Speed Time   Time  Time  \n        Current\n Dload Upload Total Spent Left  Speed\n 100 6889 100 6889  0 0     10902  0     --:-- --:-- --:-- 26033\n\n```", "```\n        $ curl URL --silent\n\n```", "```\n        $ curl http://knopper.net -o index.html --progress\n ################################## 100.0% \n\n```", "```\n$ curl URL/file -C offset\n\n```", "```\n$ curl -C - URL\n\n```", "```\n$ curl --referer Referer_URL target_URL\n\n```", "```\n$ curl --referer http://google.com http://knopper.org\n\n```", "```\n$ curl http://example.com --cookie \"user=username;pass=hack\"\n\n```", "```\n$ curl URL --cookie-jar cookie_file\n\n```", "```\n$ curl URL --user-agent \"Mozilla/5.0\"\n\n```", "```\n$ curl -H \"Host: www.knopper.net\" -H \"Accept-language: en\" URL\n\n```", "```\n$ curl URL --limit-rate 20k\n\n```", "```\n$ curl URL --max-filesize bytes\n\n```", "```\n$ curl -u user:pass http://test_auth.com\n\n```", "```\n$ curl -u user http://test_auth.com \n\n```", "```\n$ curl -I http://knopper.net \nHTTP/1.1 200 OK\nDate: Tue, 08 Nov 2016 17:15:21 GMT\nServer: Apache\nLast-Modified: Wed, 26 Oct 2016 23:29:56 GMT\nETag: \"1d3c8-1af3-b10500\"\nAccept-Ranges: bytes\nContent-Length: 6899\nContent-Type: text/html; charset=ISO-8859-1\n\n```", "```\n#!/bin/bash \n#Desc: Fetch gmail tool \n\nusername='PUT_USERNAME_HERE' \npassword='PUT_PASSWORD_HERE' \n\nSHOW_COUNT=5 # No of recent unread mails to be shown \n\necho \ncurl -u $username:$password --silent \\\n    \"https://mail.google.com/mail/feed/atom\" | \\\n     tr -d '\\n' | sed 's:</entry>:\\n:g' |\\ \n     sed -n 's/.*<title>\\(.*\\)<\\/title.*<author><name>\\([^<]*\\)<\\/name><email>\n \\([^<]*\\).*/From: \\2 [\\3] \\nSubject: \\1\\n/p' | \\ \nhead -n $(( $SHOW_COUNT * 3 ))\n\n```", "```\n$ ./fetch_gmail.sh\nFrom: SLYNUX [ slynux@slynux.com ]\nSubject: Book release - 2\n\nFrom: SLYNUX [ slynux@slynux.com ]\nSubject: Book release - 1 \n.\n... 5 entries\n\n```", "```\n sed 's/.*<title>\\(.*\\)<\\/title.*<author><name>\\([^<]*\\)<\\/name><email>\n \\([^<]*\\).*/Author: \\2 [\\3] \\nSubject: \\1\\n/' \n\n```", "```\nAuthor: \\2 [\\3] \\nSubject: \\1\\n \n\n```", "```\n$ lynx -dump -nolist \\\n    http://www.johntorres.net/BoxOfficefemaleList.html\n    grep -o \"Rank-.*\" | \\\n    sed -e 's/ *Rank-\\([0-9]*\\) *\\(.*\\)/\\1\\t\\2/' | \\\n    sort -nk 1 > actresslist.txt \n\n```", "```\n# Only 3 entries shown. All others omitted due to space limits\n1   Keira Knightley \n2   Natalie Portman \n3   Monica Bellucci \n\n```", "```\nsed -e 's/ *Rank-\\([0-9]*\\) *\\(.*\\)/\\1\\t\\2/'\n\n```", "```\n#!/bin/bash \n#Desc: Images downloader \n#Filename: img_downloader.sh \n\nif [ $# -ne 3 ];\nthen\n  echo \"Usage: $0 URL -d DIRECTORY\"\n  exit -1\nfi\nwhile [ $# -gt 0 ]\ndo\n  case $1 in\n  -d) shift; directory=$1; shift ;;\n  *) url=$1; shift;;\n  esac\ndone\n\nmkdir -p $directory;\nbaseurl=$(echo $url | egrep -o \"https?://[a-z.\\-]+\")\n\necho Downloading $url \ncurl -s $url | egrep -o \"<img[^>]*src=[^>]*>\" | \\\n  sed 's/<img[^>]*src=\\\"\\([^\"]*\\).*/\\1/g' | \\\n  sed \"s,^/,$baseurl/,\" > /tmp/$$.list\n\ncd $directory;\n\nwhile read filename;\ndo\n  echo Downloading $filename\n  curl -s -O \"$filename\" --silent\ndone < /tmp/$$.list\n\n```", "```\n$ url=https://commons.wikimedia.org/wiki/Main_Page\n$ ./img_downloader.sh $url -d images\n\n```", "```\nwhile [ -n \"$1\" ] \ndo  \n  case $1 in \n  -d) shift; directory=$1; shift ;; \n   *) url=${url:-$1}; shift;; \nesac \ndone \n\n```", "```\n$ ./img_downloader.sh -d DIR URL\n\n```", "```\n$ ./img_downloader.sh URL -d DIR\n\n```", "```\nbaseurl=$(echo $url | egrep -o \"https?://[a-z.\\-]+\") \n\n```", "```\nsed \"s,^/,$baseurl/,\" > /tmp/$$.list \n\n```", "```\n#!/bin/bash \n#Filename: generate_album.sh \n#Description: Create a photo album using images in current directory \n\necho \"Creating album..\" \nmkdir -p thumbs \ncat <<EOF1 > index.html \n<html> \n<head> \n<style> \n\nbody  \n{  \n  width:470px; \n  margin:auto; \n  border: 1px dashed grey; \n  padding:10px;  \n}  \n\nimg \n{  \n  margin:5px; \n  border: 1px solid black; \n\n}  \n</style> \n</head> \n<body> \n<center><h1> #Album title </h1></center> \n<p> \nEOF1 \n\nfor img in *.jpg; \ndo  \n  convert \"$img\" -resize \"100x\" \"thumbs/$img\" \n  echo \"<a href=\\\"$img\\\" >\" >>index.html \n  echo \"<img src=\\\"thumbs/$img\\\" title=\\\"$img\\\" /></a>\" >> index.html \ndone \n\ncat <<EOF2 >> index.html \n\n</p> \n</body> \n</html> \nEOF2  \n\necho Album generated to index.html \n\n```", "```\n$ ./generate_album.sh\nCreating album..\nAlbum generated to index.html\n\n```", "```\ncat <<EOF1 > index.html \ncontents... \nEOF1 \n\n```", "```\necho \"<a href=\\\"$img\\\" >\" \necho \"<img src=\\\"thumbs/$img\\\" title=\\\"$img\\\" /></a>\" >> index.html \n\n```", "```\n#!/bin/bash \n#Filename: twitter.sh \n#Description: Basic twitter client \n\noauth_consumer_key=YOUR_CONSUMER_KEY \noauth_consumer_scret=YOUR_CONSUMER_SECRET \n\nconfig_file=~/.$oauth_consumer_key-$oauth_consumer_secret-rc  \n\nif [[ \"$1\" != \"read\" ]] && [[ \"$1\" != \"tweet\" ]]; \nthen  \n  echo -e \"Usage: $0 tweet status_message\\n   OR\\n      $0 read\\n\" \n  exit -1; \nfi \n\n#source /usr/local/bin/TwitterOAuth.sh \nsource bash-oauth-master/TwitterOAuth.sh \nTO_init \n\nif [ ! -e $config_file ]; then \n TO_access_token_helper \n if (( $? == 0 )); then \n   echo oauth_token=${TO_ret[0]} > $config_file \n   echo oauth_token_secret=${TO_ret[1]} >> $config_file \n fi \nfi \n\nsource $config_file \n\nif [[ \"$1\" = \"read\" ]]; \nthen \nTO_statuses_home_timeline '' 'YOUR_TWEET_NAME' '10' \n  echo $TO_ret |  sed  's/,\"/\\n/g' | sed 's/\":/~/' | \\ \n    awk -F~ '{} \\ \n      {if ($1 == \"text\") \\ \n        {txt=$2;} \\ \n       else if ($1 == \"screen_name\") \\ \n        printf(\"From: %s\\n Tweet: %s\\n\\n\", $2, txt);} \\ \n      {}' | tr '\"' ' ' \n\nelif [[ \"$1\" = \"tweet\" ]]; \nthen  \n  shift \n  TO_statuses_update '' \"$@\" \n  echo 'Tweeted :)' \nfi \n\n```", "```\n$./twitter.sh read\nPlease go to the following link to get the PIN:   \nhttps://api.twitter.com/oauth/authorize?\noauth_token=LONG_TOKEN_STRING\nPIN: PIN_FROM_WEBSITE\nNow you can create, edit and present Slides offline.\n- by A Googler \n$./twitter.sh tweet \"I am reading Packt Shell Scripting Cookbook\"\nTweeted :)\n$./twitter.sh read | head -2\nFrom: Clif Flynt\nTweet: I am reading Packt Shell Scripting Cookbook \n\n```", "```\n[{\"created_at\":\"Thu Nov 10 14:45:20 +0000    \n\"016\",\"id\":7...9,\"id_str\":\"7...9\",\"text\":\"Dining...\n\n```", "```\nscreen_name~\"Clif_Flynt\" \n\n```", "```\n#!/bin/bash \n#Filename: define.sh \n#Desc: A script to fetch definitions from dictionaryapi.com \n\nkey=YOUR_API_KEY_HERE \n\nif  [ $# -ne 2 ]; \nthen \n  echo -e \"Usage: $0 WORD NUMBER\" \n  exit -1; \nfi \n\ncurl --silent \\\nhttp://www.dictionaryapi.com/api/v1/references/learners/xml/$1?key=$key | \\ \n  grep -o \\<dt\\>.*\\</dt\\> | \\ \n  sed 's$</*[a-z]*>$$g' | \\ \n  head -n $2 | nl \n\n```", "```\n    $ ./define.sh usb 1\n 1  :a system for connecting a computer to another device (such as   \n    a printer, keyboard, or mouse) by using a special kind of cord a   \n    USB cable/port USB is an abbreviation of \"Universal Serial Bus.\"How \n    it works...\n\n```", "```\n#!/bin/bash  \n#Filename: find_broken.sh \n#Desc: Find broken links in a website \n\nif [ $# -ne 1 ];  \nthen  \n  echo -e \"$Usage: $0 URL\\n\"  \n  exit 1;  \nfi  \n\necho Broken links:  \n\nmkdir /tmp/$$.lynx  \ncd /tmp/$$.lynx  \n\nlynx -traversal $1 > /dev/null  \ncount=0;  \n\nsort -u reject.dat > links.txt  \n\nwhile read link;  \ndo  \n  output=`curl -I $link -s \\ \n| grep -e \"HTTP/.*OK\" -e \"HTTP/.*200\"` \n  if [[ -z $output ]];  \n  then  \n    output=`curl -I $link -s | grep -e \"HTTP/.*301\"` \n    if [[ -z $output ]];  \n      then  \n      echo \"BROKEN: $link\" \n      let count++  \n    else  \n      echo \"MOVED: $link\" \n    fi \n  fi  \ndone < links.txt  \n\n[ $count -eq 0 ] && echo No broken links found. \n\n```", "```\n#!/bin/bash \n#Filename: change_track.sh \n#Desc: Script to track changes to webpage \n\nif [ $# -ne 1 ]; \nthen  \n  echo -e \"$Usage: $0 URL\\n\" \n  exit 1; \nfi \n\nfirst_time=0 \n# Not first time \n\nif [ ! -e \"last.html\" ]; \nthen \n  first_time=1 \n  # Set it is first time run \nfi \n\ncurl --silent $1 -o recent.html \n\nif [ $first_time -ne 1 ]; \nthen \n  changes=$(diff -u last.html recent.html) \n  if [ -n \"$changes\" ]; \n  then \n    echo -e \"Changes:\\n\" \n    echo \"$changes\" \n  else \n    echo -e \"\\nWebsite has no changes\" \n  fi \nelse \n  echo \"[First run] Archiving..\" \n\nfi \n\ncp recent.html last.html \n\n```", "```\n        $ ./track_changes.sh http://www.MyWebSite.org\n [First run] Archiving..\n\n```", "```\n        $ ./track_changes.sh http://www.MyWebSite.org\n Website has no changes \n\n```", "```\n        $ ./track_changes.sh http://www.MyWebSite.org\n\n Changes: \n\n --- last.html    2010-08-01 07:29:15.000000000 +0200 \n +++ recent.html    2010-08-01 07:29:43.000000000 +0200 \n @@ -1,3 +1,4 @@ \n <html>\n +added line :)\n <p>data</p>\n </html>\n\n```", "```\n    tclsh httpd.tcl\n\n```", "```\n    $ curl URL -d \"postvar=postdata2&postvar2=postdata2\"\n\n```", "```\n    $ curl http://127.0.0.1:8015/guestbook/newguest.html \\\n -d \"name=Clif&url=www.noucorp.com&http=www.noucorp.com\"\n\n```", "```\n<HTML> \n<Head> \n<title>Guestbook Registration Confirmed</title> \n</Head> \n<Body BGCOLOR=white TEXT=black> \n<a href=\"www.noucorp.com\">www.noucorp.com</a> \n\n<DL> \n<DT>Name \n<DD>Clif \n<DT>URL \n<DD> \n</DL> \nwww.noucorp.com \n\n</Body> \n\n```", "```\n    $ wget http://127.0.0.1:8015/guestbook/newguest.cgi \\\n --post-data \"name=Clif&url=www.noucorp.com&http=www.noucorp.com\" \\\n -O output.html\n\n```", "```\n<form action=\"newguest.cgi\" \" method=\"post\" > \n<ul> \n<li> Name: <input type=\"text\" name=\"name\" size=\"40\" > \n<li> Url: <input type=\"text\" name=\"url\" size=\"40\" > \n<input type=\"submit\" > \n</ul> \n</form> \n\n```", "```\n    youtube-dl https://www.youtube.com/watch?v=AJrsl3fHQ74\n\n```", "```\n    apt-get install libots-devel\n\n```", "```\n    ots LongFile.txt | less\n\n```", "```\n    cat LongFile.txt | ots | less\n\n```", "```\n    curl http://BlogSite.org | sed -r 's/<[^>]+>//g' | ots | less\n\n```", "```\n    cd ~/bin\n wget git.io/trans \n chmod 755 ./trans\n\n```", "```\n    $> trans \"J'adore Linux\"\n\n J'adore Linux\n\n I love Linux\n\n Translations of J'adore Linux\n French -> English\n\n J'adore Linux \n I love Linux\n\n```", "```\n    from:to\n\n```", "```\n    $> trans en:fr \"I love Linux\" \n J'aime Linux\n\n```"]