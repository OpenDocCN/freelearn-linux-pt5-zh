<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Introduction to Kubernetes</h1></div></div></div><p>In this chapter, we will cover a short overview of Google Kubernetes, which manages containerized applications across multiple hosts in a cluster. As Kubernetes is a very large project, in this chapter, we will only overview its main concepts and some use cases, including these:</p><div><ul class="itemizedlist"><li class="listitem">What is Kubernetes?</li><li class="listitem">Primary components of Kubernetes</li><li class="listitem">Kubernetes cluster setup</li><li class="listitem">Tectonic—CoreOS and Kubernetes combined for a commercial implementation</li></ul></div><div><div><div><div><h1 class="title"><a id="ch10lvl1sec49"/>What is Kubernetes?</h1></div></div></div><p>Google has been<a id="id200" class="indexterm"/> running everything in containers for more than decade. Internally, they use a system called<a id="id201" class="indexterm"/> Borg (<a class="ulink" href="http://research.google.com/pubs/pub43438.html">http://research.google.com/pubs/pub43438.html</a>), the predecessor of Kubernetes, to scale and orchestrate containers across servers.</p><p>Lessons learned from Borg were used to build Kubernetes, an open source container orchestration system. It became popular very quickly when it was released in June 2014.</p><p>All of the best ideas from Borg were incorporated into Kubernetes. Many of Borg's developers now work on Kubernetes.</p><p>Kubernetes received thousands of<a id="id202" class="indexterm"/> stars at it's GitHub project (<a class="ulink" href="https://github.com/GoogleCloudPlatform/kubernetes">https://github.com/GoogleCloudPlatform/kubernetes</a>), and hundreds of supporters from the open source community and companies such as CoreOS, Red Hat, Microsoft, VMware, and so on.</p><div><div><div><div><h2 class="title"><a id="ch10lvl2sec39"/>Primary components of Kubernetes</h2></div></div></div><p>Kubernetes can be run <a id="id203" class="indexterm"/>on any modern Linux operating system.</p><p>Here are the main components of Kubernetes:</p><div><ul class="itemizedlist"><li class="listitem"><strong>Master</strong>: This is the set <a id="id204" class="indexterm"/>of main Kubernetes control services, usually running on one server except the <code class="literal">etcd</code> cluster. However it can be spread around a few servers. The services of Kubernetes are as follows:<div><ul class="itemizedlist"><li class="listitem"><code class="literal">etcd</code> cluster</li><li class="listitem">API server</li><li class="listitem">Controller manager</li><li class="listitem">Scheduler</li></ul></div></li><li class="listitem"><strong>Node</strong>: This is a cluster worker. It can be a VM and/or bare-metal server. Nodes are managed from the master services and are dedicated to run pods. These two Kubernetes services must run on each node:<div><ul class="itemizedlist"><li class="listitem">Kubelet</li><li class="listitem">Network proxy</li></ul></div><p>Docker and rkt are<a id="id205" class="indexterm"/> used to run application containers. In future, we will see more support for application container systems there.</p></li><li class="listitem"><strong>Pod</strong>: This is a group of<a id="id206" class="indexterm"/> application containers running with the shared context. Even a single application container must run in a Pod.</li><li class="listitem"><strong>Replication controllers</strong>: These ensure that the specified numbers of pods are running. If there are too <a id="id207" class="indexterm"/>many pods, will be killed. If they are too less, then the required number of pods will be started. It is not recommended to run pods without replication controllers even if there is a single Pod.</li><li class="listitem"><strong>Services</strong>: The same pod<a id="id208" class="indexterm"/> can be run only once. If it dies, the replication controller replaces it with a new pod. Every pod gets its own dedicated IP, which allows on the same node to run many containers on the port. But every time a pod is started from the template by replication controller gets a different IP, and this is where services come to help. Each service gets assigned a virtual IP, which stays with it until it dies.</li><li class="listitem"><strong>Labels</strong>: These are the arbitrary key-value pairs that are used by every Kubernetes component; for <a id="id209" class="indexterm"/>example, the replication controller uses them for service discovery.</li><li class="listitem"><strong>Volumes</strong>: A volume is a<a id="id210" class="indexterm"/> directory that is accessible from a container, and is used to store the container's stateful data.</li><li class="listitem"><strong>Kubectl</strong>: This controls the Kubernetes cluster manager. For example, you can add/delete nodes, pods, or replication controllers; check their status; and so on. Kubernetes uses <a id="id211" class="indexterm"/><code class="literal">manifest</code> files to set up pods, replication controllers, services, labels, and so on.</li></ul></div><p>Kubernetes has a nice UI, which was<a id="id212" class="indexterm"/> built and contributed to by <a class="ulink" href="http://kismatic.io/">http://kismatic.io/</a>. It runs on an API server:</p><div><img src="img/image00180.jpeg" alt="Primary components of Kubernetes"/></div><p style="clear:both; height: 1em;"> </p><p>This allows us to check the Kubernetes cluster's status and add/delete pods, replication controllers, and so on. It also allows us to manage a Kubernetes cluster from the UI in the same way as from <code class="literal">kubectl</code>.</p><p>
<a class="ulink" href="http://kismatic.io/">http://kismatic.io/</a> is also<a id="id213" class="indexterm"/> going to offer an enterprise/commercial version of Kubernetes in the near future.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec50"/>Kubernetes cluster setup</h1></div></div></div><p>In the previous topic, we overviewed the main features of Kubernetes, so let's do some interesting stuff—installing small Kubernetes on Google Cloud.</p><p>Note, that if you are using a<a id="id214" class="indexterm"/> free/trial Google Cloud account, which has a limit of eight CPUs (eight VMs are allowed), you need to delete some of them. Let's replace <a id="id215" class="indexterm"/>our production cluster with a Kubernetes cluster. Select the VMs as per what is shown in the following screenshot. Then click on the <strong>Delete</strong> button in the top-right corner.</p><div><img src="img/image00181.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>Now we are ready to install a<a id="id216" class="indexterm"/> Kubernetes cluster:</p><div><ol class="orderedlist arabic"><li class="listitem">Type this in your terminal:<div><pre class="programlisting">
<strong>$ cd coreos-essentials-book/Chapter10/Kubernetes_Cluster</strong>
</pre></div><p>Note that as we have folders/files that are very similar to what we used to set up the Test/Staging/Production clusters, we are not going to review the scripts this time. You can always check out the setup files yourself and learn the differences there:</p></li><li class="listitem">Update the <a id="id217" class="indexterm"/><code class="literal">settings</code> file there with your GC project ID and zone.</li><li class="listitem">Let's now run the first script, named <code class="literal">1-bootstrap_cluster.sh</code>:<div><pre class="programlisting">
<strong>$ ./ 1-bootstrap_cluster.sh</strong>
</pre></div><p>You should see an output similar to this:</p><div><img src="img/image00182.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p></li></ol><div></div><p>If you check out the Google Cloud console, you should see three new VMs there, namely <strong>k8s-master</strong>, <strong>k8s-node1</strong>, and <strong>k8s-node2</strong>:</p><div><img src="img/image00183.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">1-bootstrap_cluster.sh</code> script has installed a small CoreOS cluster, which is set up in the same way as our previous Test/Staging/Production cluster—one <code class="literal">etcd</code> server and two workers connected to it. And also create a new folder, <code class="literal">k8s-cluster</code>, in the user home folder where the <code class="literal">settings</code> file got copied and other binary files will be copied later on.</p><div><ol class="orderedlist arabic"><li class="listitem">Next, we need to install the <code class="literal">fleetctl</code>, <code class="literal">etcdctl</code>, and <code class="literal">kubectl</code> local clients on our <a id="id218" class="indexterm"/>computer to be able to communicate with the CoreOS cluster <code class="literal">etcd</code> and <code class="literal">fleet</code> services, and with the Kubernetes master service.<p>Type the following line in your terminal:</p><div><pre class="programlisting">
<strong>$ ./2-get_k8s_fleet_etcd.sh</strong>
</pre></div><p>You should see an output similar to this:</p><div><img src="img/image00184.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Now let's install the Kubernetes cluster on top our new CoreOS cluster.<p>Type this command in your terminal:</p><div><pre class="programlisting">
<strong>$ ./3-install_k8s_fleet_units.sh</strong>
</pre></div><p>You should see an output similar to what is shown here:</p><div><img src="img/image00185.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Let's try <a id="id219" class="indexterm"/>access our Kubernetes cluster via <code class="literal">""</code>, which was copied to <code class="literal">~/k8s-cluster/bin</code> by the <code class="literal">1-bootstrap_cluster.sh</code> script.<p>Type this in your terminal:</p><div><pre class="programlisting">
<strong>$ cd ~/k8s-cluster/bin</strong>
<strong>$ ./set_k8s_access.sh</strong>
</pre></div><p>You should get an output similar to the following:</p><div><img src="img/image00186.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p></li></ol><div></div><p>As you can see, our<a id="id220" class="indexterm"/> Kubernetes cluster is up and running.</p><p>What <code class="literal">set_k8s_access.sh</code> does is that it provides <code class="literal">fleetctl</code> and <code class="literal">kubectl</code> with access to the remote <code class="literal">k8s-master</code> server by forwarding the <code class="literal">localhost</code> ports 2379 (<code class="literal">fleet</code>) and 8080 (Kubernetes master) to it.</p><div><ol class="orderedlist arabic"><li class="listitem">Let's check out the Kubernetes cluster by typing this into the terminal:<div><pre class="programlisting">
<strong>$ kubectl cluster-info</strong>
</pre></div><p>You should see an output similar to this:</p><div><img src="img/image00187.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>Perfect! Now we can access the remote Kubernetes cluster from our local computer.</p></li><li class="listitem">As we've got our Kubernetes cluster up and running, let's deploy the same <code class="literal">website1</code> Docker image that we used for our production cluster deployment.<p>Type this into your terminal:</p><div><pre class="programlisting">
<strong>$  kubectl run website1 --image=10.200.4.1:5000/website1 --replicas=2 --port=80</strong>
</pre></div><p>You should see the following output:</p><div><img src="img/image00188.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>The previous command has created two <code class="literal">website1</code> pods listening on <code class="literal">port 80</code>. It has also created a replication controller named <code class="literal">website1</code>, and this replication controller ensures that there are always two pods running.</p><p>We can list created <code class="literal">pods</code> by typing the following into your terminal:</p><div><pre class="programlisting">
<strong>$ kubectl get pods</strong>
</pre></div><p>You should see an output like this:</p><div><img src="img/image00189.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>To list the created replication controller, type this into your terminal:</p><div><pre class="programlisting">
<strong>$ kubectl get rc</strong>
</pre></div><p>You should see the following output:</p><div><img src="img/image00190.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Now, let's expose<a id="id221" class="indexterm"/> our pods to the Internet. The <code class="literal">Kubectl</code> command<a id="id222" class="indexterm"/> can integrate with the Google Compute Engine to add a public IP address for the <code class="literal">pods</code>. To do this, type the following line into your terminal:<div><pre class="programlisting">
<strong>$ kubectl expose rc website1 --port=80 --type=LoadBalancer</strong>
</pre></div><p>You should see an output like this:</p><div><img src="img/image00191.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>The previous command created a service named <code class="literal">website1</code> and mapped an external IP address to the service. To find that IP address, type this into your terminal:</p><div><pre class="programlisting">
<strong>$ kubectl get services</strong>
</pre></div><p>You should see an output similar to the following:</p><div><img src="img/image00192.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p></li></ol><div></div><p>The IP in the bottom line is our IP, and it is of the load balancer. It is assigned to the <code class="literal">k8s-node-1</code> and <code class="literal">k8snode-2</code> servers and used by <code class="literal">website1</code> service.</p><p>Let's type this IP into our web browser. We should get an output similar to this:</p><div><img src="img/image00193.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>As you have seen <a id="id223" class="indexterm"/>previously, it shows exactly the same web page as we got on our production web servers. Also, it is exactly the same code as we had in the staging environment. We built the Docker image from it and used that Docker image for deployment on our production cluster and the Kubernetes cluster.</p><p>If you want, you can easily run more replicas of pods by using this simple command:</p><div><pre class="programlisting">
<strong>$ kubectl scale --replicas=4 rc website1</strong>
</pre></div><p>Let's check our replication controller by typing the following into our terminal:</p><div><pre class="programlisting">
<strong>$ kubectl get rc</strong>
</pre></div><p>You should see an output similar to this:</p><div><img src="img/image00194.jpeg" alt="Kubernetes cluster setup"/></div><p style="clear:both; height: 1em;"> </p><p>The previous command scales the pods, and replication controller ensures that we always have four of them running.</p><div><h3 class="title"><a id="note12"/>Note</h3><p>You can find plenty of usage examples to play with at <a class="ulink" href="https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples">https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples</a>.</p></div><p>This book is too short to cover all the good things you can do with Kubernetes, but we should be seeing more Kubernetes books pop up soon.</p><div><h3 class="title"><a id="note13"/>Note</h3><p>Some other URLs to look at are given here:</p><p>If you are a Mac user, you <a id="id224" class="indexterm"/>can install one of the apps that will set your Kubernetes cluster on your Mac: 1 master x 2 nodes on <a class="ulink" href="https://github.com/rimusz/coreos-osx-gui-kubernetes-cluster">https://github.com/rimusz/coreos-osx-gui-kubernetes-cluster</a>, and standalone master/node on <a class="ulink" href="https://github.com/rimusz/coreos-osx-gui-kubernetes-solo">https://github.com/rimusz/coreos-osx-gui-kubernetes-solo</a>.</p><p>Other<a id="id225" class="indexterm"/> guides to<a id="id226" class="indexterm"/> Kubernetes on CoreOS are available at <a class="ulink" href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/coreos.md">https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/coreos.md</a>.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec51"/>Tectonic – CoreOS and Kubernetes combined for a commercial implementation</h1></div></div></div><p>Tectonic (<a class="ulink" href="http://tectonic.com">http://tectonic.com</a>) is a commercial CoreOS distribution with a combined CoreOS and Kubernetes stack. It can be <a id="id227" class="indexterm"/>used by businesses of any size.</p><p>Tectonic is prepackaged with all the <a id="id228" class="indexterm"/>open source components of CoreOS and<a id="id229" class="indexterm"/> Kubernetes, and adds some more commercial features:</p><div><ul class="itemizedlist"><li class="listitem">Management console/UI for workflows and dashboards</li><li class="listitem">Corporate SSO integration</li><li class="listitem">Quay-integrated container registry for building and sharing Linux containers</li><li class="listitem">Tools for automation of container deployments</li><li class="listitem">Customized rolling updates</li></ul></div><p>It can run in public clouds or on-premise.</p><p>Its management console is simple and easy to use:</p><div><img src="img/image00195.jpeg" alt="Tectonic – CoreOS and Kubernetes combined for a commercial implementation"/></div><p style="clear:both; height: 1em;"> </p><p>In the preceding screenshot, we have a visualization of <a id="id230" class="indexterm"/>our <strong>Replication controllers</strong> (<strong>RC</strong>). On the left-hand side, you can' see each RC with the labels will assign to pods as they're instantiated. Below the name of the RC, you'll see a list of all running pods that match the same label queries.</p><div><img src="img/image00196.jpeg" alt="Tectonic – CoreOS and Kubernetes combined for a commercial implementation"/></div><p style="clear:both; height: 1em;"> </p><p>The preceding<a id="id231" class="indexterm"/> screenshot shows us the <strong>elasticsearch</strong> replication controller state, which labels are used there, and pod volumes.</p><p>Tectonic aims to<a id="id232" class="indexterm"/> provide an easily container deployment solution, and companies can begin seeing its benefits very quickly of using containers in enterprise.</p></div>
<div><div><div><div><h1 class="title"><a id="ch10lvl1sec52"/>Summary</h1></div></div></div><p>In this chapter, we overviewed Google Kubernetes and covered what is about, its main components, and its CoreOS commercial implementation.</p><p>We hope that this book will equip you with all the information you need to leverage the power of CoreOS and the related containers, and help you develop effective computing networks. Thank you for reading it!</p></div></body></html>