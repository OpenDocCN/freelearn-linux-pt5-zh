<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Building a Production Cluster</h1></div></div></div><p>In the previous chapter, we saw how to deploy code on a remote test/staging cluster, and set up the Docker builder and Private Docker Registry server. In this chapter, we will cover how to set up a production cluster on Google Cloud Compute Engine and how to deploy code from the Staging server using the Docker builder and Docker private registry.</p><p>We will cover the following topics in this chapter:</p><div><ul class="itemizedlist"><li class="listitem">Bootstrapping a remote Production cluster to GCE</li><li class="listitem">Deploying code on the Production cluster servers</li><li class="listitem">An overview of the setup of Dev/Test/Staging/Production </li><li class="listitem">PaaS based on <code class="literal">fleet</code></li><li class="listitem">Another cloud alternative to run CoreOS clusters</li></ul></div><div><div><div><div><h1 class="title"><a id="ch07lvl1sec34"/>Bootstrapping a remote production cluster on GCE</h1></div></div></div><p>We have<a id="id131" class="indexterm"/> already seen how to set up our test/staging environment on Google Cloud. Here, we will use a very similar approach to set up our Production<a id="id132" class="indexterm"/> cluster, where the usually tested code is run in a stable environment with more powerful and high-availability servers.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec26"/>Setting up the production cluster</h2></div></div></div><p>Before we install the cluster, let's see<a id="id133" class="indexterm"/> what folders/files we have there; type the following commands in your terminal:</p><div><pre class="programlisting">
<strong>$ cd coreos-essentials-book/chapter7/Production_Cluster</strong>
<strong>$ ls</strong>
<strong>cloud-config                     </strong>
<strong>create_cluster_workers.sh       </strong>
<strong>fleet  </strong>
<strong>files                         </strong>
<strong>create_cluster_control.sh       </strong>
<strong>install_fleetctl_and_scripts.sh</strong>
<strong>settings</strong>
</pre></div><p>As you can see, we have folders/files that are very similar to what we used to set up the Test/Staging Cluster.</p><div><h3 class="title"><a id="note08"/>Note</h3><p>We are not going to print all the scripts and files that we are going to use, as it will take up half the chapter just for that. Take a look at the scripts and other files. They are very well-commented, and it should not be too difficult to understand them.</p></div><p>When you are done<a id="id134" class="indexterm"/> with this chapter, you can adopt the provided scripts to bootstrap your clusters. As before, update the <code class="literal">settings</code> file with your Google Cloud project ID and the zone where you want CoreOS instances to be deployed:</p><div><ol class="orderedlist arabic"><li class="listitem">Next let's install our control server, which is our Production cluster's etcd node:<div><pre class="programlisting">
<strong>$ ./create_cluster_control.sh</strong>
</pre></div><div><img src="img/image00159.jpeg" alt="Setting up the production cluster"/></div><p style="clear:both; height: 1em;"> </p><p>We've just created our new Production cluster's control node.</p><p>For learning purposes, we used only one <code class="literal">etcd</code> server. For a real Production Cluster, a minimum of three <code class="literal">etcd</code> servers is recommended, and each server should be located in a different cloud availability zone.</p><p>As the Production cluster setup scripts are very similar to the Test/Staging cluster scripts, we are not going to analyze them here.</p></li><li class="listitem">The next step is to create our Production cluster workers:<div><pre class="programlisting">
<strong>$ ./create_cluster_workers.sh</strong>
</pre></div><p>You should see the following output:</p><div><img src="img/image00160.jpeg" alt="Setting up the production cluster"/></div><p style="clear:both; height: 1em;"> </p><p>For the other<a id="id135" class="indexterm"/> cluster workers, you should see something like this:</p><div><img src="img/image00161.jpeg" alt="Setting up the production cluster"/></div><p style="clear:both; height: 1em;"> </p><div><h3 class="title"><a id="note09"/>Note</h3><p>Make a note of the workers' external IPs; we will need them later. Of course, you can always check them out at the Google Cloud Developers Console.</p></div><p>So, we've got our production servers set up on GCE. If you check out the Google Cloud Developers Console for Compute Engine Instances, you should see a list of servers, like this:</p><div><img src="img/image00162.jpeg" alt="Setting up the production cluster"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Now let's install all the<a id="id136" class="indexterm"/> necessary scripts to access our cluster:<div><pre class="programlisting">
<strong>$ ./install_fleetctl_and_scripts.sh</strong>
</pre></div><p>This script will create a new folder called <code class="literal">~/coreos-prod-gce</code>, which will have the same folders as our Test/Staging cluster:</p><div><ul class="itemizedlist"><li class="listitem">The <code class="literal">bin</code> folder will have scripts for accessing cluster machines and the <code class="literal">set_cluster_access.sh</code> script</li><li class="listitem">The <code class="literal">fleet - website1.service fleet</code> unit file</li></ul></div></li><li class="listitem">Let's run <code class="literal">set_cluster_access.sh</code>:<div><pre class="programlisting">
<strong>$ cd ~/coreos-prod-gce/bin</strong>
<strong>$ ./set_cluster_access.sh</strong>
</pre></div><div><img src="img/image00163.jpeg" alt="Setting up the production cluster"/></div><p style="clear:both; height: 1em;"> </p></li></ol><div></div><p>Perfect! Our production cluster is up-and-running!</p><p>As you can see, we have<a id="id137" class="indexterm"/> three servers there, one for the <code class="literal">etcd</code> services and two workers to run our website.</p><p>We already have the <code class="literal">website1 fleet</code> unit prepared. Let's install it:</p><div><pre class="programlisting">
<strong>$ cd ~/coreos-prod-gce/fleet</strong>
<strong>$ fleetctl start website1.service</strong>
</pre></div><p>The following screenshot demonstrates the output:</p><div><img src="img/image00164.jpeg" alt="Setting up the production cluster"/></div><p style="clear:both; height: 1em;"> </p><p>Now we are ready to deploy code on our Production servers.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec35"/>Deploying code on production cluster servers</h1></div></div></div><p>In the previous chapters, we saw<a id="id138" class="indexterm"/> how to set up our Test/Staging environment on Google Cloud and deploy our code there, and we did set up our Docker builder and Docker Private Registry server.</p><p>In the next section, we will learn how to deploy code on our Web servers in Production cluster using Docker builder and Docker Private Registry.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec27"/>Setting up the Docker builder server</h2></div></div></div><p>Before we deploy our <a id="id139" class="indexterm"/>code from staging to production, we need to copy the <code class="literal">Dockerfile</code> and the <code class="literal">build.sh</code> and <code class="literal">push.sh</code> files to <a id="id140" class="indexterm"/>our Docker builder.</p><p>To do this, run the following commands:</p><div><pre class="programlisting">
<strong>$ cd coreos-essentials-book/chapter7/Test_Staging_Cluster/</strong>
<strong>$ ./install_website1_2_dbuilder.sh</strong>
</pre></div><p>You should see something like what is shown in the following screenshot:</p><div><img src="img/image00165.jpeg" alt="Setting up the Docker builder server"/></div><p style="clear:both; height: 1em;"> </p><p>So let's check out what happened—that is, what that script has done. It has copied three files to Docker builder server:</p><div><ol class="orderedlist arabic"><li class="listitem">This will be used to build our production Docker image:<div><pre class="programlisting">
<strong>$ cat Dockerfile:</strong>
<strong>FROM nginx:latest</strong>
<strong>## add website code</strong>
<strong>ADD website1 /usr/share/nginx/html</strong>
<strong>EXPOSE 80</strong>
</pre></div></li><li class="listitem">The following is the Docker image building script:<div><pre class="programlisting">
<strong>$ cat build.sh</strong>
<strong>docker build --rm -t 10.200.4.1:5000/website1 .</strong>
</pre></div></li><li class="listitem">Here is the Docker image push script to our Private Docker Registry:<div><pre class="programlisting">
<strong>$ cat push.sh</strong>
<strong>docker push 10.200.4.1:5000/website1</strong>
</pre></div></li></ol><div></div><p>Okay, we have prepared our Docker builder server. Let's start cracking the code deployment on the production servers.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec28"/>Deploying code on production servers</h2></div></div></div><p>To deploy code on our <a id="id141" class="indexterm"/>production web servers, run the following command:</p><div><pre class="programlisting">
<strong>$ cd ~/coreos-prod-gce</strong>
</pre></div><p>When we built the production cluster, the install script installed the <code class="literal">deploy_2_production_website1.sh</code> script. Let's run it, and you should see an output similar to the next two screenshots:</p><div><pre class="programlisting">
<strong>$ ./deploy_2_production_website1.sh</strong>
</pre></div><div><img src="img/image00166.jpeg" alt="Deploying code on production servers"/></div><p style="clear:both; height: 1em;"> </p><p>You should also see something like this:</p><div><img src="img/image00167.jpeg" alt="Deploying code on production servers"/></div><p style="clear:both; height: 1em;"> </p><p>Now open <code class="literal">prod-web1</code> and <code class="literal">prod-web2</code> in your browser using their external IPs, and you should see something like what is <a id="id142" class="indexterm"/>shown in the following screenshot:</p><div><img src="img/image00168.jpeg" alt="Deploying code on production servers"/></div><p style="clear:both; height: 1em;"> </p><p>We see exactly the same web page as on our staging server.</p><p>Awesome! Our <a id="id143" class="indexterm"/>deployment to production servers is working fine!</p><p>Let's see what happened there.</p><p>Run the following command:</p><div><pre class="programlisting">
<strong>$ cat deploy_2_production_website1.sh</strong>
<strong>#!/bin/bash</strong>
<strong># Build docker container for website1</strong>
<strong># and release it</strong>

<strong>function pause(){</strong>
<strong>read -p "$*"</strong>
<strong>}</strong>

<strong># Test/Staging cluster</strong>
<strong>## Fetch GC settings</strong>
<strong># project and zone</strong>
<strong>project=$(cat ~/coreos-tsc-gce/settings | grep project= | head -1 | cut -f2 -d"=")</strong>
<strong>zone=$(cat ~/coreos-tsc-gce/settings | grep zone= | head -1 | cut -f2 -d"=")</strong>
<strong>cbuilder1=$(gcloud compute instances list --project=$project | grep -v grep | grep tsc-registry-cbuilder1 | awk {'print $5'})</strong>

<strong># create a folder on docker builder</strong>
<strong>echo "Entering dbuilder docker container"</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no  core@$cbuilder1 "/usr/bin/docker exec docker-builder /bin/bash -c 'sudo mkdir -p /data/website1 &amp;&amp; sudo chmod -R 777 /data/website1'"</strong>

<strong># sync files from staging to docker builder</strong>
<strong>echo "Deploying code to docker builder server !!!"</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$cbuilder1 '/usr/bin/docker exec docker-builder rsync -e "ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" -avzW --delete core@10.200.3.1:/home/core/share/nginx/html/ /data/website1'</strong>
<strong># change folder permisions to 755</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no  core@$cbuilder1 "/usr/bin/docker exec docker-builder /bin/bash -c 'sudo chmod -R 755 /data/website1'"</strong>

<strong>echo "Build new docker image and push to registry!!!"</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$cbuilder1 "/usr/bin/docker exec docker-builder /bin/bash -c 'cd /data &amp;&amp; ./build.sh &amp;&amp; ./push.sh'"</strong>
<strong>##</strong>

<strong># Production cluster</strong>
<strong>## Fetch GC settings</strong>
<strong># project and zone</strong>
<strong>project2=$(cat ~/coreos-prod-gce/settings | grep project= | head -1 | cut -f2 -d"=")</strong>

<strong># Get servers IPs</strong>
<strong>control1=$(gcloud compute instances list --project=$project2 | grep -v grep | grep prod-control1 | awk {'print $5'})</strong>
<strong>web1=$(gcloud compute instances list --project=$project2 | grep -v grep | grep prod-web1 | awk {'print $5'})</strong>
<strong>web2=$(gcloud compute instances list --project=$project2 | grep -v grep | grep prod-web2 | awk {'print $5'})</strong>

<strong>echo "Pull new docker image on web1"</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$web1 docker pull 10.200.4.1:5000/website1</strong>
<strong>echo "Pull new docker image on web2"</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$web2 docker pull 10.200.4.1:5000/website1</strong>

<strong>echo "Restart fleet unit"</strong>
<strong># restart fleet unit</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$control1 fleetctl stop website1.service</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$control1 fleetctl start website1.service</strong>
<strong>#</strong>
<strong>sleep 5</strong>
<strong>echo " "</strong>
<strong>echo "List Production cluster fleet units"</strong>
<strong>ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no core@$control1 fleetctl list-units</strong>

<strong>echo " "</strong>
<strong>echo "Finished !!!"</strong>
<strong>pause 'Press [Enter] key to continue...'</strong>
</pre></div><p>The steps for<a id="id144" class="indexterm"/> deployment to production are as follows:</p><div><ol class="orderedlist arabic"><li class="listitem">Creates a folder called <code class="literal">/data/website1</code> on the Docker builder server.</li><li class="listitem">Use <code class="literal">rsync</code> via the docker-builder container to sync files from <code class="literal">Staging1</code> to the Docker builder server.</li><li class="listitem">Run the <code class="literal">build.sh</code> script via the docker-builder container.</li><li class="listitem">Push a new Docker image to the Private Docker Registry.</li><li class="listitem">Pull a new <a id="id145" class="indexterm"/>Docker image onto the <code class="literal">Prod-web1</code> and <code class="literal">prod-web2</code> servers.</li><li class="listitem">Restart the <code class="literal">website1.service fleet</code> unit via the Production cluster's <code class="literal">etcd</code> server.</li><li class="listitem">And voilà! We have completed the release of a new website to our production cluster.</li></ol><div></div><div><h3 class="title"><a id="note10"/>Note</h3><p>
<strong>One thing to note</strong>
</p><p>We are using the docker-builder container to sync and build our Docker container.</p><p>This can be done directly on the Docker builder server, but using the container allows us to add any tools required to the container, which gives an advantage. If we need to replicate the Docker Builder server or replace it with a new one, we just have to install our docker-builder container to get things working again.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec36"/>An overview of the Dev/Test/Staging/Production setup</h1></div></div></div><p>Let's overview<a id="id146" class="indexterm"/> the advantages of performing the setup of the Dev/Test/Staging/Production environment in the way we did it:</p><div><ul class="itemizedlist"><li class="listitem">Local code development via the CoreOS VM decreases your testing time, as all changes get pushed to <a id="id147" class="indexterm"/>a local server on your VirtualBox VM.</li><li class="listitem">Cloud-based Test/Staging is good to use for team-shared projects using GitHub or Bitbucket. It also has, in our case, <code class="literal">nginx</code> containers running as our web servers, and the code is used via the attached <code class="literal">host</code> folder. This significantly speeds up code deployment from the test and staging <code class="literal">git</code> branches, as the Docker container does not need to be rebuilt each time we pull code from the <code class="literal">git</code> repository.</li><li class="listitem">For production, a separate cluster is used. It is good practice to separate development and production clusters.</li><li class="listitem">For production, we use the same Docker base image as that on the test/staging servers, but we build a new Docker image, with the code baked inside. So, we can, for example, auto-scale our website to as many servers as we want by reusing the same Docker image on all the servers, and all the servers will be running exactly the same code.</li><li class="listitem">For Docker image building and our Private Docker Registry, we use the same server, which is accessible only via the internal GCE IP. If you want to expose the Docker Registry to external access, for example, the <code class="literal">nginx</code> container with<a id="id148" class="indexterm"/> authentication should be put in front of the Docker registry to make it secure.</li><li class="listitem">This is only one way <a id="id149" class="indexterm"/>of setting up the Dev/Test/Staging/Production environment. Each setup scenario is different, but such setup should put you on the right path.</li></ul></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec37"/>PaaS based on fleet</h1></div></div></div><p>In this chapter and in previous chapters, we explained how to use fleet to deploy our different services on our clusters. Fleet is a powerful and easy-to-use low-level cluster manager that controls <code class="literal">systemd</code> at<a id="id150" class="indexterm"/> the cluster level. However, it lacks a web UI, easy orchestration<a id="id151" class="indexterm"/> tools, and so on, so this is where PAZ, the nice PaaS, steps in to help us out.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec29"/>Deploying services using PAZ</h2></div></div></div><p>The website at <a class="ulink" href="http://www.paz.sh">http://www.paz.sh</a> has a very<a id="id152" class="indexterm"/> nice and user-friendly web UI, which makes it much easier to set up a <a id="id153" class="indexterm"/>CoreOS cluster. PAZ also has an API that you can use if you want to automate things via scripts.</p><p>Through its dashboard, you can add and edit your services, check the status of the cluster (viewed by host or by unit), and view monitoring information and logs for the cluster.</p><div><img src="img/image00169.jpeg" alt="Deploying services using PAZ"/></div><p style="clear:both; height: 1em;"> </p><p>It fully leverages <code class="literal">fleet</code> to orchestrate services across the machines in a cluster. It is built in <code class="literal">Node.js</code> and all its<a id="id154" class="indexterm"/> services run as Docker containers.</p><p>The following pointers explain<a id="id155" class="indexterm"/> how PAZ works:</p><div><ul class="itemizedlist"><li class="listitem">Users can declare services in the UI</li><li class="listitem">Services get stored in the service directory</li><li class="listitem">The scheduler is the service that deploys things</li><li class="listitem">You can manually tell the scheduler to deploy, or have it triggered at the end of your CI process</li><li class="listitem">Paz supports the post-push Docker Hub web hooks</li><li class="listitem">By using <code class="literal">etcd</code> and service discovery, your containers are linked together</li></ul></div><p>Of course, it will keep evolving and getting new features but, at the time of writing this book, only the services in the preceding list were available.</p><p>Giving a complete overview of PAZ is beyond the scope of this book, but you can read more about the Paz<a id="id156" class="indexterm"/> architecture at <a class="ulink" href="http://paz.readme.io/v1.0/docs/paz-architecture">http://paz.readme.io/v1.0/docs/paz-architecture</a>.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec38"/>Another cloud alternative for running CoreOS clusters</h1></div></div></div><p>To bootstrap our Test/Staging<a id="id157" class="indexterm"/> and Production clusters, we used the Google Cloud Compute Engine's virtual instances, but sometimes you might want to run your servers on real servers (bare-metal servers) that are not stored at your premises.</p><p>There are a number of different bare-metal server providers out there, but one that caught my eye was <a class="ulink" href="https://www.packet.net">https://www.packet.net</a>.</p><p>I recently came across these while I was investigating hosting solutions for CoreOS and containers. They're interesting in the sense that, instead of going the typical cloud/hypervisor route, they've created a true, on-demand, and bare-metal cloud solution. I'm able to spin up a CoreOS server from scratch in less than 5 minutes, and they have a pretty comprehensive API and accompanying documentation.</p><p>Here's an example of a packet project dashboard:</p><div><img src="img/image00170.jpeg" alt="Another cloud alternative for running CoreOS clusters"/></div><p style="clear:both; height: 1em;"> </p></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec39"/>Summary</h1></div></div></div><p>In this chapter, we saw how to set up a Production cluster and deploy our code staging using the Docker builder and private Docker registry machines. Finally, we overviewed a PaaS based on <code class="literal">fleet</code>—<code class="literal">Paz.sh</code>.</p><p>In the next chapter, we will overview the CoreOS update strategies and CoreUpdate for our servers. We will also make use of hosted public/private Docker repositories at <a class="ulink" href="https://quay.io">https://quay.io</a> and the self-hosted CoreOS Enterprise Registry.</p></div></body></html>