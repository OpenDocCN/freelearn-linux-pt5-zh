- en: Chapter 7. Building a Production Cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we saw how to deploy code on a remote test/staging
    cluster, and set up the Docker builder and Private Docker Registry server. In
    this chapter, we will cover how to set up a production cluster on Google Cloud
    Compute Engine and how to deploy code from the Staging server using the Docker
    builder and Docker private registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping a remote Production cluster to GCE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying code on the Production cluster servers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the setup of Dev/Test/Staging/Production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PaaS based on `fleet`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another cloud alternative to run CoreOS clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrapping a remote production cluster on GCE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already seen how to set up our test/staging environment on Google Cloud.
    Here, we will use a very similar approach to set up our Production cluster, where
    the usually tested code is run in a stable environment with more powerful and
    high-availability servers.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the production cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we install the cluster, let''s see what folders/files we have there;
    type the following commands in your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we have folders/files that are very similar to what we used
    to set up the Test/Staging Cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We are not going to print all the scripts and files that we are going to use,
    as it will take up half the chapter just for that. Take a look at the scripts
    and other files. They are very well-commented, and it should not be too difficult
    to understand them.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you are done with this chapter, you can adopt the provided scripts to
    bootstrap your clusters. As before, update the `settings` file with your Google
    Cloud project ID and the zone where you want CoreOS instances to be deployed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next let''s install our control server, which is our Production cluster''s
    etcd node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Setting up the production cluster](img/image00159.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: We've just created our new Production cluster's control node.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For learning purposes, we used only one `etcd` server. For a real Production
    Cluster, a minimum of three `etcd` servers is recommended, and each server should
    be located in a different cloud availability zone.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As the Production cluster setup scripts are very similar to the Test/Staging
    cluster scripts, we are not going to analyze them here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is to create our Production cluster workers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Setting up the production cluster](img/image00160.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'For the other cluster workers, you should see something like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Setting up the production cluster](img/image00161.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Make a note of the workers' external IPs; we will need them later. Of course,
    you can always check them out at the Google Cloud Developers Console.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'So, we''ve got our production servers set up on GCE. If you check out the Google
    Cloud Developers Console for Compute Engine Instances, you should see a list of
    servers, like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Setting up the production cluster](img/image00162.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Now let''s install all the necessary scripts to access our cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This script will create a new folder called `~/coreos-prod-gce`, which will
    have the same folders as our Test/Staging cluster:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `bin` folder will have scripts for accessing cluster machines and the `set_cluster_access.sh`
    script
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `fleet - website1.service fleet` unit file
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s run `set_cluster_access.sh`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Setting up the production cluster](img/image00163.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Perfect! Our production cluster is up-and-running!
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we have three servers there, one for the `etcd` services and
    two workers to run our website.
  prefs: []
  type: TYPE_NORMAL
- en: 'We already have the `website1 fleet` unit prepared. Let''s install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot demonstrates the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting up the production cluster](img/image00164.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now we are ready to deploy code on our Production servers.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying code on production cluster servers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we saw how to set up our Test/Staging environment
    on Google Cloud and deploy our code there, and we did set up our Docker builder
    and Docker Private Registry server.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how to deploy code on our Web servers in
    Production cluster using Docker builder and Docker Private Registry.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the Docker builder server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we deploy our code from staging to production, we need to copy the `Dockerfile`
    and the `build.sh` and `push.sh` files to our Docker builder.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see something like what is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Setting up the Docker builder server](img/image00165.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'So let''s check out what happened—that is, what that script has done. It has
    copied three files to Docker builder server:'
  prefs: []
  type: TYPE_NORMAL
- en: 'This will be used to build our production Docker image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is the Docker image building script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is the Docker image push script to our Private Docker Registry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Okay, we have prepared our Docker builder server. Let's start cracking the code
    deployment on the production servers.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying code on production servers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To deploy code on our production web servers, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'When we built the production cluster, the install script installed the `deploy_2_production_website1.sh`
    script. Let''s run it, and you should see an output similar to the next two screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Deploying code on production servers](img/image00166.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'You should also see something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying code on production servers](img/image00167.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now open `prod-web1` and `prod-web2` in your browser using their external IPs,
    and you should see something like what is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying code on production servers](img/image00168.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We see exactly the same web page as on our staging server.
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! Our deployment to production servers is working fine!
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what happened there.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The steps for deployment to production are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Creates a folder called `/data/website1` on the Docker builder server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `rsync` via the docker-builder container to sync files from `Staging1` to
    the Docker builder server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `build.sh` script via the docker-builder container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push a new Docker image to the Private Docker Registry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pull a new Docker image onto the `Prod-web1` and `prod-web2` servers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restart the `website1.service fleet` unit via the Production cluster's `etcd`
    server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And voilà! We have completed the release of a new website to our production
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**One thing to note**'
  prefs: []
  type: TYPE_NORMAL
- en: We are using the docker-builder container to sync and build our Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: This can be done directly on the Docker builder server, but using the container
    allows us to add any tools required to the container, which gives an advantage.
    If we need to replicate the Docker Builder server or replace it with a new one,
    we just have to install our docker-builder container to get things working again.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of the Dev/Test/Staging/Production setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s overview the advantages of performing the setup of the Dev/Test/Staging/Production
    environment in the way we did it:'
  prefs: []
  type: TYPE_NORMAL
- en: Local code development via the CoreOS VM decreases your testing time, as all
    changes get pushed to a local server on your VirtualBox VM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud-based Test/Staging is good to use for team-shared projects using GitHub
    or Bitbucket. It also has, in our case, `nginx` containers running as our web
    servers, and the code is used via the attached `host` folder. This significantly
    speeds up code deployment from the test and staging `git` branches, as the Docker
    container does not need to be rebuilt each time we pull code from the `git` repository.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For production, a separate cluster is used. It is good practice to separate
    development and production clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For production, we use the same Docker base image as that on the test/staging
    servers, but we build a new Docker image, with the code baked inside. So, we can,
    for example, auto-scale our website to as many servers as we want by reusing the
    same Docker image on all the servers, and all the servers will be running exactly
    the same code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Docker image building and our Private Docker Registry, we use the same server,
    which is accessible only via the internal GCE IP. If you want to expose the Docker
    Registry to external access, for example, the `nginx` container with authentication
    should be put in front of the Docker registry to make it secure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is only one way of setting up the Dev/Test/Staging/Production environment.
    Each setup scenario is different, but such setup should put you on the right path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PaaS based on fleet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter and in previous chapters, we explained how to use fleet to deploy
    our different services on our clusters. Fleet is a powerful and easy-to-use low-level
    cluster manager that controls `systemd` at the cluster level. However, it lacks
    a web UI, easy orchestration tools, and so on, so this is where PAZ, the nice
    PaaS, steps in to help us out.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying services using PAZ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The website at [http://www.paz.sh](http://www.paz.sh) has a very nice and user-friendly
    web UI, which makes it much easier to set up a CoreOS cluster. PAZ also has an
    API that you can use if you want to automate things via scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Through its dashboard, you can add and edit your services, check the status
    of the cluster (viewed by host or by unit), and view monitoring information and
    logs for the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying services using PAZ](img/image00169.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It fully leverages `fleet` to orchestrate services across the machines in a
    cluster. It is built in `Node.js` and all its services run as Docker containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following pointers explain how PAZ works:'
  prefs: []
  type: TYPE_NORMAL
- en: Users can declare services in the UI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services get stored in the service directory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scheduler is the service that deploys things
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can manually tell the scheduler to deploy, or have it triggered at the end
    of your CI process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paz supports the post-push Docker Hub web hooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using `etcd` and service discovery, your containers are linked together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, it will keep evolving and getting new features but, at the time of
    writing this book, only the services in the preceding list were available.
  prefs: []
  type: TYPE_NORMAL
- en: Giving a complete overview of PAZ is beyond the scope of this book, but you
    can read more about the Paz architecture at [http://paz.readme.io/v1.0/docs/paz-architecture](http://paz.readme.io/v1.0/docs/paz-architecture).
  prefs: []
  type: TYPE_NORMAL
- en: Another cloud alternative for running CoreOS clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To bootstrap our Test/Staging and Production clusters, we used the Google Cloud
    Compute Engine's virtual instances, but sometimes you might want to run your servers
    on real servers (bare-metal servers) that are not stored at your premises.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of different bare-metal server providers out there, but one
    that caught my eye was [https://www.packet.net](https://www.packet.net).
  prefs: []
  type: TYPE_NORMAL
- en: I recently came across these while I was investigating hosting solutions for
    CoreOS and containers. They're interesting in the sense that, instead of going
    the typical cloud/hypervisor route, they've created a true, on-demand, and bare-metal
    cloud solution. I'm able to spin up a CoreOS server from scratch in less than
    5 minutes, and they have a pretty comprehensive API and accompanying documentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a packet project dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Another cloud alternative for running CoreOS clusters](img/image00170.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to set up a Production cluster and deploy our code
    staging using the Docker builder and private Docker registry machines. Finally,
    we overviewed a PaaS based on `fleet`—`Paz.sh`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will overview the CoreOS update strategies and CoreUpdate
    for our servers. We will also make use of hosted public/private Docker repositories
    at [https://quay.io](https://quay.io) and the self-hosted CoreOS Enterprise Registry.
  prefs: []
  type: TYPE_NORMAL
