<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Puppet – Now You Are the Puppet Master</h1></div></div></div><p>Puppet from Puppet Labs allows for central administration of your Linux devices. The central Puppet <a class="indexterm" id="id409"/>server is known as the Puppet master, continuing the analogy with puppetry. This master device certainly allows you to control servers and desktops (nodes in Puppet terms) from a single device, albeit not in the marionette style with pieces of a string. The Puppet master specifies the desired state to each node, and every 30 minutes, the node connects to the Puppet master and sends facts about its resources; if it does not meet the desired state, then the node will fix itself to meet it. During the course of this chapter, we will investigate the Puppet configuration including:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Installing the Puppet master</strong>: We will install and configure the Puppet master from the Puppet Labs repository. The Puppet master will act as the central configuration server and store the desired configuration state for each node.</li><li class="listitem" style="list-style-type: disc"><strong>Puppet resource</strong>: We will use the <code class="literal">puppet resource</code> command to manually manage<a class="indexterm" id="id410"/> resources on the node. Resources represent the fundamental building blocks of a desired state and can include files, users, services, cron jobs, and software packages on the node.</li><li class="listitem" style="list-style-type: disc"><strong>Managing packages, services, and file</strong>s: These three resources represent the main trifecta in Puppet management, and if we can manage these, we can pretty much manage the node. We will create the resource declarations in manifest files and test them on local and remote puppet agents.</li></ul></div><div><div><div><div><h1 class="title"><a id="ch09lvl1sec50"/>Installing the Puppet master</h1></div></div></div><p>As we <a class="indexterm" id="id411"/>know with many services that have to be installed on CentOS, we have to make sure that the plumbing is correct before we start. The plumbing, in the case of the Puppet master, means:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">TCP port <code class="literal">8140</code> must be open through the firewall</li><li class="listitem" style="list-style-type: disc">The<a class="indexterm" id="id412"/> Puppet master should be resolvable by the hostname <code class="literal">puppet</code> by DNS or local hosts files</li><li class="listitem" style="list-style-type: disc">Time should be synchronized</li><li class="listitem" style="list-style-type: disc">A configured Puppet Labs yum repository</li></ul></div><p>I've detailed these in the following sections.</p><div><div><div><div><h2 class="title"><a id="ch09lvl2sec53"/>Configuring the firewall</h2></div></div></div><p>I am not <a class="indexterm" id="id413"/>using a host-based firewall in the demonstration<a class="indexterm" id="id414"/> machine. This may not be the case on your systems, and if <a class="indexterm" id="id415"/>you are using a firewall, you will need to allow TCP port <code class="literal">8140</code> through the INPUT chain. The status of the firewall can be checked with the following command:</p><div><pre class="programlisting">
<strong># iptables -L</strong>
</pre></div><p>This will list the rules that are in place and the default policy. If there are no rules in place and the default policy is ACCEPT, then you will not have firewall-related issues, and you can relax.</p></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec54"/>DNS</h2></div></div></div><p>Puppet <a class="indexterm" id="id416"/>agents are running on each client or node and will try and <a class="indexterm" id="id417"/>communicate with the Puppet master using the default hostname, <code class="literal">puppet</code>. This can be changed in the <code class="literal">/etc/puppet.conf</code> file. This change will need to be implemented on each agent so it is often the easiest way to create an ADDRESS record or CNAME record in the local DNS, which can resolve the host puppet to the IP address of your desired Puppet master host. In the demonstration lab, I have the correct CNAME record in place. Using the <code class="literal">ping</code> command, we can see that the hostname is resolvable, and the output is shown in the following screenshot:</p><div><img alt="DNS" src="img/5920OS_09_01.jpg"/></div></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec55"/>Network Time Protocol</h2></div></div></div><p>If you have not<a class="indexterm" id="id418"/> already configured the time on your Puppet master server <a class="indexterm" id="id419"/>and agent nodes, then you should do so using the <strong>Network Time Protocol</strong> (<strong>NTP</strong>). This will ensure that they all share the same accurate time. Accurate time is required across all devices, as the Puppet master will act as a certificate server issuing certificates to trusted nodes, and the timestamp on the certificate cannot be in the future. In setting up NTP on the Puppet master, we will first synchronize the time to an NTP server and then configure regular time updates using NTP and entries stored within the <code class="literal">/etc/ntp.conf</code> file, as follows:</p><div><pre class="programlisting">
<strong># ntpdate uk.pool.ntp.org</strong>
</pre></div><p>The previous command does a single, one-off update with a UK-based NTP server. This sets the time so that regular updates may take place. If this is not set, then it is possible that the time will not be synchronized as the NTP client must be within 1,000 seconds of the NTP server for regular updates to take place. We can now start the NTP service and configure it for autostart. If we do not make any changes to the configuration file, <code class="literal">/etc/ntp.conf</code>, then time will synchronize with servers from the NTP pool. If you have a local time server already up and running on your network, then it will be worthwhile to use that device as the time source as follows:</p><div><pre class="programlisting">
<strong># service ntpd start</strong>
<strong># chkconfig ntpd on</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec56"/>The Puppet lab repository</h2></div></div></div><p>The Puppet master<a class="indexterm" id="id420"/> is not available in the standard <a class="indexterm" id="id421"/>CentOS repositories, nor unfortunately, the EPEL repositories, which <a class="indexterm" id="id422"/>we have already configured. This requires us to add the Puppet Labs software repositories. These repositories will provide the latest Puppet agent and master software. The Puppet agent is required on all nodes and the master software on the server. We will create the YUM repository for Puppet directly by installing the RPM from a web URL. The RPM will define only the repository file in <code class="literal">/etc/yum.repos.d</code>.</p><div><pre class="programlisting">
<strong>#  rpm -ivh http://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm</strong>
</pre></div><p>This will <a class="indexterm" id="id423"/>complete quickly, as the only file that it <a class="indexterm" id="id424"/>needs to create is the repository definition. With the repository set, we are now ready to install the Puppet master. The following command will install the Puppet master and agent to the latest version available from the Puppet Labs repositories:</p><div><pre class="programlisting">
<strong># yum install puppet-server</strong>
</pre></div><p>As always, we should start the service and enable it for autostart. When this is done, we can use the <a class="indexterm" id="id425"/>
<code class="literal">netstat</code> command to show that the Puppet master is listening on the TCP port <code class="literal">8140</code>:</p><div><pre class="programlisting">
<strong># service puppetmaster start</strong>
<strong># chkconfig puppetmaster on</strong>
<strong># netstat -antl | grep :8140</strong>
</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch09lvl1sec51"/>Puppet resource</h1></div></div></div><p>Versions of Puppet from 2.6 and later (the current release is 3.6) use the single binary puppet with <a class="indexterm" id="id426"/>subcommands for specific tasks. The earlier version had separate binaries for all of the subcommands. In the previous set of commands, we used the traditional CentOS syntax to start the Puppet master and then to enable the service for autostart; we could achieve the same result using the <code class="literal">/usr/bin/puppet</code> command along with the <code class="literal">resource</code> subcommand:</p><div><pre class="programlisting">
<strong># puppet resource Service puppetmaster enable=true ensure=running</strong>
</pre></div><p>With this command, we direct our attention to the <code class="literal">puppetmaster</code> service, enable it for autostart (<code class="literal">enable=true</code>), and start it if required (<code class="literal">ensure=running</code>). This represents the very essence of how Puppet works. Of course, to manage many clients, we will create manifest files with similar resource rules to enforce the desired state. In itself though, we will <a class="indexterm" id="id427"/>configure the desired state of the node with the use of the <code class="literal">puppet resource</code> command.</p><p>Along with setting the desired state, we can view the state of all services or a single named service using very similar commands; the following are two such commands; the first command will display all services, and the second command will display only the <code class="literal">puppetmaster</code> service:</p><div><pre class="programlisting">
<strong># puppet resource Service</strong>
<strong># puppet resource Service puppetmaster</strong>
</pre></div><p>The output from the command specific to the <code class="literal">puppetmaster</code> service is shown in the following screen capture:</p><div><img alt="Puppet resource" src="img/5920OS_09_02.jpg"/></div><p>As <a class="indexterm" id="id428"/>mentioned earlier in the introduction to this chapter, the three main resources that we manage with Puppet include:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Service</li><li class="listitem" style="list-style-type: disc">Files</li><li class="listitem" style="list-style-type: disc">Packages</li></ul></div><p>Along with these main resources, we have others, which include the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Users</li><li class="listitem" style="list-style-type: disc">Groups</li><li class="listitem" style="list-style-type: disc">Cron jobs</li><li class="listitem" style="list-style-type: disc">Notify</li><li class="listitem" style="list-style-type: disc">Yumrepo</li><li class="listitem" style="list-style-type: disc"><code class="literal">ssh_authorized_key</code></li><li class="listitem" style="list-style-type: disc">Interface</li></ul></div><p>To gain an understanding of how Puppet can manage these resources, we will work through an example using the <code class="literal">puppet resource</code> command to manually enforce a desired state on our node. Even though the node on which we run the command is the Puppet master, for all intents and purposes, we will only use the client, which is the Puppet agent at this stage. The example we used earlier with puppet resource demonstrates what can be achieved with Puppet before moving the desired state configuration into manifest files on the Puppet master.</p><p>Using puppet resource user, we can ensure that a user account is present on a system, by referencing an account that does not exist, Puppet will create the account and set the given attribute's password. If we need to delete an account, we can use the <code class="literal">ensure=&gt;absent</code> attribute.</p><p>To begin, we must obtain the encrypted password for the new user account. There are different mechanisms that can be used to do this, but here I will use Python from the command line<a class="indexterm" id="id429"/> to generate the password:</p><div><pre class="programlisting">
<strong># python -c 'import crypt; print crypt.crypt("Password1","$5$RA")'</strong>
</pre></div><p>The output from this command will be the SHA-256 password to be used by the new user. We are now ready to use Puppet to create the user:</p><div><pre class="programlisting">
<strong># puppet resource User newuser ensure=present uid='2222' gid='100' home='/home/newuser' managehome=true shell='/bin/bash' password='&lt;encrypted password&gt;'</strong>
</pre></div><div><div><h3 class="title"><a id="tip14"/>Tip</h3><p>Blocks of <a class="indexterm" id="id430"/>code like these that describe the resource are known as <strong>resource declarations</strong>.</p></div></div><p>This will create the user with the set of desired attribute values. The home directory for the user will be created along with the user account. This behavior is controlled with the <code class="literal">managehome</code> attribute; setting this to be <code class="literal">true</code> will create the directory.</p><p>Although we would not want this set manually on all servers, as in this case, we could use a similar method to allow periodic password changes for the root account across all nodes as well as ensure other system accounts exist.</p></div>
<div><div><div><div><h1 class="title"><a id="ch09lvl1sec52"/>Managing packages, services, and files</h1></div></div></div><p>We will move on from this manual configuration and become familiar with Puppet as a central configuration server, whereby we can define settings within manifest files that will be <a class="indexterm" id="id431"/>distributed to the required nodes. To begin this, we <a class="indexterm" id="id432"/>will create the manifest file; these are just text files, and<a class="indexterm" id="id433"/> apply it locally on the Puppet master using <code class="literal">puppet apply</code>. Once we have verified that the manifest is working and enforcing the desired state, we will enlist the clients and see true Puppet automation at work.</p><p>The building <a class="indexterm" id="id434"/>blocks for Puppet start with the resource declarations<a class="indexterm" id="id435"/> that we have already looked at. These declarations <a class="indexterm" id="id436"/>are written to manifest files, which have the extension <code class="literal">.pp</code>. Within the manifest file, resources can be grouped together into classes. A class often represents related resources, such as the <code class="literal">openssh-server</code> package, the <code class="literal">sshd</code> service, and the <code class="literal">/etc/ssh/sshd_config</code> configuration file. It would seem reasonable to group these resources together in a class definition.</p><p>We can view these building blocks by taking a look inside an example manifest file, as shown in the following diagram:</p><div><img alt="Managing packages, services, and files" src="img/5920OS_09_03.jpg"/></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec57"/>Classes</h2></div></div></div><p>Classes are <a class="indexterm" id="id437"/>reusable because a class can be used by multiple node <a class="indexterm" id="id438"/>definitions and are said to be <code class="literal">singleton</code> in the sense that once a given class is used on a node, it can only be used once and cannot be redeclared for that node. The class we have created here is named <code class="literal">ssh</code>. A class has to be first defined and then declared. The following code block is an example of a class definition: </p><div><pre class="programlisting">class web-servers {
  code……
}</pre></div><p>The following example code shows the same class being declared:</p><div><pre class="programlisting">include web-servers</pre></div></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec58"/>Resource definition</h2></div></div></div><p>Resource<a class="indexterm" id="id439"/> definitions, such as what we looked at earlier <a class="indexterm" id="id440"/>for the user resource, do not need to be enclosed within classes; however, related resources are often grouped together by means of the class for ease of assignment to nodes. In this example, we define a file resource and a service resource. The name of the service resource must match the name of the service on the node to which it will be assigned; in the case of CentOS, the OpenSSH server is the <code class="literal">sshd</code> service.</p><p>A resource in Puppet is an instance of a specific resource type. To list all the available types in CentOS, we can use the <code class="literal">describe</code> subcommand:</p><div><pre class="programlisting">
<strong># puppet describe -l</strong>
</pre></div><p>A resource<a class="indexterm" id="id441"/> type has a defined schema that states<a class="indexterm" id="id442"/> which attributes are available. To list the schema details of <a class="indexterm" id="id443"/>a resource type, we can use the <code class="literal">describe</code> subcommand again:</p><div><pre class="programlisting">
<strong># puppet describe -s User</strong>
<strong># puppet describe User</strong>
</pre></div><p>A short description is shown with and without the <code class="literal">-s</code> option; a full listing of the resource type schema is listed. In the previous commands, we display information for the <code class="literal">user</code> resource type.</p><p>Earlier in this chapter, we created a new user account from the command line using <code class="literal">puppet resource</code>. If we needed a system account on many nodes and wished that Puppet provision the account, we can create a <code class="literal">user</code> resource definition within a manifest file similar to the following:</p><div><pre class="programlisting">user { 'puppetuser' :
  ensure =&gt; present,
  uid =&gt; '99',
  gid =&gt; '99',
  shell =&gt; '/bin/false',
  password =&gt; '$5$RA$e7cMcsFNqvFkZrlm62fnzy0vpN2GxrOjzpsLaVQzIc4',
  home =&gt; '/tmp',
  managehome =&gt; false,
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec59"/>Puppet facts</h2></div></div></div><p>In the example manifest we listed earlier, we defined a file resource for the <code class="literal">/etc/motd</code> file. This is displayed when a user logs into the system, be it locally or via a remote SSH connection. The<a class="indexterm" id="id444"/> Puppet agent will compare facts from the node's <a class="indexterm" id="id445"/>configuration to see if it matches the desired state. These facts are<a class="indexterm" id="id446"/> gathered from the machine's configuration using the <code class="literal">/usr/bin/facter</code> command. We can display these facts in the following way:</p><div><pre class="programlisting">
<strong>$ facter</strong>
</pre></div><p>The preceding command will display all the facts, whereas the following command will display just the IP address:</p><div><pre class="programlisting">
<strong>$ facter ipaddress</strong>
</pre></div><p>We can further expand the resource definition using additional attributes for the file and fill out the content with some facts as follows:</p><div><pre class="programlisting">file {'/etc/motd' :
  ensure =&gt; file,
  mode =&gt; 0644,
  content =&gt; "Welcome to TUP
This is a ${operatingsystem}  ${operatingsystemrelease} host with IP ${ipaddress}
",
}</pre></div><p>If this <a class="indexterm" id="id447"/>resource definition was applied to a node, it would ensure<a class="indexterm" id="id448"/> that the file is of the type "file"; rather than a directory, the permission would be set to <code class="literal">rw- r-- r--</code>, and the contents would expand with three variables created from facts. This will create contents similar to the following screenshot:</p><div><img alt="Puppet facts" src="img/5920OS_09_04.jpg"/></div><p>Remember that we only need to create the resource definition once. On the Puppet server, this one definition will then be applied to all the nodes it is assigned to. However, using variables based on facts from each node, we can create unique content for each individual <code class="literal">/etc/motd</code> file.</p></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec60"/>Using include</h2></div></div></div><p>The <code class="literal">include</code> statement declares the use of the class. If we define a class and do not use the <code class="literal">include</code> statement, then none of the resource definitions will be used. The class can be defined <a class="indexterm" id="id449"/>within the same manifest in which it is <a class="indexterm" id="id450"/>declared, but more often, classes are defined in separate manifest files created within the puppet module path. The <code class="literal">modulepath</code> defaults to the <code class="literal">/etc/puppet/modules</code> and <code class="literal">/usr/share/puppet/modules</code> directories. You can view the module path, which is colon delimited, using the following command:</p><div><pre class="programlisting">
<strong># puppet config print modulepath</strong>
</pre></div><p>The output from my CentOS system shows the default settings, as shown in the following screen capture:</p><div><img alt="Using include" src="img/5920OS_09_05.jpg"/></div></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec61"/>Creating and testing manifests</h2></div></div></div><p>Manifests are ASCII text files that have the <code class="literal">.pp</code> extension. These files contain class declarations <a class="indexterm" id="id451"/>and/or resource definitions. Classes are also defined and <a class="indexterm" id="id452"/>declared within manifests; however, as mentioned before, they are often defined in separate manifest files to those where they are declared. This allows for greater modularity of your code. The manifest file can be supplied as a local file and <a class="indexterm" id="id453"/>invoked via the <code class="literal">apply</code> subcommand of Puppet or, more often, from the Puppet master. We will apply the manifest locally using <code class="literal">puppet apply</code>. The file that we will create will be consistent with a client server deployment so that we can reuse the same file once we have tested it locally; for this, we will create the file as <code class="literal">/etc/puppet/manifests/site.pp</code>. Nodes, when connecting to the Puppet master, will look for the <code class="literal">site.pp</code> file for their configuration. The example manifest is shown in the following code:</p><div><pre class="programlisting">class tup {
  file {'/etc/motd' :
  ensure =&gt; file,
  mode =&gt; 0644,
  owner =&gt; 'root',
  group =&gt; 'root',
  content =&gt; "Welcome to TUP
This is a ${operatingsystem}  ${operatingsystemrelease} host with IP ${ipaddress}
",
 }
service {'sshd':
   ensure =&gt; running,
   enable =&gt; true,
 }
package { 'openssh-server' :
    ensure =&gt; installed,
 }
}
include tup</pre></div><p>With the manifest created and saved under <code class="literal">/etc/puppet/manifests/site.pp</code>, we can validate the syntax of the file with the following command:</p><div><pre class="programlisting">
<strong># puppet parser validate  /etc/puppet/manifests/site.pp</strong>
</pre></div><p>If errors can be seen, then we can re-edit the file to correct these errors, and when the output is error free, we can manually apply the file:</p><div><pre class="programlisting">
<strong># puppet apply /etc/puppet/manifests/site.pp</strong>
</pre></div><p>Using<a class="indexterm" id="id454"/> the <a class="indexterm" id="id455"/>
<code class="literal">cat</code> command, we can validate the contents of the <code class="literal">/etc/motd</code> file:</p><div><pre class="programlisting">
<strong>$ cat /etc/motd</strong>
</pre></div><p>If we now<a class="indexterm" id="id456"/> stop the <code class="literal">sshd</code> service and change the permissions of the file, we can see how Puppet ensures a consistent configuration:</p><div><pre class="programlisting">
<strong># service sshd stop</strong>
<strong># chmod 777 /etc/motd</strong>
</pre></div><p>With the changes made, we have diverged from the desired state and can now reapply the manifest; under normal client-server operations, the Puppet agent will check into the server every 30 minutes.</p><div><pre class="programlisting">
<strong># puppet apply /etc/puppet/manifests/site.pp</strong>
</pre></div><p>The output should include notices similar to those in the following screenshot, indicating that the service has been started and the mode has been changed:</p><div><img alt="Creating and testing manifests" src="img/5920OS_09_06.jpg"/></div></div><div><div><div><div><h2 class="title"><a id="ch09lvl2sec62"/>Enrolling remote puppet agents</h2></div></div></div><p>As we saw, Puppet can be effective in maintaining a consistent configuration, but we do not want<a class="indexterm" id="id457"/> to create the manifests on each device<a class="indexterm" id="id458"/> and run the puppet commands manually. To see the real strength of Puppet as a central configuration server, we need to enroll clients and have the puppet agent run as a service. As we mentioned before, the agent will check its desired state every 30 minutes automatically when the agent service is running.</p><p>From a remote CentOS 6.5 system, we will check whether we can resolve the hostname of the Puppet master, using the follow command line:</p><div><pre class="programlisting">
<strong>$ host puppet</strong>
</pre></div><p>As seen before, we will need to ensure that we have time synchronization on our remote node:</p><div><pre class="programlisting">
<strong># ntpdate uk.pool.ntp.org</strong>
<strong># service ntpd start</strong>
<strong># chkconfig ntpd on</strong>
</pre></div><p>We will add the remote Puppet labs repository to the remote client CentOS system:</p><div><pre class="programlisting">
<strong># rpm -ivh http://yum.puppetlabs.com/puppetlabs-release-el6.noarch.rpm</strong>
</pre></div><p>Finally, we<a class="indexterm" id="id459"/> will install the Puppet agent on the<a class="indexterm" id="id460"/> client system and display the version of Puppet:</p><div><pre class="programlisting">
<strong># yum install puppet</strong>
<strong># puppet --version</strong>
</pre></div><p>At the time of writing this, the version of the Puppet Labs repository is 3.6.2.</p><p>We are now ready to test the client. The first step towards this is to start the agent manually so that we can enroll the node on the server. This will submit a certificate signing request to the Puppet master, as the node is not yet enrolled:</p><div><pre class="programlisting">
<strong># puppet agent test</strong>
</pre></div><p>Returning now to the console of the Puppet master, we can check the certificate authority for agent signing request:</p><div><pre class="programlisting">
<strong># puppet ca list</strong>
</pre></div><p>We should see the request from the client machine on our lab setup; the client request shows <code class="literal">centos65.tup.com</code>. We can accept and sign this request using the following command:</p><div><pre class="programlisting">
<strong> #  puppet ca --sign centos65.tup.com</strong>
</pre></div><p>We will now return to the client machine and rerun the test agent; this will download the signed certificate, and the agent will then download and apply the <code class="literal">site.pp</code> manifest:</p><div><pre class="programlisting">
<strong># puppet agent test</strong>
</pre></div><p>We can now check the contents of the <code class="literal">/etc/motd</code> file. We should have the content we saw before, but <a class="indexterm" id="id461"/>with the IP address of this node. Using the <code class="literal">cat</code> command from the remote client machine, the output will look similar to the following screenshot:</p><div><img alt="Enrolling remote puppet agents" src="img/5920OS_09_07.jpg"/></div><p>Now that we have installed the signed certificate onto the client, we can start the agent service<a class="indexterm" id="id462"/> and leave the system to manage<a class="indexterm" id="id463"/> itself; we can have even more time on the golf course now!</p><div><pre class="programlisting">
<strong># service puppet start</strong>
<strong># chkconfig puppet on</strong>
</pre></div><p>On CentOS, the agent service is just Puppet and with the service running, the agent will check the configuration every 30 minutes.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch09lvl1sec53"/>Summary</h1></div></div></div><p>In this chapter, we looked at how we can implement central configuration management using Puppet. Although we only looked at it on CentOS, the configuration can work across many operating systems including Linux, Windows, and Unix. The main server is the Puppet master and agents connected on the TCP port <code class="literal">8140</code> to download the site manifest. This manifest can include other classes but will determine the desired configuration for a node.</p><p>As we move onto the next chapter, we will look at how we can use <strong>pluggable authentication modules</strong> (<strong>PAM</strong>) to help harden the CentOS host, as well as venture into the world of SELinux.</p></div></body></html>