["```\nstatic DEFINE_SPINLOCK(my_spinlock);\n```", "```\n#define DEFINE_SPINLOCK(x) spinlock_t x = \\\n                                 __SPIN_LOCK_UNLOCKED(x)\n```", "```\nstatic DEFINE_SPINLOCK(foo_lock);\n```", "```\nstruct bigger_struct {\n    spinlock_t lock;\n    unsigned int foo;\n    [...]\n};\nstatic struct bigger_struct *fake_init_function()\n{\n    struct bigger_struct *bs;\n    bs = kmalloc(sizeof(struct bigger_struct), GFP_KERNEL);\n    if (!bs)\n        return -ENOMEM;\n    spin_lock_init(&bs->lock);\n    return bs;\n}\n```", "```\nstatic __always_inline void spin_unlock(spinlock_t *lock)\nstatic __always_inline void spin_lock(spinlock_t *lock)\n```", "```\nstatic void spin_unlock_irq(spinlock_t *lock)\nstatic void spin_lock_irq(spinlock_t *lock)\n```", "```\nspin_lock_irqsave(spinlock_t *lock, unsigned long flags)\nspin_unlock_irqrestore(spinlock_t *lock, unsigned long flags)\n```", "```\nstruct mutex {\n    atomic_long_t owner;\n    spinlock_t wait_lock;\n#ifdef CONFIG_MUTEX_SPIN_ON_OWNER\n    struct optimistic_spin_queue osq; /* Spinner MCS lock */\n#endif\n    struct list_head wait_list;\n[...]\n};\n```", "```\nstatic DEFINE_MUTEX(my_mutex);\n```", "```\n#define DEFINE_MUTEX(mutexname) \\\nstruct mutex mutexname = __MUTEX_INITIALIZER(mutexname)\n```", "```\nstruct fake_data {\n    struct i2c_client *client;\n    u16 reg_conf;\n    struct mutex mutex;\n};\nstatic int fake_probe(struct i2c_client *client)\n{\n[...]\n    mutex_init(&data->mutex);\n[...]\n}\n```", "```\nvoid mutex_lock(struct mutex *lock);\nint mutex_lock_interruptible(struct mutex *lock);\nint mutex_lock_killable(struct mutex *lock);\n```", "```\nvoid mutex_unlock(struct mutex *lock);\n```", "```\nstatic bool mutex_is_locked(struct mutex *lock)\n```", "```\nint mutex_trylock(struct mutex *lock)\n```", "```\nstatic DEFINE_SPINLOCK(foo_lock);\n[...]\nstatic void foo(void)\n{\n    [...]\n    if (!spin_trylock(&foo_lock)) {\n        /* Failure! the spinlock is already locked */\n        [...]\n        return;\n    }\n    /*\n    * reaching this part of the code means that the\n    * spinlock has been successfully locked\n    */\n    [...]\n    spin_unlock(&foo_lock);\n    [...]\n}\n```", "```\nstatic DEFINE_MUTEX(bar_mutex);\n[...]\nstatic void bar (void)\n{\n    [...]\n    if (!mutex_trylock(&bar_mutex)){\n        /* Failure! the mutex is already locked */\n        [...]\n        return;\n    }\n    /*\n     * reaching this part of the code means that the\n     * mutex has been successfully acquired\n     */\n    [...]\n    mutex_unlock(&bar_mutex);\n    [...]\n}\n```", "```\nstruct wait_queue_head {\n    spinlock_t lock;\n    struct list_head head;\n};\n```", "```\nDECLARE_WAIT_QUEUE_HEAD(my_event);\n```", "```\nwait_queue_head_t my_event;\ninit_waitqueue_head(&my_event);\n```", "```\nwait_event(&my_event, (event_occured == 1));\n/* or */\nwait_event_interruptible(&my_event, (event_occured == 1));\n```", "```\nwait_event_timeout(wq_head, condition, timeout)\n```", "```\nunsigned long msecs_to_jiffies(const unsigned int m)\nunsigned long usecs_to_jiffies(const unsigned int u)\n```", "```\nwake_up(&my_event);\nwake_up_all(&my_event);\nwake_up_interruptible(&my_event);\nwake_up_interruptible_all(&my_event);\n```", "```\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/time.h>\n#include <linux/delay.h>\n#include<linux/workqueue.h>\nstatic DECLARE_WAIT_QUEUE_HEAD(my_wq);\nstatic int condition = 0;\n/* declare a work queue*/\nstatic struct work_struct wrk;\nstatic void work_handler(struct work_struct *work)\n{\n    pr_info(\"Waitqueue module handler %s\\n\", __FUNCTION__);\n    msleep(5000);\n    pr_info(\"Wake up the sleeping module\\n\");\n    condition = 1;\n    wake_up_interruptible(&my_wq);\n}\nstatic int __init my_init(void)\n{\n    pr_info(\"Wait queue example\\n\");\n    INIT_WORK(&wrk, work_handler);\n    schedule_work(&wrk);\n    pr_info(\"Going to sleep %s\\n\", __FUNCTION__);\n    if (wait_event_interruptible(my_wq, condition != 0)) {\n        pr_info(\"Our sleep has been interrupted\\n\");\n        return -ERESTARTSYS;\n    }\n    pr_info(\"woken up by the work job\\n\");\n    return 0;\n}\nvoid my_exit(void)\n{\n    pr_info(\"waitqueue example cleanup\\n\");\n}\nmodule_init(my_init)\nmodule_exit(my_exit);\nMODULE_AUTHOR(\"John Madieu <john.madieu@gmail.com>\");\nMODULE_LICENSE(\"GPL\");\n```", "```\n[342081.385491] Wait queue example\n[342081.385505] Going to sleep my_init\n[342081.385515] Waitqueue module handler work_handler\n[342086.387017] Wake up the sleeping module\n[342086.387096] woken up by the work job\n[342092.912033] waitqueue example cleanup\n```", "```\nusleep_range(unsigned long min, unsigned long max)\nmsleep(unsigned long msecs)\nmsleep(unsigned long msecs)\nmsleep_interruptible(unsigned long msecs)\n```", "```\nndelay(unsigned long nsecs)\nudelay(unsigned long usecs)\nmdelay(unsigned long msecs)\n```", "```\nroot@raspberrypi4-64-d0:~# cat  /sys/devices/system/clocksource/clocksource0/available_clocksource \narch_sys_counter \nroot@raspberrypi4-64-d0:~#\n```", "```\nroot@udoo-labcsmart:~# cat  /sys/devices/system/clocksource/clocksource0/available_clocksource \nmxc_timer1 \nroot@udoo-labcsmart:~#\n```", "```\nroot@raspberrypi4-64-d0:~# cat  /sys/devices/system/clocksource/clocksource0/current_clocksource \narch_sys_counter\nroot@raspberrypi4-64-d0:~#\n```", "```\njma@labcsmart:~$ cat /sys/devices/system/clocksource/clocksource0/available_clocksource\ntsc hpet acpi_pm \njma@labcsmart:~$ cat /sys/devices/system/clocksource/clocksource0/current_clocksource \ntsc\njma@labcsmart:~$\n```", "```\njma@labcsmart:~$ echo acpi_pm >  /sys/devices/system/clocksource/clocksource0/current_clocksource \njma@labcsmart:~$\n```", "```\nroot@raspberrypi4-64-d0:~# ls /sys/devices/system/clockevents/         \nbroadcast    clockevent1  clockevent3  uevent\nclockevent0  clockevent2  power\nroot@raspberrypi4-64-d0:~#\n```", "```\nroot@udoo-labcsmart:~# ls /sys/devices/system/clockevents/\nbroadcast    clockevent0  clockevent1  consumers    power        suppliers    uevent\nroot@empair-labcsmart:~#\n```", "```\njma@labcsmart:~$ ls /sys/devices/system/clockevents/\nbroadcast  clockevent0  clockevent1  clockevent2  clockevent3  clockevent4  clockevent5  clockevent6  clockevent7  power  uevent\njma@labcsmart:~$\n```", "```\nroot@udoo-labcsmart:~# cat /sys/devices/system/clockevents/clockevent0/current_device \nlocal_timer\nroot@udoo-labcsmart:~# cat /sys/devices/system/clockevents/clockevent1/current_device \nlocal_timer\n```", "```\nroot@raspberrypi4-64-d0:~# cat /sys/devices/system/clockevents/clockevent2/current_device\narch_sys_timer\nroot@raspberrypi4-64-d0:~# cat /sys/devices/system/clockevents/clockevent3/current_device\narch_sys_timer\n```", "```\njma@labcsmart:~$ cat /sys/devices/system/clockevents/clockevent0/current_device\nlapic-deadline\njma@labcsmart:~$ cat /sys/devices/system/clockevents/clockevent1/current_device\nlapic-deadline\n```", "```\nstruct tick_device {\n    struct clock_event_device *evtdev;\n    enum tick_device_mode mode;\n};\n```", "```\nstruct tick_sched {\n    struct hrtimer               sched_timer;\n    enum tick_nohz_mode          nohz_mode;\n[...]\n};\n```", "```\nstatic DEFINE_PER_CPU(struct tick_sched, tick_cpu_sched);\n```", "```\njma@labcsmart:~$ cat /sys/devices/system/clockevents/broadcast/current_device\nhpet\n```", "```\nroot@raspberrypi4-64-d0:~# cat /sys/devices/system/clockevents/broadcast/current_device\nbc_hrtimer\n```", "```\nroot@udoo-labcsmart:~# cat /sys/devices/system/clockevents/broadcast/current_device \nmxc_timer1\n```", "```\nunsigned long long __weak sched_clock(void)\n```", "```\njma@labcsmart:~$ grep ‘CONFIG_HZ=' /boot/config-$(uname -r)\nCONFIG_HZ=250\njma@labcsmart:~$\n```", "```\nroot@udoo-labcsmart:~# zcat /proc/config.gz |grep CONFIG_HZ\nCONFIG_HZ_100=y\nroot@udoo-labcsmart:~#\n```", "```\nstruct timer_list {\n    struct hlist_node entry;\n    unsigned long expires;\n    void (*function)(struct timer_list *);\n    u32 flags;\n);\n```", "```\nvoid timer_setup( struct timer_list *timer,        \\\n           void (*function)( struct timer_list *), \\\n           unsigned int flags);\n#define DEFINE_TIMER(_name, _function) [...]\n```", "```\nint mod_timer(struct timer_list *timer,\n               unsigned long expires);\nvoid add_timer(struct timer_list *timer)\n```", "```\nmy_timer.expires = jiffies + ((12 * HZ) / 10); /* 1.2s */\nadd_timer(&my_timer);\n```", "```\nint del_timer(struct timer_list *timer);\nint del_timer_sync(struct timer_list *timer);\n```", "```\nmainline (CPUx)                  handler(CPUy)\n==============                   =============\n                                 enter xxx_timer()\ndel_timer()\nkfree(some_resource)\n                                 access(some_resource)\n```", "```\nmainline (CPUx)            handler(CPUy)\n==============             =============\n                           enter xxx_timer()\n del_timer()\n kfree(timer)\n                           mod_timer(timer)\n```", "```\nint timer_pending(const struct timer_list *timer);\n```", "```\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/timer.h>\nstatic struct timer_list my_timer;\nvoid my_timer_callback(struct timer_list *t)\n{\n    pr_info(\"Timer callback&; called\\n\");\n}\n\nstatic int __init my_init(void)\n{\n    int retval;\n    pr_info(\"Timer module loaded\\n\");\n    timer_setup(&my_timer, my_timer_callback, 0);\n    pr_info(\"Setup timer to fire in 500ms (%ld)\\n\",\n              jiffies);\n    retval = mod_timer(&my_timer,\n                        jiffies + msecs_to_jiffies(500));\n    if (retval)\n        pr_info(\"Timer firing failed\\n\");\n\n    return 0;\n}\n\nstatic void my_exit(void)\n{\n    int retval;\n    retval = del_timer(&my_timer);\n    /* Is timer still active (1) or no (0) */\n    if (retval)\n        pr_info(\"The timer is still in use...\\n\");\n    pr_info(\"Timer module unloaded\\n\");\n}\nmodule_init(my_init);\nmodule_exit(my_exit);\nMODULE_AUTHOR(\"John Madieu <john.madieu@gmail.com>\");\nMODULE_DESCRIPTION(\"Standard timer example\");\nMODULE_LICENSE(\"GPL\");\n```", "```\nunsigned long msecs_to_jiffies(const unsigned int m)\nunsigned long usecs_to_jiffies(const unsigned int u)\nunsigned long timespec64_to_jiffies(\n                  const struct timespec64 *value);\n```", "```\n#define from_timer(var, callback_timer, timer_fieldname) \\\n    container_of(callback_timer, typeof(*var), timer_fieldname) \n```", "```\nstruct fake_data {\n    struct timer_list timer;\n    struct sometype foo;\n    int bar;\n};\n```", "```\nstruct fake_data *fd = alloc_init_fake_data();\ntimer_setup(&fd->timer, timer_callback, 0);\n```", "```\nvoid timer_callback(struct timer_list *t)\n{\n    struct fake_data *fd = from_timer(fd, t, timer);\n    sometype data = fd->data;\n    int var = fd->bar;\n[...]\n}\n```", "```\nstruct hrtimer {\n    ktime_t                 _softexpires;\n    enum hrtimer_restart    (*function)(struct hrtimer *);\n    struct hrtimer_clock_base    *base;\n    u8                     state;\n[...]\n};\n```", "```\nvoid hrtimer_init(struct hrtimer *timer,\n                  clockid_t which_clock,\n                  enum hrtimer_mode mode);\n```", "```\nenum hrtimer_restart callback(struct hrtimer *h);\n```", "```\nu64 hrtimer_forward(struct hrtimer *timer,\n                    ktime_t now, ktime_t interval)\n```", "```\nhrtimer_forward(hrtimer, ktime_get(), ms_to_ktime(500));\n/* or */\nhrtimer_forward(handle, hrtimer_get_expires(handle),\n                 ns_to_ktime(450));\n```", "```\nu64 hrtimer_forward_now(struct hrtimer *timer,\n                          ktime_t interval)\n```", "```\nint hrtimer_start(struct hrtimer *timer, ktime_t time,\n                    const enum hrtimer_mode mode);\n```", "```\nktime_t ktime_set(const s64 secs,\n                  const unsigned long nsecs);\nktime_t ns_to_ktime(u64 ns);\nktime_t ms_to_ktime(u64 ms);\n```", "```\ns64 ktime_to_ns(const ktime_t kt)\ns64 ktime_to_us(const ktime_t kt)\n```", "```\nktime_t ktime_sub(const ktime_t lhs, const ktime_t rhs);\nktime_t ktime_sub(const ktime_t lhs, const ktime_t rhs);\nktime_t ktime_add(const ktime_t add1, const ktime_t add2);\nktime_t ktime_add_ns(const ktime_t kt, u64 nsec);\n```", "```\nint hrtimer_cancel(struct hrtimer *timer);\nint hrtimer_try_to_cancel(struct hrtimer *timer);\n```", "```\nint hrtimer_callback_running(struct hrtimer *timer);\n```", "```\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/hrtimer.h>\n#include <linux/ktime.h>\nstatic struct hrtimer hr_timer;\nstatic enum hrtimer_restart timer_callback(struct hrtimer *timer)\n{\n    pr_info(\"Hello from timer!\\n\");\n#ifdef PERIODIC_MS_500\n    hrtimer_forward_now(timer, ms_to_ktime(500));\n    return HRTIMER_RESTART;\n#else\n    return HRTIMER_NORESTART;\n#endif\n}\n```", "```\nstatic int __init hrtimer_module_init(void)\n{;\n    ktime_t init_time;\n    init_time = ktime_set(1, 1000);\n    hrtimer_init(&hr_timer, CLOCK_MONOTONIC,\n                   HRTIMER_MODE_REL);\n    hr_timer.function = &timer_callback;\n    hrtimer_start(&hr_timer, init_time, HRTIMER_MODE_REL);\n    return 0;\n}\nstatic void __exit hrtimer_module_exit(void) {\n    int ret;\n    ret = hrtimer_cancel(&hr_timer);\n    if (ret)\n        pr_info(\"Our timer is still in use...\\n\");\n     pr_info(\"Uninstalling hrtimer module\\n\");\n}\nmodule_init(hrtimer_module_init);\nmodule_exit(hrtimer_module_exit);\n```", "```\nstruct softirq_action {\n    void (*action)(struct softirq_action *);\n};\n```", "```\nvoid softirq_handler(struct softirq_action *h)\n```", "```\nvoid open_softirq(int nr,\n                  void (*action)(struct softirq_action *))\n```", "```\nenum\n{\n    HI_SOFTIRQ=0,   /* High-priority tasklets */\n    TIMER_SOFTIRQ,  /* Timers */\n    NET_TX_SOFTIRQ, /* Send network packets */\n    NET_RX_SOFTIRQ, /* Receive network packets */\n    BLOCK_SOFTIRQ,  /* Block devices */\n    BLOCK_IOPOLL_SOFTIRQ, /* Block devices with I/O polling\n                           * blocked on other CPUs */\n    TASKLET_SOFTIRQ,/* Normal Priority tasklets */\n    SCHED_SOFTIRQ,  /* Scheduler */\n    HRTIMER_SOFTIRQ,/* High-resolution timers */\n    RCU_SOFTIRQ,    /* RCU locking */\n    NR_SOFTIRQS     /* This only represent the number\n                     * of softirqs type, 10 actually */\n};\n```", "```\nconst char * const softirq_to_name[NR_SOFTIRQS] = {\n    \"HI\", \"TIMER\", \"NET_TX\", \"NET_RX\", \"BLOCK\", \"BLOCK_IOPOLL\", \n    \"TASKLET\", \"SCHED\", \"HRTIMER\", \"RCU\"\n};\n```", "```\nroot@udoo-labcsmart:~# cat /proc/softirqs\n                    CPU0       CPU1       \n          HI:       3535          1\n       TIMER:    4211589    4748893\n      NET_TX:    1277827         39\n      NET_RX:    1665450          0\n       BLOCK:       1978        201\n    IRQ_POLL:          0          0\n     TASKLET:     455761         33\n       SCHED:    4212802    4750408\n     HRTIMER:          3          0\n         RCU:     438826     286874\nroot@udoo-labcsmart:~#\n```", "```\nstatic struct softirq_action softirq_vec[NR_SOFTIRQS] ;\n```", "```\nvoid open_softirq(int nr,\n                  void (*action)(struct softirq_action *))\n{\n    softirq_vec[nr].action = action;\n}\n```", "```\nopen_softirq(NET_TX_SOFTIRQ, net_tx_action);\nopen_softirq(NET_RX_SOFTIRQ, net_rx_action);\n```", "```\nvoid __raise_softirq_irqoff(unsigned int nr)\nvoid raise_softirq_irqoff(unsigned int nr)\nvoid raise_softirq(unsigned int nr)\n```", "```\nirq_cpustat_t irq_stat[NR_CPUS] ____cacheline_aligned;\nEXPORT_SYMBOL(irq_stat);\n```", "```\nstatic __init int spawn_ksoftirqd(void)\n{\n    cpuhp_setup_state_nocalls(CPUHP_SOFTIRQ_DEAD, \"softirq:dead\",\n                          NULL, takeover_tasklets);\n    BUG_ON(smpboot_register_percpu_thread(&softirq_threads));\n    return 0;\n}\nearly_initcall(spawn_ksoftirqd);\n```", "```\nstruct tasklet_struct\n{\n\tstruct tasklet_struct *next;\n\tunsigned long state;\n\tatomic_t count;\n\tbool use_callback;\n\tunion {\n\t\tvoid (*func)(unsigned long data);\n\t\tvoid (*callback)(struct tasklet_struct *t);\n\t};\n\tunsigned long data;\n};\n```", "```\n#define DECLARE_TASKLET_OLD(name, _func)       \\\n    struct tasklet_struct name = {             \\\n    .count = ATOMIC_INIT(0),            \t   \\\n    .func = _func,                    \t        \\\n}\n#define DECLARE_TASKLET(name, _callback)       \\\n     struct tasklet_struct name = {            \\\n     .count = ATOMIC_INIT(0),                  \\\n     .callback = _callback,                    \\\n     .use_callback = true,                     \\\n}\n```", "```\nvoid foo(unsigned long data);\n```", "```\nvoid foo(struct tasklet_struct *t)\n```", "```\nvoid tasklet_setup(struct tasklet_struct *t,\n     void (*callback)(struct tasklet_struct *));\n```", "```\nDECLARE_TASKLET(name, _callback)\nDECLARE_TASKLET_DISABLED(name, _callback);\nDECLARE_TASKLET_OLD(name, func);\nvoid tasklet_setup(struct tasklet_struct *t,\n     void (*callback)(struct tasklet_struct *));\nvoid tasklet_enable(struct tasklet_struct *t);\nvoid tasklet_disable(struct tasklet_struct *t);\nvoid tasklet_schedule(struct tasklet_struct *t);\nvoid tasklet_hi_schedule(struct tasklet_struct *t);\n```", "```\nvoid tasklet_kill(struct tasklet_struct *t);\n```", "```\n# #include <linux/init.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>    /* for tasklets api */\n/* Tasklet handler, that just prints the handler name */\nvoid tasklet_function(struct tasklet_struct *t)\n{\n    pr_info(\"running %s\\n\", __func__);\n}\nDECLARE_TASKLET(my_tasklet, tasklet_function);\nstatic int __init my_init(void)\n{\n    /* Schedule the handler */\n    tasklet_schedule(&my_tasklet);\n    pr_info(\"tasklet example\\n\");\n    return 0;\n}\nvoid my_exit( void )\n{\n    /* Stop the tasklet before we exit */\n    tasklet_kill(&my_tasklet);\n    pr_info(\"tasklet example cleanup\\n\");\n    return;\n}\nmodule_init(my_init);\nmodule_exit(my_exit);\nMODULE_AUTHOR(\"John Madieu <john.madieu@gmail.com>\");\nMODULE_LICENSE(\"GPL\");\n```", "```\nDECLARE_WORK(name, function)\nDECLARE_DELAYED_WORK(name, function)\nINIT_WORK(work, func );\nINIT_DELAYED_WORK( work, func);\n```", "```\nstruct work_struct {\n    atomic_long_t data;\n    struct list_head entry;\n    work_func_t func;\n};\nstruct delayed_work {\n    struct work_struct work;\n    struct timer_list timer;\n    struct workqueue_struct *wq;\n    int cpu;\n};\n```", "```\ntypedef void (*work_func_t)(struct work_struct *work);\n```", "```\nstruct delayed_work *to_delayed_work(\n                struct work_struct *work)\n```", "```\nstruct workqueue_struct *create_workqueue(const char *name)\nstruct workqueue_struct *create_singlethread_workqueue(\n                                          const char *name)\n```", "```\nbool queue_work(struct workqueue_struct *wq,\n                 struct work_struct *work)\nbool queue_delayed_work(struct workqueue_struct *wq,\n                        struct delayed_work *dwork,\n                        unsigned long delay)\n```", "```\nunsigned long msecs_to_jiffies(const unsigned int m)\nunsigned long usecs_to_jiffies(const unsigned int u)\n```", "```\nqueue_delayed_work(my_wq, &drvdata->tx_work,\n                  usecs_to_jiffies(200));\n```", "```\nbool cancel_work_sync(struct work_struct *work)\nbool cancel_delayed_work(struct delayed_work *dwork)\nbool cancel_delayed_work_sync(struct delayed_work *dwork)\n```", "```\nvoid flush_workqueue(struct worksqueue_struct * queue); \nvoid destroy_workqueue(structure workqueque_struct *queue);\n```", "```\nint schedule_work(struct work_struct *work);\nint schedule_delayed_work(struct delayed_work *dwork,\n                          unsigned long delay);\nint schedule_work_on(int cpu,\n               struct work_struct *work);\nint schedule_delayed_work_on(int cpu,\n                struct delayed_work *dwork,\n                unsigned long delay);\n```", "```\nstruct workqueue_struct *system_wq __read_mostly;\nEXPORT_SYMBOL(system_wq);\n```", "```\nvoid flush_scheduled_work(void);\n```", "```\nstruct workqueue_struct *alloc_workqueue(const char *fmt,\n                             unsigned int flags,\n                             int max_active, ...);\n#define alloc_ordered_workqueue(fmt, flags, args...) [...]\nvoid destroy_workqueue(struct workqueue_struct *wq)\n```", "```\ntypedef irqreturn_t (*irq_handler_t)(int, void *);\n```", "```\ndevm_request_irq(struct device *dev, unsigned int irq,\n                  irq_handler_t handler,\n                  unsigned long irqflags, \n                  onst char *devname, void *dev_id)\n```", "```\n#define IRQF_SHARED 0x00000080\n#define IRQF_PROBE_SHARED 0x00000100\n#define IRQF_NOBALANCING 0x00000800\n#define IRQF_IRQPOLL 0x00001000\n#define IRQF_ONESHOT 0x00002000\n#define IRQF_NO_SUSPEND 0x00004000\n#define IRQF_FORCE_RESUME 0x00008000\n#define IRQF_NO_THREAD 0x00010000\n#define IRQF_EARLY_RESUME 0x000200002\n#define IRQF_COND_SUSPEND 0x00040000\n```", "```\nint request_irq(unsigned int irq, irq_handler_t handler,\n                unsigned long flags, const char *name,\n                void *dev) \n```", "```\nvoid free_irq(unsigned int irq, void *dev_id)\n```", "```\ndevm_request_threaded_irq(struct device *dev, unsigned int irq,\n                  irq_handler_t handler, irq_handler_t thread_fn,\n                  unsigned long irqflags, const char *devname,\n                  void *dev_id);\n```", "```\n/* Default primary interrupt handler for threaded\n * interrupts. Assigned as primary handler when\n * request_threaded_irq is called with handler == NULL.\n * Useful for oneshot interrupts.\n */\nstatic irqreturn_t irq_default_primary_handler(int irq,\n                                         void *dev_id)\n{\n    return IRQ_WAKE_THREAD;\n}\nint request_threaded_irq(unsigned int irq,\n          irq_handler_t handler, irq_handler_t thread_fn,\n          unsigned long irqflags, const char *devname,\n          void *dev_id)\n{\n[...]\n    if (!handler) {\n        if (!thread_fn)\n            return -EINVAL;\n        handler = irq_default_primary_handler;\n    }\n[...]\n}\nEXPORT_SYMBOL(request_threaded_irq);\n```", "```\nstatic irqreturn_t data_event_handler(int irq,\n                                      void *dev_id)\n{\n    struct big_structure *bs = dev_id;\n    clear_device_interupt(bs);\n    process_data(bs->buffer);\n    return IRQ_HANDLED;\n}\nstatic int my_probe(struct i2c_client *client)\n{\n[...]\n    if (client->irq > 0) {\n        ret = request_threaded_irq(client->irq, NULL, \n                &data_event_handler,\n                IRQF_TRIGGER_LOW | IRQF_ONESHOT,\n                id->name, private);\n        if (ret)\n            goto error_irq;\n    }\n...\n    return 0;\nerror_irq:\n    do_cleanup();\n    return ret;\n}\n```", "```\nint request_any_context_irq(unsigned int irq,\n                irq_handler_t handler, unsigned long flags,\n                const char *name, void *dev_id)\n```", "```\nstatic irqreturn_t packt_btn_interrupt(int irq,\n                                       void *dev_id)\n{\n    struct btn_data *priv = dev_id;\n    input_report_key(priv->i_dev, BTN_0,\n        gpiod_get_value(priv->btn_gpiod) & 1);\n    input_sync(priv->i_dev);\n    return IRQ_HANDLED;\n}\nstatic int btn_probe(struct platform_device *pdev)\n{\n    struct gpio_desc *gpiod;\n    int ret, irq;\n    gpiod = gpiod_get(&pdev->dev, \"button\", GPIOD_IN);\n    if (IS_ERR(gpiod))\n        return -ENODEV;\n    priv->irq = gpiod_to_irq(priv->btn_gpiod);\n    priv->btn_gpiod = gpiod;\n[...]\n    ret = request_any_context_irq(priv->irq,\n              packt_btn_interrupt,\n             (IRQF_TRIGGER_FALLING | IRQF_TRIGGER_RISING),\n             \"packt-input-button\", priv);\n    if (ret < 0)\n        goto err_btn;\n    return 0;\nerr_btn:\n    do_cleanup();\n    return ret;\n}\n```", "```\nstruct private_struct {\n    int counter;\n    struct work_struct my_work;\n    void __iomem *reg_base;\n    spinlock_t lock;\n    int irq;\n    /* Other fields */\n    [...]\n};\n```", "```\nstatic void work_handler(struct work_struct *work)\n{\n    int i;\n    unsigned long flags;\n    struct private_data *my_data =\n          container_of(work, struct private_data, my_work);\n    /*\n     * Processing at least half of MIN_REQUIRED_FIFO_SIZE\n     * prior to re-enabling the irq at device level,\n     * so that buffer can receive further data\n     */\n    for (i = 0, i < MIN_REQUIRED_FIFO_SIZE, i++) {\n        device_pop_and_process_data_buffer();\n        if (i == MIN_REQUIRED_FIFO_SIZE / 2)\n            enable_irq_at_device_level(my_data);\n    }\n    spin_lock_irqsave(&my_data->lock, flags);\n    my_data->buf_counter -= MIN_REQUIRED_FIFO_SIZE;\n    spin_unlock_irqrestore(&my_data->lock, flags);\n}\n```", "```\n/* This is our hard-IRQ handler. */\nstatic irqreturn_t my_interrupt_handler(int irq,\n                                        void *dev_id)\n{\n    u32 status;\n    unsigned long flags;\n    struct private_struct *my_data = dev_id;\n    /* we read the status register to know what to do */\n    status = readl(my_data->reg_base + REG_STATUS_OFFSET);\n    /*\n     * Ack irq at device level. We are safe if another\n     * irq pokes since it is disabled at controller\n     * level while we are in this handler\n     */\n    writel(my_data->reg_base + REG_STATUS_OFFSET,\n            status | MASK_IRQ_ACK);\n    /*\n     * Protecting the shared resource, since the worker\n     * also accesses this counter\n     */\n    spin_lock_irqsave(&my_data->lock, flags);\n    my_data->buf_counter++;\n    spin_unlock_irqrestore(&my_data->lock, flags);\n    /*\n     * Our device raised an interrupt to inform it has\n     * new data in its fifo. But is it enough for us\n     * to be processed ?\n     */\n    if (my_data->buf_counter != MIN_REQUIRED_FIFO_SIZE)) {\n       /* ack and re-enable this irq at controller level */\n       return IRQ_HANDLED;\n    } else {\n        /* Right. prior to scheduling the worker and\n         * returning from this handler, we need to\n         * disable the irq at device level\n         */\n        writel(my_data->reg_base + REG_STATUS_OFFSET,\n                MASK_IRQ_DISABLE);\n        schedule_work(&my_work);\n    }\n    /* This will re-enable the irq at controller level */\n    return IRQ_HANDLED;\n};\n```", "```\nstatic int foo_probe(struct platform_device *pdev)\n{\n    struct resource *mem;\n    struct private_struct *my_data;\n    my_data = alloc_some_memory(\n                        sizeof(struct private_struct));\n    mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n    my_data->reg_base = ioremap(ioremap(mem->start,\n                                resource_size(mem)););\n    if (IS_ERR(my_data->reg_base))\n        return PTR_ERR(my_data->reg_base);\n    /*\n     * workqueue initialization. \"work_handler\" is\n     * the callback that will be executed when our work\n     * is scheduled.\n     */\n    INIT_WORK(&my_data->my_work, work_handler);\n    spin_lock_init(&my_data->lock);\n    my_data->irq = platform_get_irq(pdev, 0);\n    if (devm_request_irq(&pdev->dev, my_data->irq,\n                        my_interrupt_handler, 0,\n                        pdev->name, my_data))\n        handler_this_error()\n    return 0;\n}\n```", "```\nstatic int my_probe(struct platform_device *pdev)\n{\n    int irq;\n    int ret;\n    irq = platform_get_irq(pdev, i);\n    ret = devm_request_threaded_irq(&pdev->dev, irq, NULL,\n                my_threaded_irq, IRQF_ONESHOT,\n                dev_name(dev), my_data);\n[...]\n    return 0;\n}\nstatic irqreturn_t my_threaded_irq(int irq, void *dev_id)\n{\n    struct priv_struct *my_data = dev_id;\n    /* Save FIFO Underrun & Transfer Error status */\n    mutex_lock(&my_data->fifo_lock);\n    /*\n     * Accessing the device's buffer through i2c\n     */\n    device_get_i2c_buffer_and_push_to_fifo();\n    mutex_unlock(&ldev->fifo_lock);\n    return IRQ_HANDLED;\n}\n```", "```\nstatic int my_probe(struct platform_device *pdev)\n{\n    int irq;\n    int ret;\n    [...]\n    irq = platform_get_irq(pdev, 0);\n    if (irq < 0)\n        goto handle_get_irq_error;\n    ret = devm_request_threaded_irq(&pdev->dev, irq,\n                    hard_handler, threaded_handler, \n                    IRQF_ONESHOT, dev_name(dev), my_data);\n    if (ret < 0)\n        goto err_cleanup_irq;\n     [...]\n    return 0;\n}\n```", "```\nstatic irqreturn_t hard_handler(int irq, void *dev_id)\n{\n    struct priv_struct *my_data = dev_id;\n    u32 status;\n    unsigned long flags;\n    /* Protecting the shared resource */\n    spin_lock_irqsave(&my_data->lock, flags);\n    my_data->status = __raw_readl(\n            my_data->mmio_base + my_data->foo.reg_offset);\n    spin_unlock_irqrestore(&my_data->lock, flags);\n    /* Let us schedule the bottom-half */\n    return IRQ_WAKE_THREAD;\n}\n```", "```\nstatic irqreturn_t threaded_handler(int irq, void *dev_id)\n{\n    struct priv_struct *my_data = dev_id;\n    spin_lock_irqsave(&my_data->lock, flags);\n    /* doing sanity depending on the status */\n    process_status(my_data->status);\n    spin_unlock_irqrestore(&my_data->lock, flags);\n    /*\n     * content of status not needed anymore, let's do\n     * some other work\n     */\n     [...]\n    return IRQ_HANDLED;\n}\n```"]