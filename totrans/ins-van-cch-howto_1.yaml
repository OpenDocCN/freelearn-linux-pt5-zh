- en: Chapter 1. Instant Varnish Cache How-to
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to *Instant Varnish Cache How-to*. In this book, we will cover the basics
    of setting up a Varnish Cache server instance in front of your website, how to
    identify cacheable portions of it, and how to get the best performance from your
    cache mechanism and policies.
  prefs: []
  type: TYPE_NORMAL
- en: Varnish Cache is a caching reverse proxy—often referred to as an HTTP accelerator,
    which sits between your application server and the client's requests. Its main
    goal is to avoid unnecessary duplicated work when the generated response is known
    to be the same, and with its flexible framework, it allows you to manipulate requests
    and also stitches together the **Edge Side Includes** (**ESI**) parts.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the sample codes found in this book were written for a specific use-case
    and should be applied with caution. Hopefully, these examples will inspire you
    to write your own solutions for your scenario, and deploy a fast and reliable
    Varnish Cache inside your infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: This book targets system administrators and web developers with previous knowledge
    of the HTTP protocol. I've made a few assumptions throughout the book regarding
    the HTTP protocol and if you ever find yourself in need of an extended explanation,
    you can always refer to the HTTP Version 1.1 documentation at [http://www.w3.org/Protocols/rfc2616/rfc2616.html](http://www.w3.org/Protocols/rfc2616/rfc2616.html)
    or the Varnish Cache 3.0 documentation at [https://www.varnish-cache.org/docs/3.0/](https://www.varnish-cache.org/docs/3.0/).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Varnish Cache (Must know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Varnish Cache binaries are very likely to be provided by your Linux distribution
    package repository, but the version you get from that repository might not be
    as up-to-date as it should be.
  prefs: []
  type: TYPE_NORMAL
- en: The Varnish Cache official repository provides versions for Red Hat- or Debian-based
    distributions, FreeBSD, and there's also the possibility to install it manually
    from a tarball file.
  prefs: []
  type: TYPE_NORMAL
- en: In the following recipe, we will install Varnish Cache on a Linux CentOS box
    using the `varnish-cache.org` repository and the **yum** package manager.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following example will use both Varnish Cache 3.0.3 and 64-bit Linux CentOS
    6.
  prefs: []
  type: TYPE_NORMAL
- en: It's recommended to try it out first on a virtual machine, since your caching
    policy will need to be adjusted and debugged before you go live.
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have virtualization software yet, I recommend the Oracle VirtualBox
    at [https://www.virtualbox.org/](https://www.virtualbox.org/) for its easy-to-use
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: For other Linux distributions, you can find the correct `varnish-cache.org`
    repository at [https://www.varnish-cache.org/releases/](https://www.varnish-cache.org/releases/).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Add the `varnish-cache.org` repository to your CentOS box by typing the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install Varnish Cache by typing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the Varnish Cache daemon by typing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adding the `varnish-cache.org` repository allows us to keep our varnish server
    up-to-date and running with stable versions only.
  prefs: []
  type: TYPE_NORMAL
- en: If there's no `varnish-cache.org` repository for your Linux distribution, or
    in case you decide to compile it by hand, you'll need to download a tarball file
    from [http://repo.varnish-cache.org/source/](http://repo.varnish-cache.org/source/
    ) and resolve the dependencies before you use the GNU `make` and `make install`
    commands.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Always check if the startup script service was correctly added to the runlevels
    list by typing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see runlevels 2, 3, 4, and 5 marked as `on`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In case the service is turned `off` in any of these runlevels, turn them `on`
    by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This will ensure that in case of a power outage or accidental server restart,
    our Varnish Cache instance will be up and running as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Startup scripts (also known as initialization script), are scripts that are
    typically run at system boot time. Most of them start services and set initial
    system parameters. For more information, visit [https://access.redhat.com/knowledge/docs/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s2-boot-init-shutdown-init.html](https://access.redhat.com/knowledge/docs/en-US/     Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s2-boot-init-shutdown-init.html).'
  prefs: []
  type: TYPE_NORMAL
- en: The runlevels list determines which programs are executed at system startup.
    More information about how runlevels works can be found at [https://access.redhat.com/knowledge/docs/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s1-boot-init-shutdown-sysv.html](https://access.redhat.com/knowledge/docs/en-US/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/s1-boot-init-shutdown-sysv.html).
  prefs: []
  type: TYPE_NORMAL
- en: Varnish Cache server daemon options (Must know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have installed the Varnish Cache service and it's running, we need
    to take a moment to make sure that our startup parameters are correct.
  prefs: []
  type: TYPE_NORMAL
- en: The default post-installation storage method declared in the startup script
    is file, and we will change that to a memory-based storage in order to maximize
    our performance boost.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Bear in mind that our entire data is supposed to fit into memory. In case it
    doesn't, stick with the default storage type (file).
  prefs: []
  type: TYPE_NORMAL
- en: Some parameters such as the number of open files, the location of the configuration
    file, and others do not require adjusting to server specifications and should
    work as provided.
  prefs: []
  type: TYPE_NORMAL
- en: The daemon options go from setting the amount of space for storage and the type
    of storage used up, to thread pooling and hashing algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `varnish` file at `/etc/sysconfig` is where all daemon options are conveniently
    located and also the resource for the startup script. You can also start the daemon
    manually and set the configuration parameters by passing arguments to it, but
    there's no need to do it since everything is already packed and ready. Every change
    to the `varnish` file at `/etc/sysconfig` is only valid after a full restart of
    the Varnish Cache service.
  prefs: []
  type: TYPE_NORMAL
- en: 'To restart the Varnish Cache, use the following provided script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When you perform a full restart, the cache is completely wiped. Be careful.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open the `varnish` file from `/etc/sysconfig` using your favorite text editor
    (I''m using vim) by typing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Take your time and read all the comments so that you can understand every bit
    of this file, since it's loaded by the startup script (`/etc/init.d/varnish`).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Find the `VARNISH_STORAGE` parameter and change the default value to `malloc
    ,${VARNISH_STORAGE_SIZE}`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Set the `VARNISH_STORAGE_SIZE` parameter to about 85 percent of your available
    ram.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On a 16-GB RAM system, we can allocate 14-GB for storage and leave the remaining
    2-GB for OS usage by using the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Both methods of storage—file and malloc—make use of file and memory resources
    but in a slightly different manner.
  prefs: []
  type: TYPE_NORMAL
- en: While the file storage type will allocate the entire cache size on a file, and
    tell the OS to map that file to memory (if possible) in order to gain speed, the
    malloc will request the storage size to the OS, and let it decide about how to
    divide and swap to file, what it can't fit into memory.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Don''t get fooled by the name**'
  prefs: []
  type: TYPE_NORMAL
- en: The file storage does not keep data in file when you restart your Varnish Cache
    server.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A new and still experimental storage type called persistent will work in a similar
    fashion for the file storage, but not every object will persist, since it can't
    handle situations where there's no more space left on the disk. The main benefit
    of this new storage type would be having a warmed up cache when recovering from
    an outage, since the objects are still available on disk.
  prefs: []
  type: TYPE_NORMAL
- en: The warm-up phase can also be performed with a tool called `varnishreplay`,
    but it requires much more time, since you will need an access logfile to replay
    it to Varnish Cache.
  prefs: []
  type: TYPE_NORMAL
- en: You can find more information about the persistent storage type on [https://www.varnish-cache.org/trac/wiki/ArchitecturePersistentStorage](https://www.varnish-cache.org/trac/wiki/ArchitecturePersistentStorage).
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to backend servers (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A backend server can be defined as any HTTP server from which Varnish Cache
    can request and fetch data. In this recipe, we will define our backend servers,
    probe those servers for their health status, and direct our clients' requests
    to the correct backend servers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have a server architecture diagram, that's a good place to start listing
    all the required servers and grouping them, but you'll also need some technical
    data about those servers. You may find this information in a server monitoring
    diagram, where you will find the IP addresses, ports, and luckily a probing URL
    for health checks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/0403OS_03_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In our case, the main VCL configuration file `default.vcl` is located at `/etc/varnish`
    and defines the configuration that the Varnish Cache will use during the life
    cycle of the request, including the backend servers list.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open the `default vcl` file by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A simple backend declaration would be:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This small block of code indicates the name of the backend (`server01`), and
    also the hostname or IP, and which port to connect to.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Save the file and reload the configuration using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this point, Varnish will proxy every request to the first declared backend
    using its default VCL file. Give it a try and access a known URL (like the index
    of your website) through the Varnish Cache and make sure that the content is delivered
    as it would be without Varnish.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For testing purposes, this is an okay backend declaration, but we need to make
    sure that our backend servers are up and waiting for requests before we really
    start to direct web traffic to them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s include a probing request to our backend:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Varnish will now probe the backend server using the provided URL with a timeout
    of 60 ms, every couple of seconds.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To determine if a backend is healthy, it will analyze the last five probes.
    If three of them result in `200 – OK`, the backend is marked as Healthy and the
    requests are forwarded to this backend; if not, the backend is marked as Sick
    and will not receive any incoming requests until it's Healthy again.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Probe the backend servers that require additional information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In case your backend server requires extra headers or has an HTTP basic authentication,
    you can change the probing from `URL` to `Request` and specify a raw HTTP request.
    When using the `Request` probe, you''ll always need to provide a `Connection:
    close` header or it will not work. This is shown in the following code snippet:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Choose a backend server based on incoming data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After declaring your backend servers, you can start directing the clients''
    requests. The most common way to choose which backend server will respond to a
    request is according to the incoming URL, as shown in the following code snippet:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Based on the preceding configuration, all requests that contain `/api/` (`www.yourdomain.com/api/`)
    in the URL will be sent to the backend named `api` and the others will reach the
    backend named `website`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also pick the correct backend server, based on User-agent header, Client
    IP (geo-based), and pretty much every information that comes with the request.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By probing your backend servers, you can automate the removal of a sick backend
    from your cluster, and by doing so, you avoid delivering a broken page to your
    customer. As soon as your backend starts to behave normally, Varnish will add
    it back to the cluster pool.
  prefs: []
  type: TYPE_NORMAL
- en: Directing requests to the appropriate backend server is a great way to make
    sure that every request reaches its destination, and gives you the flexibility
    to provide content based on the incoming data, such as a mobile device or an API
    request.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have lots of servers to be declared as backend, you can declare probes
    as a separated configuration block and make reference to that block later at the
    backend specifications, avoiding repetition and improving the code's readability.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `server01` server will use the probe named `favicon`, and the `server02`
    server will use the probe named `robots`.
  prefs: []
  type: TYPE_NORMAL
- en: Load balance requests (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Balancing requests is a great way to share workload across the cluster pool
    and avoid overloading a single server instance, keeping the overall health of
    the system. There's also the possibility to direct VIP customers to a dedicated
    cluster pool, guaranteeing them the best user experience.
  prefs: []
  type: TYPE_NORMAL
- en: By using a director group, Varnish will manage and spread the incoming requests
    to those servers included in it. Having the servers constantly checked, Varnish
    can take care of the sick servers and maintain everything as if there was no problem
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are six types of director groups to be configured: random, client, hash,
    round-robin, DNS, and fallback. While the random director is self-explanatory
    (randomly distributes requests), a DNS director can be used to spread to an entire
    network of servers. The hash director will always choose a backend based on the
    hash of the incoming URL and the fallback director can be used in emergency cases
    when servers behave oddly.'
  prefs: []
  type: TYPE_NORMAL
- en: The two most common directors are the round-robin and client directors.
  prefs: []
  type: TYPE_NORMAL
- en: The round-robin can be used to spread requests one by one to the entire cluster
    of servers no matter what is requested, and the client director can be used to
    create a sticky-session based on unique information provided by the client, such
    as an IP address.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe we will create both the client and round-robin balancers to spread
    requests across application servers.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Group the backend servers to load balance requests by using the following code
    snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding example, we have declared that our director named `dr1` is
    a `round-robin` director, and inside this director there are four backend servers
    to be balanced. Backend servers `server01` to `server04` have already been configured
    earlier and this declaration is only referring to them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a sticky-session pool of servers by using the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At first, there's absolutely no difference from the `round-robin` declaration
    to the `client` one, but inside your `vcl_recv` subroutine, you'll need to specify
    what identifies a unique client. Varnish will use, as default, the client IP address,
    but if you have other services in front of your Varnish Cache (such as a firewall),
    you'll need to rewrite the value of the `client.identity` variable. In the following
    example, we'll use the `X-Forwarded-For` header to get the clients' real IP address.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: The `X-Forwarded-For` header is used to maintain information lost in the proxying
    process. For more information visit [http://tools.ietf.org/html/draft-ietf-appsawg-http-forwarded-10](http://tools.ietf.org/html/draft-ietf-appsawg-http-forwarded-10).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: A sticky-session pool is necessary to direct clients to specific parts of your
    website that requires an HTTP session or authorization, such as shopping cart/checkout
    and login/logout pages, without breaking their session. Those parts of your website
    may be critical to your business, and having a sticky-session dedicated cluster
    can prioritize paying customers while the others are still browsing the products
    and will not interfere with the checkout process performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By using directors to load balance the requests, we can obtain greater service
    availability and provide paying customers with an improved user experience.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes it's not possible for all the servers to be identical inside a cluster.
    Some servers may have more available ram or more processors than others, and to
    balance requests based on the weakest server in the cluster is not the best way
    to solve this problem, since the higher end servers would be underused.
  prefs: []
  type: TYPE_NORMAL
- en: 'Weight-based load balancing improves the balance of the system by taking into
    account a pre-assigned weight for each server as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Weighting the servers is only possible in the random or client directors.
  prefs: []
  type: TYPE_NORMAL
- en: The Varnish Configuration Language (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Varnish Configuration Language** (**VCL**) is a domain-specific language
    used to define the caching policy. It might seem a bit confusing at first to learn
    another DSL instead of using an already known language, but in the next recipe
    you will find out how easy it is to define how your cache should behave using
    the VCL.
  prefs: []
  type: TYPE_NORMAL
- en: Every written VCL code will be compiled to binary code when you start your Varnish
    Cache. So if you forget a semi-colon, for example, the code will not compile and
    the daemon will continue using the last compiled version of your configuration
    file, as long as you use the reload function from the startup script and don't
    restart your server.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main configuration file `default.vcl` used to define the caching policy
    is entirely written in VCL and is located at `/etc/varnish/`.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the configuration is written into subroutines and follows a pre-defined
    flow during the request and response phase.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/0403OS_05_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating comments in the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can use `//`, `#`,or `/* your comment inside */`for creating a comment
    in your code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assignment and logical operators:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assignments can be done with a single equals sign `=`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Comparisons can be done with `==` for matching conditions or `!=`for not matching
    conditions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Logical operations can be done with `&&` for AND operations, and || for OR operations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Regular expressions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Varnish uses the **Perl-compatible regular expressions** (**PCRE Regex**).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The contains operator for validating regex is `~` (tilde) and the does not contain
    operator is `!~`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'VCL functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`regsub()` and `regsuball()`: They work by changing a provided string whenever
    it matches a regex expression. The difference between the two functions is that
    the `regsub()`function replaces only the first match and the `regsuball()`function
    replaces all matching occurrences.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Both functions expect a `original_string`, regex, `substitute_stringformat`
    as input:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: This expression will remove any character located after a `?`sign (including
    the question mark itself). Removing the parameters from the requested URL during
    the `vcl_hash` phase will help you avoid storing duplicated content (be careful
    not to end up serving the wrong content).
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '`purge`: It is used to invalidate stale content, keeping the cache fresh. A
    good rule of thumb is to send an HTTP `PURGE` request to Varnish Cache whenever
    your backend receives an HTTP `POST` or `DELETE`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ban()` and `ban_url()`: They create a filter, instructing if a cached object
    is supposed to be delivered or not. Adding a new filter to the ban list will not
    remove the content that is already cached—what it really does is exclude the matching
    cached objects from any subsequent requests, forcing a cache miss.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Too many entries in the ban list will consume extra CPU space.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '`return(`: It determines to which subroutine the request should proceed to.
    By calling `return(lookup)` method, we''re instructing Varnish to stop executing
    the current subroutine and proceed to the `lookup` subroutine.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '`hash_data(`: It is responsible for setting the hash key used to store an object
    and it is only available inside the `vcl_hash` subroutine. The default value for
    the `hash_data` variable is `req.url` (requested URL), but it may not suit your
    needs. In a multi-domain website, a hash key conflict may occur, since the default
    `hash_data` for the homepage would be `/` in all domains. Concatenating the value
    of the `req.http.Host` variable would add the domain name to the hash key, making
    it unique.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`error`: It is used to interrupt a request or response whenever an error arises
    and an error page needs to be displayed. The first argument is the HTTP error
    code and the second is a string with the error code message.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All the VCL written code is translated to C language and compiled into a shared
    object, which will be linked to the server process when it is reloaded. Any coding
    mistake found during this phase, such as a missing semi-colon at the end of a
    line, will generate the following compiler error indicating the line and what
    the compiler was expecting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the VCC compiler informs that it was expecting a `;`(semi-colon)
    on line `93` and found a `}` (curly bracket) instead.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To find out how Varnish is translating your VCL code to C language, run the
    daemon with the `-C` argument that will instruct the daemon to compile and print
    the C language code to the console.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: If you decide to insert an inline C code inside your VCL, analyzing the generated
    code will help you to debug it.
  prefs: []
  type: TYPE_NORMAL
- en: You will also find out that inside the generated C code the default VCL configuration
    is still present, even if you have deleted it. This is a self-defense mechanism
    which makes sure that a request always has a valid `return()` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Handling HTTP request vcl_recv (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `vcl_recv` routine is the first subroutine to be executed when a request
    comes in. At this point, you can normalize URL, add or subtract HTTP headers,
    strip or delete cookies, define which backend or director will respond to the
    request, control access, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will take a look at the default `vcl_recv` subroutine and increment
    its behavior to suit our needs.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open the `default.vcl` file at `/etc/varnish` and find the `vcl_recv` routine
    (`sub vcl_recv`).
  prefs: []
  type: TYPE_NORMAL
- en: The following block of codes are presented as an explanation of the default
    behavior and in the *How to do it...* section, we will modify them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The `req.restarts` object is an internal counter that indicates how many times
    the request was restarted (the prefix `req` indicates that this variable is of
    the type request). Restarting is commonly done when a backend server is not responding
    or an expected error arises, and by doing so, you can choose another backend server,
    rewrite the URL, or take other actions to prevent an error page.
  prefs: []
  type: TYPE_NORMAL
- en: This specific block of code is executed only when the request is not restarted,
    and it will append the client IP to an `X-Forwarded-For` header, if present. If
    not, Varnish will create the `X-Forwarded-For` header and assign the client IP
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: If the incoming request is not a known HTTP method, Varnish will pipe it to
    the backend and let it handle the request.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Since delivering cached content can only be done in `GET` and `HEAD` HTTP methods,
    we need to pass the request that do not match to the backend servers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: If the request contains an authorization or cookies header, we should not try
    to look up for it in cache, since the content of this request is specific to the
    client.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The final statement inside the `vcl_recv` subroutine instructs Varnish to look
    up the requested URL in cache. When the request does not match any of the previous
    conditions, which instructs Varnish not to look up for the content (like cookies,
    authorization, HTTP `POST`, and others), it will deliver a cached version of the
    requested content.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After understanding the default `vcl_recv` subroutine, we should identify the
    sections of our website that can be cached and the ones that cannot be cached.
    For some sections of the website, you still may want to deliver a cached version
    even if a user sends a cookie, for example, static content such as CSS, XML, and
    JPEG files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stripping cookies from requests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If the requested URL ends in any of the extensions (`.png`, `.jpeg`, `.ico`,
    and so on) listed in the condition, the cookies will be removed before the request
    continues through the VCL. The same behavior will happen for anything under the
    `static` and `images` directory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Remember that Varnish will execute the code in a sequential way, so the first
    return statement that matches will be executed, and all the code after that will
    not be processed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define which backend or director will receive the request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Every request that contains a `/java/` URL will hit the `java` director and
    everything else will hit the `php` director. This is a really basic example, and
    in reality you will probably use a regular expression to match sections of the
    requested URL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create security barriers to avoid unauthorized access:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you want to, you can pass the request directly to the error subroutine `vcl_error`
    (with an HTTP error code and message), instead of using a return statement.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Getting your subroutines right is one of the most important steps to get a good
    hit ratio, since the `vcl_recv` and `vcl_fetch` subroutines are probably where
    you will write 80 percent of your VCL code.
  prefs: []
  type: TYPE_NORMAL
- en: By stripping cookies of known static content, we get rid of requests that would
    always hit the backend for the same content like a header or footer, since the
    default behavior is to pass requests that contain cookies. Be extremely careful
    when stripping cookies, otherwise users may be locked outside your website if
    you remove sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: The `vcl_recv` subroutine is also the one where you control how balanced your
    cluster/directors will be, whenever a request passes through Varnish.
  prefs: []
  type: TYPE_NORMAL
- en: Handling HTTP request vcl_hash (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `vcl_hash` subroutine is the subroutine that is executed after the `vcl_recv`
    subroutine. Its responsibility is to generate a hash that will become the key
    in the memory map of stored objects and play an important role in achieving a
    high hit ratio.
  prefs: []
  type: TYPE_NORMAL
- en: The default value for an object's key is its URL and it probably suits most
    of the cases. If you have too many SEO friendly URLs, and purging becomes a problem
    since those URLs are dynamically generated, using the `vcl_hash` subroutine to
    normalize these keys will help you remove stale content from cache.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is the default action for the `vcl_hash` subroutine and the object's key
    will be of the `URL + host` format, in case an HTTP `host` header is present,
    or of the `URL + server ip` format, when it is not.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Whenever the `hash_data()` function is called, the provided value is appended
    to the current key.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Avoiding double caching for `www.youdomain.com` and `yourdomain.com`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Adding the HTTP host normalization step before it is appended to the `hash_data()`
    function will prevent your cache from generating different keys for `www.yourdomain.com`
    and `www.yourdomain.com`, when the content is the same.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Removing domain name (host) from static files of multi-language websites:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Removing a domain name from the object's key can help you achieve a higher hit
    ratio by serving the same image for all web pages that speak the same language
    but have different domain names.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Creating a temporary header `http X-HASH` to rewrite and modify everything you
    need before passing to the `hash_data()` function can make your code more readable.
    By removing the domain name, the generated object's keys for `http://www.youdomain.com/images/example.png`
    and `http://www.youdomain.co.uk/images/example.png` will be the same.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Normalizing SEO URLs for easier purging:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Taking `http://yourdomain.com/a-long-seo-friendly-url-that-can-make-your-life-harder__3458.html`
    as an example of a SEO-friendly URL, removing this object from cache can become
    harder if the generated SEO URL is based on an updated field (as you will lose
    reference to the old key value), or if you have an asynchronous process that purges
    content, based on the timestamp of objects.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Normalizing the object's key can make your life easier whenever you need to
    purge a content that is shared across multiple domains, or whenever you have a
    SEO friendly website in which it is necessary to update content as soon as it
    becomes stale.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding duplicated content will save extra memory space and provide you with
    a higher hit ratio, improving the overall performance of your website.
  prefs: []
  type: TYPE_NORMAL
- en: Take some time to familiarize yourself with your website contents, in order
    to identify files and sections that can benefit from a normalized key.
  prefs: []
  type: TYPE_NORMAL
- en: Handling HTTP request vcl_pipe and vcl_pass (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main difference between these two subroutines is that the `vcl_pipe` subroutine
    will transmit the bytes back and forth after a pipe instruction is executed at
    the `vcl_recv` subroutine (and the subsequent VCL code will not be processed),
    no matter what is in it, while the `vcl_pass` subroutine will transmit the request
    to the backend without caching the generated response.
  prefs: []
  type: TYPE_NORMAL
- en: Both subroutines respect a `keep-alive` header. As long as the connection is
    still open, the `vcl_pipe` subroutine will keep transmitting bytes back and forth
    without analyzing any of the subsequent requests, preventing cached content from
    being delivered since the pipe is still active.
  prefs: []
  type: TYPE_NORMAL
- en: Piping or passing a request can be useful when users reach a protected section
    of the website.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is the default `vcl_pipe` subroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The default behavior is that if you do not set the HTTP `connection` header
    as `close`, a client might be piped once, and then all other subsequent requests
    made with a keep-alive header will use the same pipe, overloading your backend
    servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the default `vcl_pass` subroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The default `vcl_pass` behavior is pretty much self-explanatory. The request
    will be passed to the backend and the generated response will not be cached.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Add a connection header to piped requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Every piped request will be closed after it is processed.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By piping requests, you can stream large objects, but you need to be careful
    or all other subsequent requests for that same client will also be piped.
  prefs: []
  type: TYPE_NORMAL
- en: Passing requests is the default action for protected or personalized sections
    of your website and requires no extra work.
  prefs: []
  type: TYPE_NORMAL
- en: Handling HTTP response vcl_fetch (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `vcl_fetch` subroutine is the first subroutine to deal with the response
    phase and it plays an important role on caching policies and **Edge-side Include**
    (**ESI**). When dealing with a legacy system that does not provide a `cache-control`
    header, you can hardcode a time to live (ttl) value to the content that should
    be cached.
  prefs: []
  type: TYPE_NORMAL
- en: While you can manipulate requests based on client-provided data using the `req.*`
    variable in the `vcl_recv` subroutine, you can do the same data manipulation in
    the `vcl_fetch` subroutine, but with data provided by a backend server using the
    `beresp.*` variable (`beresp` = backend response).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information about edge-side include visit [http://www.w3.org/TR/esi-lang](http://www.w3.org/TR/esi-lang).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First we will take a look at the default `vcl_fetch` subroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The default `vcl_fetch` behavior will not cache the response if your backend
    server provides a zero or negative ttl value, a `Set-cookie` header, or a `Vary`
    header. Instead, Varnish will cache a dummy object that instructs the next requests
    for this URL to be passed for the next two minutes. This is called hit-for-pass.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Overriding the default time to live of a cached object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using the `set beresp.ttl = 1d` instruction, our static files will be stored
    in cache for one day. If our backend server provides an HTTP `cache-control` or
    `expires` header with a different time frame, we will override it with the set
    command.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Stripping cookies for static content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Removing the HTTP `set-cookie` header from the response allows us to sanitize
    the object before inserting it into memory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Restart requests that failed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In case the backend server returns a 500+ HTTP error code (server-side error)
    and the original request was not an HTTP `POST`, we will restart it and try a
    different backend. Restarting will take the request back to the `vcl_recv` subroutine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To do so, we also need to tweak the `vcl_recv` subroutine so that the restarted
    request can pick another backend instead of our original failed server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inspecting why the response was not cached:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sending a debug header alongside the response can help you understand the behavior
    of the cache and why a specific content was not cached.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding code will check for the presence of an expired time to live, cookies,
    or if the `Cache-control` header instructed that the content is private.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stripping cookies from a response will help you clean up data that should not
    be stored along with the object in cache, but it may be risky to do so, since
    cookies are used to authenticate users or track user steps. Be extra sure that
    the user experience will not be affected.
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to restart a request that would otherwise end up in an error
    inside the `vcl_error` subroutine, but there's no need to take that extra step
    if you can restart it as soon as the backend server throws an error. This is not
    a bulletproof method, but it can most certainly help you when a bad deploy happens
    in one of the cluster servers.
  prefs: []
  type: TYPE_NORMAL
- en: Handling HTTP response vcl_deliver (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `vcl_deliver` subroutine is the last step before a response returns to the
    client and can be used for server obfuscation, adding debug headers, and a last
    overall headers' clean up.
  prefs: []
  type: TYPE_NORMAL
- en: Because the `vcl_deliver` subroutine is executed after the object is placed
    into cache, all manipulation that happens inside the `vcl_deliver` subroutine
    will not be persisted.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is the default `vcl_deliver` behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the default `vcl_deliver` subroutine is very straightforward
    and in fact it does not modify anything.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Remove the server name for obfuscating purposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Obfuscating the HTTP `Server` header is a good way to avoid exposing what type
    of server and version you are using behind your Varnish Cache.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Removing extra headers added by Varnish:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The HTTP `Age` header provides information about how long this object has been
    cached, while the HTTP `Via` header informs who delivered the response. The `X-Varnish`
    header returns two values: the first one is the request ID that originated the
    cached object, and the second one is the present request ID.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: There is absolutely no need to remove those headers, but it is a good way to
    not give away unnecessary information.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add cache `hit` or `miss` debug headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Inside the `vcl_deliver` subroutine, you can read the object's `hit` counter
    variable to determine if the object is being served from cache or by the backend.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adding a debug header in order to know if the content was served from cache
    helps you to identify objects that should be served from cache, but are not.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Handling HTTP response vcl_error (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `vcl_error` subroutine handles odd behaviors from backend servers, and can
    also be used when you want to deny access to a request or redirect requests to
    a new location.
  prefs: []
  type: TYPE_NORMAL
- en: Another good use of the `vcl_error` subroutine is to deliver a maintenance page
    while you are working on the backstage, rolling out patches, or deploying a new
    version of your website (in case you cannot have multiple versions deployed at
    the same time).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will take a look at the default `vcl_error` subroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The default `vcl_error` subroutine will generate a simple HTML page informing
    the status of the response and the ID of the request.
  prefs: []
  type: TYPE_NORMAL
- en: Custom error pages can be declared inside the synthetic block.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Maintenance page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Whenever you need to take the entire website offline (as a last resort), you
    can redirect users straight from the request phase (`vcl_recv`) to the `vcl_error`
    subroutine and deliver a static page that warns the users about the scheduled
    maintenance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Redirecting users:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside the `vcl_error` subroutine you can read and write to requests, objects,
    and responses variables. In case of an unexpected failure, you can redirect customers
    to an **Oops! We're sorry** friendly page or even to the website home page.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Keep in mind that the `301` HTTP code means Moved Permanently, so dealing with
    redirections based on a system failure cannot be assigned as a `301` status. A
    `302` HTTP code informs that the resource was temporarily moved.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Redirecting customers to a friendly error page is a good way to avoid users
    from having a bad experience, therefore favoring a competitor's website.
  prefs: []
  type: TYPE_NORMAL
- en: Caching static content (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A static web page can be defined as a page that is pre-built and delivered exactly
    the same way every time it is loaded. Even if the content of a page is updated
    from time to time (let's say every 10 to 15 minutes) with the latest news or products,
    you can still cache that page for a smaller period and benefit from not having
    to process that same response for every customer inside that time frame.
  prefs: []
  type: TYPE_NORMAL
- en: Other cacheable static contents that can make your website faster are the CSS,
    JavaScript, and image files which will probably be cached for a longer period
    of time than your HTML pages.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, you need to identify your static files or sections and define a time
    to live based on how long you expect a specific type of file to change its content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a list of files and sections helps you grouping them under a single
    VCL condition (rule) based on their expected ttl:'
  prefs: []
  type: TYPE_NORMAL
- en: '| File type | Time period |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Image files (JPG, PNG, GIF) | 1 week |'
  prefs: []
  type: TYPE_TB
- en: '| JavaScript | 1 hour |'
  prefs: []
  type: TYPE_TB
- en: '| CSS | 1 hour |'
  prefs: []
  type: TYPE_TB
- en: The best place to define your ttl caching policies is inside the `vcl_fetch`
    subroutine because it is the last step before an object is inserted to cache.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Define a time to live based on file type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As you have probably already noticed, Varnish takes a numeric argument followed
    by a single letter, which identifies a scale of time:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: S = seconds
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: H = hours
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: D = days
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: W = weeks
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Disabling cache:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Setting the ttl to zero seconds will create an already expired object, forcing
    it not to be cached.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Avoiding duplicated workload is the first step to a faster website, and achieving
    a higher hit ratio for your static content is where you have to primarily focus
    before moving to more complex caching policies.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure your backend is not already defining a caching policy with `cache-control`
    or `expire` headers, as you probably will be better off obeying those policies.
  prefs: []
  type: TYPE_NORMAL
- en: Un-setting cookies before the object is placed into memory is mandatory or else
    you will end up caching unnecessary and sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: Cookies, sessions, and authorization (Become an expert)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many ways to identify unique users in our website. In this recipe,
    we will cover the three most used ones: cookies, sessions, and authorization.
    Whenever one of them occurs, you must be extremely careful with the request and
    generated response since they contain user-specific data and cannot be delivered
    to a different user.'
  prefs: []
  type: TYPE_NORMAL
- en: Caching user-specific content requires an extra step, since only the same user
    will be able to access that cached object. Delivering user-specific content to
    someone else can lead to session hijacking, user's private information leakage,
    and many other security problems.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An HTTP cookie, also referred to as browser cookie, is the result of a `set-cookie`
    response header and it is used to store small pieces of data on the client side
    (browser) for later usage on subsequent requests. The top reason for using cookies
    is to identify a unique user and use the stored information to generate personalized
    content or to track its steps.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP session is generated on the server side and only the ID of that interaction
    is sent to the client in the form of a cookie. A session is used to keep all the
    information on the server side, and the user only handles the session ID (token),
    unlike what happens with a regular cookie. Session tokens are often specific to
    programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP authorization is the most basic kind of HTTP security that can be implemented
    in a website (often called HTTP Basic Auth), and it is executed via an `authorization`
    header. HTTP authorization will often encrypt the username and password in a base
    64 fashion.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Avoiding cache for user-specific requests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Since sessions are stored inside cookies, you will only need to check for the
    presence of a session as a URL parameter, like the `JSESSIONID` (for Java systems).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Caching user specific information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you need to create a per-user cache, the following example of code will set
    the cookie along with the original `hash_data`. Caching responses with cookies
    will often lead to more problems than solutions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is actually a basic example on how to deal with requests that contain cookies
    and need to be cached. You should write your own regex (using the `regsub` function)
    to extract only the value of the cookie that you will use to append to the default
    object's key.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Storing user-specific content in cache can be helpful to deliver a faster response,
    but it is not recommended since the non-authenticated users represent the biggest
    portion of the requests, therefore, the authenticated users will not have trouble
    if they do not hit the cache at all.
  prefs: []
  type: TYPE_NORMAL
- en: Unless you have a website that requires all users (or at least half of them)
    to be logged in, it is better to let the requests pass to backend servers and
    avoid the trouble of leaking private information and other security concerns.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP cache headers (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HTTP is a long-established protocol for exchanging information between clients
    and servers, and the headers are an important part of that communication. HTTP
    headers define what the client is requesting and how they expect it to be responded
    to by the server.
  prefs: []
  type: TYPE_NORMAL
- en: Along with a request, you will probably find a handful of headers such as accept,
    accept-encoding, keep-alive, host, and many others. In a `GET` method, the request
    will ask for information about a specific resource and attach headers to allow
    the server to know how the response should be formed.
  prefs: []
  type: TYPE_NORMAL
- en: On the response phase of the communication, the server will also attach server-specific
    headers to let the client know how it should treat the response and, if instructed,
    store it (browser cache).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will focus primarily on the HTTP header called cache-control
    which is covered in the section 13 of the Hypertext Transfer Protocol Version
    1.1 ([http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html](http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html)).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The HTTP protocol Version 1.1 introduced the `cache-control` response header
    as an alternative to the `expires` header implemented in HTTP 1.0\. The main difference
    between them is that `expires` takes a date value and the `cache-control` can
    receive an age value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cache-control` header can also indicate what level of cache should be
    done for that response. This type of control is passed as a directive and can
    assume the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`public`: Any type of cache mechanism (server, proxy, or browser) can cache
    the content of that response.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`private`: Indicates that the response (or part of it) is specific to a single
    client and should not be cached by a "shared" cache mechanism.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`no-cache`: Forces a validation request to the origin server before delivering
    the cached copy to the user. It is primarily used for authentication when a cached
    copy of the response cannot be delivered to an unauthorized client.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`no-store`: The response cannot be cached at all.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The expiration attributes (ttl) of the `cache-control` header are:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`max-age`: Defines for what period of time the response will be cached.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s-maxage`: Exactly the same as max-age, but it only applies to proxy caches.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Opposite to the `cache-control` header, the `expires` header receives an HTTP-date
    (RFC 1123) as value that indicates until when the content of the response is considered
    valid. After it expires, a new representation will be requested from the origin
    server.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The HTTP-date specification can be found at section 3.3.1 of the HTTP protocol
    ([http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html](http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html)).
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The HTTP protocol is the foundation in which Varnish relies and includes a number
    of elements to make caching policies easier. The best approach to setting different
    times for cached objects (when using a proxy-cache) is to code the time to live
    policies inside your application server, by sending a `cache-control` header alongside
    with the response and thus avoiding to hardcode the ttl inside the VCL code. In
    case you are dealing with a legacy system that is no longer maintained, you will
    probably need to hardcode the ttl to create a cache object.
  prefs: []
  type: TYPE_NORMAL
- en: Varnish will respect the cache headers values unless it is told not to. So whenever
    a content should be cached and it is not, check the response headers for any indication
    of a `no-store`, `no-cache`, or maybe an already expired time value.
  prefs: []
  type: TYPE_NORMAL
- en: Invalidating cached content (Should know)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up until now, we have only seen ways of caching contents of your website, but
    delivering stale data to clients is undesirable when an updated version of that
    content has already been deployed—this is actually worst than not having a cache
    at all.
  prefs: []
  type: TYPE_NORMAL
- en: A simple example of bad content (stale) is the representation of a product that
    is on sale, and after the discount expires, the server keeps showing its discounted
    value. Since you would not cache a sensitive portion of your website, like the
    shopping cart, the user would see a discount price at the product detail page
    and a higher price at the shopping cart.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are actually two ways of invalidating cached contents, and it is very
    important that you understand the difference between them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Purge**: It is used to remove a single object from cache and must be implemented
    inside both the `vcl_hit` and `vcl_miss` subroutines. A single object can contain
    multiple cached versions if the content is delivered with a `vary` header, and
    the purge method will remove all existing variations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ban**: It is useful for removing large amounts of contents at the same time
    by using regular expressions as match. In case you need to ban all JPEGs (`.jpg`)
    or any other regex match, the ban method is faster than the purge method because
    the latter will invalidate them one by one, thus taking a lot longer to process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be aware that while the purge will remove the content from cache, the ban method
    does not remove it right away—what it actually does is create a ban list that
    is checked every time a request comes, trying to find out if the content should
    be delivered from cache or if a newer version should be fetched from the backend
    server. At this point, you must probably have concluded that this will generate
    extra workload and a big ban list filter may increase the load on your server.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Purge:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When using any method of invalidation, it is always a good idea to have an **Access
    Control List** (**ACL**) with the authorized hosts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding example, we are adding `localhost` and all hosts from the `10.1.0.0`
    and `172.16.11.0` networks to an ACL called `purge` (you can name the ACL any
    way you want).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Even though the `PURGE` method is not present in the HTTP protocol, it is actually
    a `GET` method with a different name that is used to direct requests to the purge
    method inside the VCL.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The exact requested object might not generate a hit and a variant of that object
    might be in cache, so using the purge method inside the `vcl_miss` subroutine
    is necessary to remove all variants.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Ban:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ban can be done through VCL code:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'But, it can also can be done through the varnish CLI:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While you may increase the ttl of cached objects in hope that it will improve
    the chances of a cache hit, serving stale content is bad and should be avoided
    at any cost. Implementing a cache invalidation policy is as important as getting
    objects into cache and should be treated as a top priority.
  prefs: []
  type: TYPE_NORMAL
- en: You should always purge content whenever your application server receives an
    update to its own entities. Since this behavior is not always present in legacy
    systems, you may need to remove stale data using the varnish CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Compressing the response (Become an expert)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HTTP compression can be described as a way to reduce the transferred data between
    servers and client. Reducing the amount of transmitted data will result in a faster
    loading website, and in the new cloud datacenter era, it may even reduce your
    network usage costs.
  prefs: []
  type: TYPE_NORMAL
- en: Compression can be performed mainly on text content such as HTML, CSS, JS, XML
    files, but it does not mean that other type of files cannot be compressed. A common
    mistake is to compress files that are already natively compressed, such as a PNG
    image file. This odd behavior will only reduce performance as the compression
    and decompression processes will actually consume more time and will not result
    in a smaller file.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Only after Version 3.0 of the Varnish Cache, the gzip compression method is
    possible and is definitely encouraged.
  prefs: []
  type: TYPE_NORMAL
- en: Varnish default behavior is to compress the response before delivering it to
    the client, searching for the presence of the `accept-encoding` header in the
    request. You can change this behavior by setting the `http_gzip_support` parameter
    in the Varnish daemon.
  prefs: []
  type: TYPE_NORMAL
- en: Even if the `accept-encoding` header is present in the request, this does not
    guarantee that the cached object will be stored as a compressed representation.
    In the following section, we will compress objects before inserting them into
    cache.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Compressing before storing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting the `do_gzip` variable to `true` inside the `vcl_fetch` subroutine will
    enable the gzip compression before the content is stored.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compressing specific content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should not try to compress files that are already natively compressed such
    as JPEGs, MP3s, and so on, avoiding unnecessary workload.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Compressing the response will result in a smaller network footprint, a faster
    loading time of pages, and in reduced costs if your datacenter charges you for
    network bandwidth usage.
  prefs: []
  type: TYPE_NORMAL
- en: Since most of the search engines will add relevance to faster websites, consider
    this tool as one of the most important implementation inside your VCL code.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring the hit ratio (Become an expert)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Varnish default installation comes with many secondary tools that can make the
    debugging and analysis tasks easier and faster, including `varnishlog` (to access
    the shared memory log), `varnishncsa` (to generate an access log in the apache
    common format), `varnishhist` (to create a histogram with hit-miss along with
    time), `varnishadm` (for administrative interface), and the `varnishstat` that
    we will cover in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the HTTP headers contained inside the requests and responses will
    solve most of the problems you may encounter while debugging. An HTTP header viewer
    such as the Firefox add-on **Live HTTP Headers** will be very helpful to sort
    out why a response is not being cached, but some other type of bugs will take
    extra investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before trying to improve your cache by reducing the number of repeated objects
    in memory and refactoring your VCL code to make it slimmer, take a minute to see
    how well you cache is performing live.
  prefs: []
  type: TYPE_NORMAL
- en: If you Varnish instance has a low hit ratio percentage, you may need to implement
    more aggressive caching policies by forcing to cache static content that is not
    being stored due to a misconfigured header.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Open the `varnishstat` monitoring tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Type in your server console screen the preceding command to execute the Varnish
    statistics tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will be presented with a screen full of statistics and we will go through
    the most important ones here is this section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![How to do it...](img/0403_17_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: The upper left part of the `varnishstat` shows the uptime of the server (Days+Hours:Minutes:Seconds).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Hitrate ratio** indicates the time frame, in seconds, of the collected
    data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **Hitrate avg** numbers show the percentage of hits (multiply by 100) according
    to the time frame right above them.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this example, the hit ratio average was 77 percent for the last 10 seconds,
    as it also was in the remaining time frames.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following data is formatted as:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Raw data / realtime (per second) / since boot (per second)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![How to do it...](img/0403_17_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 8.99 connections accepted per second.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 199.71 requests being made.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The preceding lines show the client connections and requests. The client connections
    are expected to be lower than the requests, since `KeepAlive` headers were sent
    with the connections.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![How to do it...](img/0403_17_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 162.76 cache hits per second.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 33.95 cache misses per second.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A high cache miss counter is the first sign of a bad caching policy that needs
    revision. There is not a magic number when it comes to hit ratio average, but
    if your cache is not effective, there is no point in caching.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![How to do it...](img/0403_17_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 0.00 connections to the backend.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 37.94 connections reused to the backend.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do not be scared if you find out that in the last second no connections were
    made to the backend servers. This is a good sign of connections being reused,
    which avoid unnecessary handshake between servers. We are aiming for a high backend
    reuse.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are many other counters to retrieve information from the statistics about
    the health of your Varnish instance and whether there is a problem with it or
    not. You should pay close attention to the hit ratio and how well Varnish is connecting
    to the backend servers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To quit the `varnishstat` interface just hit *Ctrl* + *C*.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring the hit ratio average, the backend connections and other information
    after a new VCL has been deployed is the key to identifying early problems before
    it crashes and a server restart is required.
  prefs: []
  type: TYPE_NORMAL
- en: The smallest mistake while coding a personalized hash key or misplacing a return
    statement can ruin your cache and make your backend servers go down with the increased
    and unexpected load.
  prefs: []
  type: TYPE_NORMAL
