<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch12"/>Chapter 12. VMware View 5.1</h1></div></div></div><p>At the launch of this book, VMware View 5.0 was being superseded by the VMware View 5.1 release, and despite being a .1 release, the VMware View team added a significant number of features that improve the VMware View performance, scalability, and user experience.<a id="id569" class="indexterm"/>
</p><p>This chapter splits the new features into five main areas as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Platform</li><li class="listitem" style="list-style-type: disc">User experience and client</li><li class="listitem" style="list-style-type: disc">Management and administration</li><li class="listitem" style="list-style-type: disc">Persona management</li><li class="listitem" style="list-style-type: disc">Security</li></ul></div><div><div><div><div><h1 class="title"><a id="ch12lvl1sec01"/>Platform features</h1></div></div></div><p>The platform feature enhancements in VMware View 5.1 are focused on making the storage requirements less dramatic. As a significant portion of this book has been dedicated to streamlining and optimizing the storage requirements, the improvements in VMware View 5.1 are quite welcome.<a id="id570" class="indexterm"/>
</p><div><div><div><div><h2 class="title"><a id="ch12lvl2sec01"/>Content-Based Read Cache (also known as View Storage Accelerator)</h2></div></div></div><p>The<strong> Content-Based Read Cache (CBRC)</strong> feature is native to VMware vSphere 5 and is managed by VMware View. CBRC helps to address some of the typical VDI performance bottlenecks, as well as help to decrease the overall storage cost for VDI.<a id="id571" class="indexterm"/>
</p><p>CBRC is a RAM-based caching solution on a given ESXi host that helps to reduce the number of read I/Os issued to the storage subsystem. By reducing the number of read I/Os issued to the storage subsystem, improved scalability of the storage subsystem and overall performance can be realized. CBRC is completely transparent to the guest OS (vDesktop).<a id="id572" class="indexterm"/>
</p><p>VMware announced that during their tests with CBRC, there was an approximate reduction of boot storm as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">80 percent of peak IOPS</li><li class="listitem" style="list-style-type: disc">45 percent of average IOPS</li><li class="listitem" style="list-style-type: disc">65 percent of peak throughput</li><li class="listitem" style="list-style-type: disc">25 percent of average throughput</li></ul></div><p>These are significant savings of the storage subsystem and should be carefully considered during a VMware View design. It should be noted that CBRC is a feature for read I/Os only.</p><p>There are two components of the cache as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>In-memory cache:</strong> This is configured by the administrator and has a fixed maximum size of 2 GB and default memory reservation of 400 MB<a id="id573" class="indexterm"/></li><li class="listitem" style="list-style-type: disc"><strong>Dynamic cache:</strong> It loads blocks on demand and manages the cache based on access patterns of the various blocks on the VMDK<a id="id574" class="indexterm"/></li></ul></div><p>A digest/metadata table that is maintained on disk for each VMDK disk on the host. The metadata holds information about the various blocks on the VMDK. It can be imagined as a hash table with each hash entry pointing to a particular block.</p><p>Putting the preceding two components together, if there is a read request to a particular block on the VMDK, a hash value is computed, and the in-memory cache is checked to see if the block is present. If it is not present, the hash table is accessed and the appropriate block is loaded into the in-memory cache. If the block is already in the in-memory cache, it is returned back to the user.</p><div><img src="img/1124EN_12_01.jpg" alt="Content-Based Read Cache (also known as View Storage Accelerator)"/></div><p>The additional memory taken up by CBRC itself is treated as a<strong> regression</strong> as far as memory consumption goes. As memory requirements are not as high for CBRC for steady state workload, vSphere characterizes and reduces memory consumption.<a id="id575" class="indexterm"/>
</p><p>CBRC will benefit VDI environments without intelligent arrays and cache management. However, for arrays with read or read/write cache management, CBRC will also help to reduce I/O latency in the storage fabric. As read I/Os are served from in-host RAM, there is no requirement to go out to the network to retrieve data blocks. Additionally, data blocks are retrieved to the guest in terms of microseconds, instead of milliseconds.</p><div><img src="img/1124EN_12_02.jpg" alt="Content-Based Read Cache (also known as View Storage Accelerator)"/></div><p>The preceding diagram highlights the direct access the ESXi host has to its memory, where the CBRC resides. If data must be retrieved from a typical storage array, the request must traverse any paths to have the request fulfilled. The I/O performance improvement delivered by CBRC is clearly noticed by end users while using their desktops. However, it should be duly noted that the majority of I/Os during a steady-state workload are write I/Os, not read I/Os.</p><p>View Storage Accelerator allows host caching of OS Disks and user-persistent disks on linked clone desktops; and administrators also have the ability to specify how often the cache metadata should be regenerated.</p><div><div><div><div><h3 class="title"><a id="ch12lvl3sec01"/>CBRC storage sizing</h3></div></div></div><p>When View Storage Accelerator is enabled (OS Disk, or OS and persistent disk), a per-VMDK digest file is created to store hash information about the VMDK blocks.<a id="id576" class="indexterm"/>
</p><p>The estimated size of each digest file is roughly:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">5 MB per 1 GB of the VMDK size when hash collision detection is Off (default value)</li><li class="listitem" style="list-style-type: disc">12 MB per 1 GB of the VMDK size when hash collision detection is On</li></ul></div><div><img src="img/1124EN_12_03.jpg" alt="CBRC storage sizing"/></div><p>The preceding screenshot shows the existence of the CBRC digest files in a given datastore.</p><div><img src="img/1124EN_12_04.jpg" alt="CBRC storage sizing"/></div><p>Within VMware vCenter's task pane, the creation of a virtual disk digest will also be displayed.</p><p>The digest file creation for a large replica disk can take a reasonable amount of time and IOPS, therefore it is recommended not to run the operation, create new desktop pools, or recompose existing pools during production hours.<a id="id577" class="indexterm"/>
</p><p>As an example, a 25 GB Windows VM replica will consume about 125 MB of storage space for the digest file. For snapshots (deltas) or persistent disks, a snapshot is created for the digest file as well. If a VMDK is cloned, the digest file is copied.</p><p>Due to the fact that Windows-based desktops will have a significant percentage of identical blocks between them, it is safe to assume that performance gains can be realized when using CBRC with full desktop clones. At the time of writing, however, full desktop clones were not supported by CBRC.</p><p>For 5 GB persistent disks, the digest file will be approximately 24 MB.</p></div><div><div><div><div><h3 class="title"><a id="ch12lvl3sec02"/>Host memory sizing</h3></div></div></div><p>CBRC uses a RAM cache to manage the cached disk blocks. The per-VMDK digest file is also loaded in the memory.<a id="id578" class="indexterm"/>
</p><p>CBRC should not be enabled under memory-overcommit environments. If a host is memory overcommitted and CBRC is enabled, the memory pressure is increased as CBRC also uses memory for the cache. In such cases, the host could experience increased swapping and the overall host performance could be impacted. In this scenario, enabling CBRC could actually make the performance worse.</p><p>The following screenshot is a graph demonstrating the moment when CBRC with 512 MB cache is enabled on the host:</p><div><img src="img/1124EN_12_05.jpg" alt="Host memory sizing"/></div><p>As CBRC consumes host memory as part of its architecture, host disk swap and performance degradation can be mitigated by reducing VM density on the hosts themselves. A more favorable approach is to size the hosts appropriately to include the additional RAM required to support the CBRC functionality.<a id="id579" class="indexterm"/>
</p><p>For each VMDK digest created, approximately 24 MB of RAM is consumed in addition to the defined CBRC cache. As an example, if only one system disk is being hashed and the host cache is 500 MB, then 500 MB + 24 MB = total of 524 MB memory will be used.</p><p>It is important to remember that it is possible to create digests for system and persistent disks as well.</p><p>In another example, if 64 VMs were in use, there would be 64 persistent disks, plus 1 replica disk. In this case, we would have 65 VMDK to be hashed. Assuming that host cache is using 2 GB RAM (maximum size), then 2048 MB + (65 * 24 MB) = total of 3.5 GB memory will be used.</p></div><div><div><div><div><h3 class="title"><a id="ch12lvl3sec03"/>Managing CBRC</h3></div></div></div><p>In VMware View, CBRC is under the<strong> Host Caching</strong> tab of<strong> vCenter Server</strong> configuration. It is possible to enable and define the total amount of RAM cache assigned for the host. Each host may have a different cache size, although it is recommended to maintain consistency across the vSphere cluster.<a id="id580" class="indexterm"/>
</p><div><img src="img/1124EN_12_06.jpg" alt="Managing CBRC"/></div><p>During the desktop pool creation process, administrators may define that the pool should use CBRC, the types of disks to have the digest file created for, and how often the digest file should be regenerated.<a id="id581" class="indexterm"/>
</p><div><img src="img/1124EN_12_07.jpg" alt="Managing CBRC"/></div><p>The following options are exposed through<code class="literal"> /config/CBRCFilter/intOpts</code> and is visible through the VMware vSphere Client Advanced Configuration. VMware View has built-in capabilities to manage the following options, and it's recommended not to manually modify any of these items:<a id="id582" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">/config/CBRC/intOpts/DCacheMemReserved:</code> Memory consumed by CBRC data cache (in MB).</li><li class="listitem" style="list-style-type: disc"><code class="literal">/config/CBRC/intOpts/DCacheSize:</code> Size of CBRC data cache (in MB). This cannot be changed if<strong> CBRC.Enable</strong> is set to<strong> 1</strong>.</li><li class="listitem" style="list-style-type: disc"><code class="literal">/config/CBRC/intOpts/DigestJournalBootInterval:</code> Interval (in minutes) for which Digest Journal is temporarily disabled to avoid interfering with the boot process.</li><li class="listitem" style="list-style-type: disc"><code class="literal">/config/CBRC/intOpts/Enable:</code> Enable Content-Based Read Cache.</li></ul></div><p>It is important to note that View Storage Accelerator is not supported under certain conditions, including:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">With View Composer APIs for Array Integration, which is a Tech Preview feature of View 5.1</li><li class="listitem" style="list-style-type: disc">For use with desktops with the Local Mode feature turned on</li><li class="listitem" style="list-style-type: disc">When VMware View replica tiering is enabled.</li></ul></div></div></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec02"/>View Composer Array Integration</h2></div></div></div><p>
<strong>View Composer Array Integration (VCAI)</strong> is a Tech Preview feature in VMware View 5.1, which allows administrators to take advantage of the storage-native snapshot feature within the normal administrative workflow of VMware View and View Composer.<a id="id583" class="indexterm"/>
</p><p>VCAI integrates with<strong> Network-attached storage (NAS)</strong> partner's native cloning capabilities using<strong> vSphere vStorage APIs for Array Integration (VAAI)</strong>. VCAI speeds up provisioning of linked clone virtual desktops in automated pools, helping to offload CPU consumption and network bandwidth.<a id="id584" class="indexterm"/>
</p><div><img src="img/1124EN_12_08.jpg" alt="View Composer Array Integration"/></div><p>It is recommended to read<em> VMware End-User Computing Blog</em> at<a class="ulink" href="http://blogs.vmware.com/euc/2012/05/view-composer-array-integration-tech-preview.html."> http://blogs.vmware.com/euc/2012/05/view-composer-array-integration-tech-preview.html.</a>
<a id="id585" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec03"/>Support 32 (up from 8) hosts in a cluster on NAS</h2></div></div></div><p>Until VMware View 5.1, any vSphere cluster supporting VMware View deployments with linked clones would only allow for clusters with a maximum of 8 hosts. The reason behind the limitation is a VMFS limit on the number of hosts that can concurrently execute I/O operations against a single file; the replica disk.<a id="id586" class="indexterm"/>
</p><p>This was never much of an issue when talking about NFS exports; however, the limitation was hardcoded into View Composer the tool responsible for creating the linked clones.</p><p>With VMware View 5.1, this limitation has been removed and View Composer will support a cluster with 32 hosts if the underlying storage filesystem and protocol is NFS. This change completely modifies the architecture of many VMware View deployments with NFS-based clusters. As this was a late addition to the book, its increased in-host support (from 8 to 32) for NFS will be addressed in a future blog post or addendum.<a id="id587" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec04"/>Standalone View Composer Server</h2></div></div></div><p>VMware View Composer is the software responsible for creating linked clones and may now be installed in a server other than vCenter Server. This move is aiming towards a highly scalable VMware View architecture.<a id="id588" class="indexterm"/>
</p><div><img src="img/1124EN_12_09.jpg" alt="Standalone View Composer Server"/></div><p>The preceding screenshot shows the configuration tab where a standalone View Composer Server can be configured. This is ideal for large environments where the resilience and performance of both the VMware vCenter Server(s) and VMware View Composer Server(s) must be protected.<a id="id589" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec05"/>Customizable disposable disk drive letter</h2></div></div></div><p>VMware View 5.1 has added the ability to specify the drive letter for disposable disks. In the past, the disposable disk would utilize the first available drive letter in the desktop. VMware View can still autoselect the drive letter by leaving the<strong> Drive letter</strong> option set to<strong> Auto</strong> mode, as shown in the following screenshot:<a id="id590" class="indexterm"/>
</p><div><img src="img/1124EN_12_10.jpg" alt="Customizable disposable disk drive letter"/></div><p>The preceding screenshot shows the configuration tab for the disposable disk drive letter.<a id="id591" class="indexterm"/>
</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch12lvl1sec02"/>User experience and client features</h1></div></div></div><p>VMware View 5.1 has a large number of improvements that directly affect the user experience. Both VMware View and Teradici PCoIP continue to evolve with every release. Comparing the end user experience of VMware View 4.x and VMware View 5.1 shows a very significant improvement.<a id="id592" class="indexterm"/>
</p><p>VMware View 5.1 delivers enhancement in several user experience and client areas, including Local Mode and USB redirection.</p><p>The enhancements for VMware View Local Mode are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Multi-monitor support</li><li class="listitem" style="list-style-type: disc">Disk I/O performance improvements and reduced deduplication I/O cost</li><li class="listitem" style="list-style-type: disc">NAT support for DNS over TCP</li><li class="listitem" style="list-style-type: disc">Local Mode disk consistency validations</li><li class="listitem" style="list-style-type: disc">Virtual Hardware Version 8 support</li><li class="listitem" style="list-style-type: disc">Improved NAT, DNS resolution performance, link state propagation</li><li class="listitem" style="list-style-type: disc">One click to send the<em> Ctrl</em> +<em> Alt</em> +<em> Delete</em> keystrokes<a id="id593" class="indexterm"/></li><li class="listitem" style="list-style-type: disc">Automation Support for Point-of-Sale operations</li><li class="listitem" style="list-style-type: disc">Data integrity and security hardening</li></ul></div><p>VMware also reworked the USB stack for Windows clients with VMware View 5.1. The enhancements for USB are as follows:<a id="id594" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Broader device support</li><li class="listitem" style="list-style-type: disc">New filtering mechanism for better management of devices on Client, configurable via Group Policies</li><li class="listitem" style="list-style-type: disc">Multi-platform support for USB View Client</li><li class="listitem" style="list-style-type: disc">New filtering mechanism for better management of devices on Agent, allowing blocking of unwanted devices and blocking of devices that are forwarded by other means (for example, keyboards/smartcards), configurable via Group Policies</li><li class="listitem" style="list-style-type: disc">The device driver for a device no longer needs to be installed on the client machine</li></ul></div><p>There are also a small number of enhancements for PCoIP. These enhancements include reduction in CPU utilization to decode PCoIP frames on the client side, ultimately improving the protocol performance.</p></div>
<div><div><div><div><h1 class="title"><a id="ch12lvl1sec03"/>Management and administration</h1></div></div></div><p>While VMware View has proven to be relatively easy to manage and administer, there have been definite areas for improvement, including basic UI features such as right-click. In VMware View 5.1, there are several improvements to the UI and management of VMware View.<a id="id595" class="indexterm"/>
</p><div><div><div><div><h2 class="title"><a id="ch12lvl2sec06"/>UI enhancements and localization</h2></div></div></div><p>The user interface in VMware View 5.1 has a new look and feel; it's sleeker and faster. VMware View has also been localized to five different foreign languages (French, German, Japanese, Korean, and Simplified Chinese).<a id="id596" class="indexterm"/>
</p><div><img src="img/1124EN_12_11.jpg" alt="UI enhancements and localization"/></div><p>A new right-click functionality has been added to the user interface to help streamline the process of managing desktop pools, entitlements, and desktops.<a id="id597" class="indexterm"/>
<a id="id598" class="indexterm"/>
</p><div><img src="img/1124EN_12_12.jpg" alt="UI enhancements and localization"/></div></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec07"/>Support of pre-created Active Directory Machine Accounts</h2></div></div></div><p>The ability to utilize pre-created Active Directory computer objects is a great addition for organizations that need to create their own Active Directory computer accounts due to security guidelines, or because of automation processes in place to ensure that Active Directory objects are created upon the user joining the organization, as an example.<a id="id599" class="indexterm"/>
</p><div><img src="img/1124EN_12_13.jpg" alt="Support of pre-created Active Directory Machine Accounts"/></div><p>The preceding screenshot shows the configuration tab for allowing the use of pre-existing Active Directory computer accounts.<a id="id600" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec08"/>VMware vCenter and View Composer Advanced Settings</h2></div></div></div><p>The VMware View user interface now allows administrators to specify the maximum concurrent number of provisioning and maintenance operations. Previously, only power and vCenter concurrent operations were available for configuration via the user interface.<a id="id601" class="indexterm"/>
</p><p>It is recommended not to change the default settings in the production environment as it could affect the user experience; this is because an environment under heavy provisioning or maintenance tasks could generate significant IOPS, impacting all of the current users.</p><div><img src="img/1124EN_12_14.jpg" alt="VMware vCenter and View Composer Advanced Settings"/></div><p>The preceding screenshot shows the configuration tab for specifying advanced operation maximums.<a id="id602" class="indexterm"/>
</p></div><div><div><div><div><h2 class="title"><a id="ch12lvl2sec09"/>Phone home</h2></div></div></div><p>This is an opt-in option during install time for anonymous VMware View usage statistics collection. All data is made anonymous and untraceable, and phone home will collect information on versions, features used, system architecture choices, and deployment scale.<a id="id603" class="indexterm"/>
</p><p>VMware aims to use this information to provide better support and more enhancements to the most popular features. In addition, VMware believes that this data collection will allow for better alignment of View product R&amp;D priorities to match the customer use out in the field.</p><div><img src="img/1124EN_12_15.jpg" alt="Phone home"/></div><p>The preceding screenshot shows the configuration tab for enabling phone-home support (Participate<strong> anonymously in the user experience improvement program)</strong>.<a id="id604" class="indexterm"/>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch12lvl1sec04"/>Persona management</h1></div></div></div><p>Persona management has also received enhancement in VMware View 5.1. While many organizations will continue to use third-party solutions such as Liquidware Labs ProfileUnity, the native persona management in VMware View is starting to evolve into a more acceptable solution. The enhancements in View 5.1 to persona management include:<a id="id605" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Allowing virtual profile management of physical machines</li><li class="listitem" style="list-style-type: disc">A one-time Windows XP to Windows 7 migration capability</li></ul></div><p>VMware View Persona Management now offers profile support on physical machines to help a user's transition from physical to VMware View desktops. As mentioned earlier in this book, extracting the user profile from a vDesktop (as is typical in a non-persistent solution) allows for an easier migration from a physical desktop to a vDesktop.</p><p>During a physical to virtual migration, the administrator can first install View Persona Management on the physical desktop, and when the user uses a virtual desktop with persona management enabled, user data and settings are automatically synchronized.</p><p>VMware also provides support for a one-time Windows XP to Windows 7 migration.</p></div>
<div><div><div><div><h1 class="title"><a id="ch12lvl1sec05"/>Security</h1></div></div></div><p>Security was a big topic addressed in VMware View 5.1, including security hardening and fixes. Security is a big driver for many organizations to adopt VDI. The continued improvements in the security area of the product highlight VMware's commitment to highly-secured environments. The release of View 5.1 includes the following security enhancements:<a id="id606" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Support for multiple two-factor authentication with RADIUS Support, including vendors such as RSA SecurID, VASCO DIGIPASS, SMS Passcode, SafeNet, and others.</li><li class="listitem" style="list-style-type: disc"><strong>VMware View Administrator session timeout:</strong> The session timeout option was always there, but now it is an option that can be configured by the administrator.</li><li class="listitem" style="list-style-type: disc"><strong>SSL certificate security enhancements:</strong> VMware View 5.1 now alerts when self-signed certificates are used. Administrators will have to validate the use of self-signed certificates. VMware recommends that trusted<strong> certification authority (CA)</strong> services should be used.<a id="id607" class="indexterm"/><div><img src="img/1124EN_12_16.jpg" alt="Security"/></div></li></ul></div><p>The preceding screenshot shows the configuration tab for enabling the VMware View Administrator<strong> Session timeout</strong>.</p><div><img src="img/1124EN_12_17.jpg" alt="Security"/></div><p>The preceding screenshot shows an error generated from using self-signed certificates.<a id="id608" class="indexterm"/>
</p></div>
<div><div><div><div><h1 class="title"><a id="ch12lvl1sec06"/>Summary</h1></div></div></div><p>VMware continues to evolve the View product through acquisition, internal R&amp;D, customer feedback, support from partners such as Teradici, and involvement from the community. As this book was already completed and in the final publishing process when View 5.1 was released, the authors felt it was important to have an overview of the new content. For additional reading, please refer to the blogs<a class="ulink" href="http://myvirtualcloud.net/"> http://myvirtualcloud.net/</a> and<a class="ulink" href="http://www.thinkvirt.com/"> http://www.thinkvirt.com/</a>.</p></div></body></html>