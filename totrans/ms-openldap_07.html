<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Multiple Directories</h1></div></div></div><p>In the previous chapters we were focused on using a single directory server. But in a networked environment, you may need to configure multiple directory servers to interoperate. In this chapter we will be looking at different ways of getting directory servers to interoperate over a network.</p><p>While the focus of this book is OpenLDAP, many of the strategies presented here can be adopted to integrate OpenLDAP with other LDAP directory servers, such as The Apache Directory Server, Fedora DS, Microsoft's Active Directory, and the Novell Directory Server (NDS).</p><a class="indexterm" id="id720"/><p>The two main processes we will look at are replication (creating a mirror of a directory information tree on another directory server) and proxying (allowing one directory server to act as an intermediary between an LDAP client and another directory server). In this chapter we will cover:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The basics of synchronizing and replicating directories</li><li class="listitem" style="list-style-type: disc">Directory replication with SyncRepl</li><li class="listitem" style="list-style-type: disc">Proxying with the <code class="literal">ldap</code> backend</li><li class="listitem" style="list-style-type: disc">Adding caching with the Proxy Cache overlay</li><li class="listitem" style="list-style-type: disc">Using the <code class="literal">transparency</code> overlay to create a hybrid cache</li></ul></div><p>In this chapter we will be working with two servers—one that will host the authoritative copy of the directory, and another that will synchronize itself over the network with the authoritative copy.</p><div><div><div><div><h1 class="title"><a id="ch07lvl1sec39"/>Replication: An Overview</h1></div></div></div><a class="indexterm" id="id721"/><p>Sometimes it is desirable to have multiple identical copies of a directory server. This can be particularly effective in cases where LDAP servers sustain large volumes of traffic, where fail-over protection is required, or in cases where LDAP clients are geographically dispersed, and having local copies of a directory would greatly expedite service. These are cases where LDAP replication can provide a solution.</p><p>
<strong>Replication</strong> is the process of configuring two or more directories to contain the same directory information tree (or portion of the directory tree), and to keep the multiple copies of the directory data synchronized over time. This has been a central feature of the OpenLDAP suite since its inception. In fact its predecessor, the University of Michigan LDAP Server, implemented replication early on and, because of this, replication has long been considered a standard task for an LDAP server.</p><a class="indexterm" id="id722"/><a class="indexterm" id="id723"/><a class="indexterm" id="id724"/><p>In the standard LDAP model, replication is done in a hierarchy. One server is considered the <strong>master server</strong> (or the <strong>master DSA</strong> (Directory Server Agent), sometimes called the <strong>provider</strong>)<a class="indexterm" id="id725"/>. This server is responsible for maintaining the canonical version of the directory information tree.</p><a class="indexterm" id="id726"/><a class="indexterm" id="id727"/><a class="indexterm" id="id728"/><p>Beneath the master server are one or more <strong>shadow servers</strong> (sometimes called <strong>consumer</strong>, <strong>replica</strong>, or <strong>slave servers</strong><a class="indexterm" id="id729"/>
<a class="indexterm" id="id730"/>). A shadow server holds a replica of the master server's directory information tree, and clients can connect to the shadow server and perform searches of the directory information tree (DIT). Let's have a look at the following figure:</p><div><img alt="Replication: An Overview" src="img/1021_07_01.jpg"/></div><p>For<a class="indexterm" id="id731"/> all practical purposes, shadow servers have read-only features. While the shadow servers can handle many LDAP operations, shadow servers are not allowed to alter the records in the replicated directory information tree. When add, modify, or delete operations are received, for instance, the shadow server will return a <strong>referral</strong> to the client, directing it to contact the master server instead. A referral is a special type of response that directs the client to contact another server to perform that operation. Configuring a referral to point from a shadow server to a master server is a simple matter of adding a <code class="literal">referral</code> directive to the <code class="literal">slapd.conf</code> file.</p><p>When a client receives a referral it has the information it needs to re-try the operation on the correct server.</p><p>Why not allow writing to the slaves? Allowing multiple servers to accept all the modifications, additions, and deletions makes it possible for the directory information tree to taken on inconsistent states. What happens if two directory servers change an attribute at the same time? Or if one modifies a record that another is simultaneously deleting? By allowing write operations only on the master server, it is much easier to keep the many replicas consistent.</p><div><div><h3 class="title"><a id="note123"/>Note</h3><p>In the 2.4 release of OpenLDAP, it will be possible to configure <strong>multimaster</strong> which will allow multiple servers to act as masters. As with all multimaster configurations, there will be risks that certain inconsistencies arise, but these risks should be minimized.</p></div></div><p>In<a class="indexterm" id="id732"/> OpenLDAP there are two different ways to implement replication. The first is by configuring the master server to keep the shadow servers updated. This<a class="indexterm" id="id733"/> is called the <em>push</em> method. The second is to configure the slaves to periodically check the master for changes, and update itself accordingly; this is called the <em>pull</em> method.</p><a class="indexterm" id="id734"/><p>Until OpenLDAP 2.2, the first model was the only model supported in OpenLDAP, and it was done through a stand-alone server called SLURPD. But SLURPD suffered from a number of problems and inefficiencies, and is now deprecated. It will be removed from OpenLDAP 2.4. If you are interested in using it to retain backward compatibility see the <em>OpenLDAP</em> <em>Administrator's</em> <em>Guide</em> at <a class="ulink" href="http://openldap.org">http://openldap.org</a>.</p><p>As SLURPD aged the OpenLDAP developers began working on a better, more robust way of replicating directories. The result was the new Syncrhonization-Replication (SyncRepl) model, which uses the LDAP synchronization protocol to keep shadow directories synchronized with a master server.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec90"/>SyncRepl</h2></div></div></div><p>In<a class="indexterm" id="id735"/>
<a class="indexterm" id="id736"/> OpenLDAP 2.2, the developers released a new, experimental form of replication called <strong>LDAP Synchronization-Replication</strong>, or <strong>SyncRepl</strong> for short. This method was both more reliable and more configurable, and it was further refined and designated stable when OpenLDAP 2.3 was released. It is now the preferred way of handling replication for OpenLDAP servers.</p><p>Unlike<a class="indexterm" id="id737"/> the SLURPD replication process, SyncRepl does not require a second daemon process. The SLAPD server implements the shadow server portion of the code, and the provider services (for the master server) are provided in an overlay. SyncRepl can use either a shadow-from-master pull or a hybrid pull/push method.</p><p>In<a class="indexterm" id="id738"/> the pull scenario (called the <strong>refresh-only operation</strong>), the shadow server periodically connects to the master server and requests all changes since the last time it checked. The master then sends the shadow all changed records (or, in the case of deletions, the DN of the deleted record).</p><p>SynRepl's<a class="indexterm" id="id739"/> second method (called <strong>refresh and persist</strong>) is a hybrid of the push features exemplified in the SLURPD model and some of the pull features discussed above (therefore it is not a <em>true</em> push method).</p><p>In this scenario, the shadow server makes an initial connection to the master and pulls some initial updates. But it leaves the connection open. When the master modifies its copy of the directory information tree, it pushes information to the shadow server using that open connection. If the shadow server gets disconnected, the master server does nothing. The next time the slave server connects though, it requests all new changes (like in the pull method), and the master sends them.</p><div><div><h3 class="title"><a id="note124"/>Note</h3><p>For more detailed information about LDAP content synchronization and the SyncRepl implementation included in OpenLDAP, see RFC 4533 (<a class="ulink" href="http://www.rfc-editor.org/rfc/rfc4533.txt">http://www.rfc-editor.org/rfc/rfc4533.txt</a>) and the <em>OpenLDAP Administrator's Guide</em> at <a class="ulink" href="http://openldap.org">http://openldap.org</a>.</p></div></div><p>The SyncRepl model has some distinct advantages over SLURPD:</p><div><ol class="orderedlist arabic"><li class="listitem"><a class="indexterm" id="id740"/>Since the shadow server initiates connections and handles updates, a network outage does not cause problems with the reliability of the directory information tree. The next time the slave can get back on line it will retrieve all of its updates.</li><li class="listitem">There is rarely any need to interrupt service on the master server. When a new shadow server first connects to the master it downloads the entire directory information tree, so there is no need to dump the data from the master server and send it to the shadow (though that method is still supported, and it might be expedient in cases where there is a large directory information tree and a slow network connection).</li><li class="listitem">The flexibility in choosing between the refresh-only and refresh-and-persist operations gives you the ability to choose a model that will best match your needs.</li></ol></div><p>Each mode of replication has its advantages. In highly distributed networks, the refresh-only replication tends to work better as it doesn't require keeping a constant connection open across a large and unpredictable network. But since the shadow server only checks the master periodically, there can be a lag between when the master is updated and when the shadow picks up the changes. Most times this does not cause any problems.</p><p>On a reliable LAN, the refresh-and-persist (refreshAndPersist) replication may be a better choice—especially if it is important that changes get from the master to the shadow in a minimal amount of time. As soon as the master is changed, it will send the updates to the shadow server. This means that there is less waiting time.</p><div><div><h3 class="title"><a id="note125"/>Note</h3><p>Even in the refresh-and-persist (refreshAndPersist) operation, a network outage is not catastrophic. The shadow server will simply attempt to re-connect to the master server, retrieving updates as soon as it successfully connects.</p></div></div><p>These comments are intended to serve as general guidelines. Since it is fairly easy to try both, you may want to experiment to see what works best for you. Generally, on a LAN, refresh-and-persist is the best choice, while on slower links, refresh-only is better. In the next section we will cover the process of configuring SyncRepl between a master and a shadow copy.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec40"/>Configuring SyncRepl</h1></div></div></div><p>The<a class="indexterm" id="id741"/> SLAPD server comes with all of the functionality necessary for implementing a shadow server, and the <code class="literal">syncprov</code> overlay provides the functionality for implementing a master server.</p><div><div><h3 class="title"><a id="note126"/>Note</h3><p>SyncRepl was introduced in OpenLDAP 2.2, but configuration was significantly different. SyncRepl should be avoided in production environments running OpenLDAP 2.2.</p></div></div><p>Getting SyncRepl running requires configuration on both the master and the shadow server. The configuration directives for both are added to the backend sections of the <code class="literal">slapd.conf</code> files.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec91"/>Configuring the Master Server</h2></div></div></div><p>The<a class="indexterm" id="id742"/>
<a class="indexterm" id="id743"/> first thing we will do is configure one server as a master. This server will listen for replication requests from our shadow server and will send updates as requested. Throughout this book we have been configuring a SLAPD server. Now we will use that server as the master.</p><p>The functionality of the master server is implemented in an overlay called <code class="literal">syncprov</code> (which is short for <strong>Synchronization Provider</strong>). We need to load and configure that overlay.</p><p>Since our SLAPD server is built using modules, the first step is to add a module-loading instruction near the top of the <code class="literal">slapd.conf</code> file:</p><div><pre class="programlisting">modulepath      /usr/local/libexec/openldap
moduleload      back_hdb
moduleload      refint
moduleload      unique
moduleload      accesslog
<strong>moduleload      syncprov</strong>
</pre></div><p>When the directory server is restarted the <code class="literal">syncprov</code> module will be loaded. Now we need to make some changes to the configuration section for database that we are going to replicate. The main portion of this directory configuration looks something like this:</p><div><pre class="programlisting">database  hdb
suffix  "dc=example,dc=com"
rootdn  "cn=Manager,dc=example,dc=com"
rootpw  secret
directory  /var/lib/ldap
#directory  /usr/local/var/openldap-data
index  objectClass  eq
index  cn  eq,sub,pres,approx
index  uid  eq,sub,pres
index  sn  eq,sub,approx
index  member  eq</pre></div><a class="indexterm" id="id744"/><p>Now we want to set this database up for SyncRepl.</p><p>The first thing to add is a few additional indexes. These indexes will track a pair of operational attributes that are frequently accessed in the SyncRepl process: the <code class="literal">entryCSN</code> attribute, and the <code class="literal">entryUUID</code> attribute.</p><p>The <code class="literal">entryCSN</code> attribute is used to store a <strong>Change Sequence Number (CSN)</strong> in each record. The value of <code class="literal">entryCSN</code> is basically a fine-grained time stamp that indicates when the attribute was last modified. The <code class="literal">entryUUID</code> attribute, the second attribute, contains a (universally) unique identifier for that entry, and can be used to quickly identify corresponding entries on master and shadow servers. Like any other attributes, these attributes can be retrieved through an LDAP search:</p><div><pre class="programlisting">$ ldapsearch -LLL -U matt "(uid=matt)" entryCSN entryUUID
SASL/DIGEST-MD5 authentication started
Please enter your password: 
SASL username: matt
SASL SSF: 128
SASL installing layers

dn: uid=matt,ou=Users,dc=example,dc=com
<strong>entryUUID: bec1eb70-c5b0-102a-81bf-81bc30f92d57</strong>
<strong>entryCSN: 20070122003136Z#000000#00#000000</strong>
</pre></div><p>When SyncRepl searches for these attributes it does equality checking, so we should configure an index for performing equality tests:</p><div><pre class="programlisting">index entryCSN,entryUUID eq</pre></div><p>This <code class="literal">index</code> directive, which configures two equality indexes—one for each attribute—can be added to the <code class="literal">slapd.conf</code> file just beneath the other <code class="literal">index</code> directives.</p><p>Next we need to load and configure the <code class="literal">syncprov</code> overlay. There are only two configuration directives generally used by this overlay, so our complete overlay configuration for the master server looks like this:</p><div><pre class="programlisting">overlay syncprov
syncprov-checkpoint 50 10
syncprov-sessionlog 100</pre></div><p>The first line loads the <code class="literal">syncprov</code> overlay. The second line specifies how often SyncRepl information ought to be written to the database. Just as with the BDB and HDB backends, SyncRepl is tuned to perform operations as fast as possible. Writing to the underlying database<a class="indexterm" id="id745"/> is costly, so streamlining the process can improve performance.</p><p>The <code class="literal">syncprov-checkpoint</code> directive instructs the overlay to only write changes to the database when a new write request comes in and either a certain number of writes have already occurred (<code class="literal">50</code> in this case), or a certain number of minutes (<code class="literal">10</code>) has elapsed.</p><p>The second directive, <code class="literal">syncprov-sessionlog</code>, specifies how many modifications and deletions ought to be stored in the session log. The master uses information in this log to determine what information needs to be sent to the shadow servers. In this case, it will store the latest 100 modifications and deletions.</p><p>Our finished configuration looks something like this:</p><div><pre class="programlisting">##############################
# Database 1: Example.Com

database        hdb
suffix          "dc=example,dc=com"
rootdn          "cn=Manager,dc=example,dc=com"
rootpw          secret
directory      /var/lib/ldap
#directory       /usr/local/var/openldap-data
index   objectClass     eq
index   cn      eq,sub,pres,approx
index   uid     eq,sub,pres
index   sn      eq,sub,approx
index   member  eq
index   entryCSN,entryUUID      eq

overlay syncprov
syncprov-checkpoint 50 10
syncprov-sessionlog 100</pre></div><p>Once modifications to <code class="literal">slapd.conf</code> are finished it is a good idea to run <code class="literal">slaptest</code> to make sure the configuration file can be parsed, and then (for good measure) run <code class="literal">slapindex</code> to update the index files.</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec93"/>Creating a SyncRepl User</h3></div></div></div><p>The<a class="indexterm" id="id746"/>
<a class="indexterm" id="id747"/> last thing we need to do to prepare the master server is create a special account for synchronization. The shadow server will connect to the master using this account.</p><p>We will create an account similar to the one we use for performing authentication:</p><div><pre class="programlisting">dn: uid=syncrepl,ou=System,dc=example,dc=com
uid: syncrepl
ou: System
userPassword: secret
description: Special account for SyncRepl.
objectClass: account
objectClass: simpleSecurityObject</pre></div><p>We can load this record with the <code class="literal">ldapadd</code> client:</p><div><pre class="programlisting">
<strong>  $ ldapadd -U matt -f syncReplUser.ldif</strong>
</pre></div><p>In order for the replication account to work, it will also need permissions to update the requisite entries in the directory. This means that the ACLs must grant this user the permissions. While we could spell out detailed ACLs as we did in Chapter 4, for the sake of expedience we will just add the new SyncRepl user to the <code class="literal">cn=LDAP</code> <code class="literal">Admins</code> group with <code class="literal">ldapmodify</code>:</p><div><pre class="programlisting">$ ldapmodify -U matt
SASL/DIGEST-MD5 authentication started
Please enter your password: 
SASL username: matt
SASL SSF: 128
SASL installing layers

<strong>dn: cn=LDAP Admins, ou=Groups, dc=example,dc=com
changetype: modify
add: uniqueMember
uniqueMember: uid=syncrepl,ou=system,dc=example,dc=com</strong>

modifying entry "cn=LDAP Admins, ou=Groups, dc=example,dc=com"</pre></div><p>Now, the <code class="literal">uid=syncrepl</code> user is a member of the LDAP administrators group, and the ACLs that apply to that group will also apply to our new user.</p><p>That is all there is to configuring the directory to act as a master. Next, we will configure the shadow server.</p></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec92"/>Configuring the Shadow Server</h2></div></div></div><p>We<a class="indexterm" id="id748"/>
<a class="indexterm" id="id749"/> will configure our shadow server to use <code class="literal">refreshOnly</code> replication, where the slave server periodically checks the master for updates and, if it finds any, retrieves the changes and loads them into its own directory tree.</p><p>Our shadow server will be a fresh instance of SLAPD, running on another server on the same LAN. Let's start with a basic <code class="literal">slapd.conf</code> file. We will change this file as we configure SyncRepl:</p><div><pre class="programlisting"># slapd.conf - Configuration file for LDAP SLAPD
##########
# Basics #
##########
include  /etc/ldap/schema/core.schema
include  /etc/ldap/schema/cosine.schema
include  /etc/ldap/schema/inetorgperson.schema
include  /etc/ldap/schema/blog.schema

pidfile  /var/run/slapd/slapd.pid
argsfile  /var/run/slapd/slapd.args
loglevel none

modulepath /usr/lib/ldap
moduleload back_hdb

#############################
# BDB Database Configuration #
##############################
# Database 1: Example.Com

database  hdb
suffix  "dc=example,dc=com"
rootdn  "cn=Manager,dc=example,dc=com"
#rootpw  secret
directory  /var/lib/ldap
index  objectClass,member eq
index  cn,uid,sn  eq,sub
index  entryCSN,entryUUID eq

#include  /usr/local/etc/openldap/acl.conf</pre></div><p>This should look familiar, based on the configuration we assembled in Chapters 2 and 3. There are a few things to note though:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">All of the schemas that the master uses must be loaded on the shadow server too.</li><li class="listitem" style="list-style-type: disc">In this case we are going to replicate the entire master directory onto this shadow SLAPD server, so we want the suffix to be the same, <code class="literal">dc=example,dc=com</code>.</li><li class="listitem" style="list-style-type: disc">We do not want a root password for this instance. All updates will come from the master, and we do not want any changes to be made locally.</li><li class="listitem" style="list-style-type: disc">There is no requirement that the indexes be the same on the master and the shadow server (in fact, there is no requirement that the master and shadow server even run the same database backends), but we do want to make sure that <code class="literal">objectclass</code>, <code class="literal">entryCSN</code>, and <code class="literal">entryUUID</code> are all indexed, since those are important for SLAPD's performance.</li></ul></div><p>This basic <code class="literal">slapd.conf</code> file should be capable of running a stand-alone server. But we don't want to run a stand-alone server; we want it to get its information from, and stay synchronized with, the master server.</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec94"/>
<a class="indexterm" id="id750"/>The syncrepl Directive
</h3></div></div></div><p>When<a class="indexterm" id="id751"/>
<a class="indexterm" id="id752"/> a shadow SLAPD server performs its synchronization operations, it acts like a special sort of LDAP client. It binds to the master server and performs LDAP operations—usually the special LDAP synchronization operation defined in RFC 4533.</p><p>It should come as no surprise then, to find that configuring a shadow server to act like a SyncRepl consumer is similar to configuring other LDAP clients. Most of the configuration has to do with providing information about how the shadow should bind to the master and how it should perform searches.</p><p>The majority of the configuration work for implementing a shadow server is done with one <code class="literal">slapd.conf</code> directive: <code class="literal">syncrepl</code>. This directive takes a number of parameters, in <code class="literal">name=value</code> format, that specify how the shadow server is to behave. Here is a <code class="literal">syncrepl</code> directive that contains all of the parameters necessary to perform basic synchronization. In the <code class="literal">slapd.conf</code> file, this directive goes in the database configuration section for our <code class="literal">example.com</code> backend:</p><div><pre class="programlisting">syncrepl rid=001
  provider=ldap://directory.example.com 
  type=refreshOnly
  interval=00:00:05:00
  searchbase="dc=example,dc=com"
  binddn="uid=syncrepl,ou=system,dc=example,dc=com"
  credentials=secret</pre></div><p>This directive provides the minimum configuration necessary to make SyncRepl work. The directive has seven name/value parameters: <code class="literal">rid</code>, <code class="literal">provider</code>, <code class="literal">type</code>, <code class="literal">interval</code>, <code class="literal">searchbase</code>, <code class="literal">binddn</code>, and <code class="literal">credentials</code>.</p><p>The first parameter is <code class="literal">rid</code>, the <strong>Replica Identifier (RID)</strong>. This three-digit number must be unique among all of the shadow servers that use the same master server. The master SLAPD instance uses the RID to track which consumer servers are contacting it. Typically, it is best start with a low RID number and increment it for each shadow server. Thus, <code class="literal">rid=001</code> indicates that this is the first shadow server. If we were to add a second shadow copy it would be <code class="literal">rid=002</code>.</p><div><div><h3 class="title"><a id="note127"/>Note</h3><p>In earlier versions of OpenLDAP the master had to contain a list of all RIDs for its consumer servers. That is no longer necessary.</p></div></div><p>The provider parameter should contain the LDAP URL for the master. Either <code class="literal">ldap://</code> or <code class="literal">ldaps://</code> protocols can be used. The host portion can be either a host name or an IP address, and an optional port can be added to the end, separated by a colon. For example, to connect to a master using LDAPS over a non-standard port you could use a provider like this: <code class="literal">ldaps://10.0.1.34:6868</code>. Note that only this simple form of LDAP URL can be used. The complete LDAP URL syntax, such as containing a base DN, search filter, and so on, is not supported here.</p><div><div><h3 class="title"><a id="tip2543612635"/>Tip</h3><p><strong>Using StartTLS instead of SSL/TLS</strong></p><p>You can configure the shadow server to connect over LDAP (unencrypted) and then issue a StartTLS command to begin TLS encryption between it and the master server. To do this, add <code class="literal">starttls=yes</code> (or <code class="literal">starttls=critical</code> if failure to finish TLS negotiation should stop the transaction).</p></div></div><p>The <code class="literal">type</code> parameter determines which of the two replication modes the shadow server will use when connecting to the master. The only acceptable values are <code class="literal">refreshOnly</code> and <code class="literal">refreshAndPersist</code>.</p><p>In our example we used the <code class="literal">refreshOnly</code> option. In a refresh-and-persist configuration the <code class="literal">interval</code> parameter will be ignored.</p><p>Otherwise, there are no significant differences between configuring refresh-only and refresh-and-persist.</p><p>The <code class="literal">interval</code> parameter indicates how long the shadow server will wait before checking the master for updates. This applies to the <code class="literal">refreshOnly</code> mode where the consumer server connects, checks for updates, and then disconnects. It will then wait the period specified by <code class="literal">interval</code> before checking again.</p><p>The syntax for the <code class="literal">interval</code> parameter is <code class="literal">dd:hh:mm:ss</code>, where <code class="literal">dd</code> is number of days to wait, <code class="literal">hh</code> is hours, <code class="literal">mm</code> is minutes, and <code class="literal">ss</code> is seconds. If this parameter is not specified it defaults to one day (<code class="literal">01:00:00:00</code>). A shorter interval is often desirable especially if it is important for shadow servers to provide up-to-date information right away. In the previous example the shadow server will wait five minutes (<code class="literal">00:00:05:00</code>) between checks.</p><div><div><h3 class="title"><a id="tip132132"/>Tip</h3><p>If it is very important for shadow servers to stay closely synchronized, and the shadow is on the same LAN as the master, the refreshAndPersist mode is probably a better fit.</p></div></div><p>One potential difficulty with the <code class="literal">refreshOnly</code> mode arises in the case where the master server becomes unavailable (for example, because of a network outage or a server failure). How should the shadow server behave? In addition to the interval parameter, there is an additional parameter that allows tuning of the refresh interval but this option takes effect only when the master server cannot be reached.</p><p>This parameter, <code class="literal">retry</code>, provides information about what should be done when the shadow server cannot contact the master server. It looks like this: <code class="literal">retry="120</code> <code class="literal">10"</code>. This instructs the shadow server to retry the connection every <code class="literal">120</code> seconds up to <code class="literal">10</code> times when the master server becomes unavailable.</p><div><div><h3 class="title"><a id="tip55858585"/>Tip</h3><p><strong>Using the retry Parameter</strong></p><p>It is a good idea to set the retry parameter in both refresh-only and refresh-and-persist configurations. This will ensure that a brief network failure does not disturb replication.</p></div></div><p>This parameter can take multiple pairs. For example, we can configure it to check a couple of times in short intervals, then (if it still cannot connect) to test again at longer intervals for a longer period of time: <code class="literal">retry="30</code> <code class="literal">10</code> <code class="literal">600</code> <code class="literal">20"</code>. This time, if the shadow server cannot connect to the master it will try to reconnect every <code class="literal">30</code> seconds <code class="literal">10</code> times in a row. If the master still cannot be connected, then it will wait ten minutes (600 seconds), and try again. It will repeat this process twenty more times. But after these attempts the shadow server will give up trying to reach the master.</p><p>To configure the shadow server to test indefinitely—to keep trying until it connects—the special <code class="literal">+</code> (plus) symbol can be inserted in lieu of a retry count. For example, the parameter <code class="literal">retry="60</code> <code class="literal">+"</code> would instruct the shadow SLAPD to try connecting to the master once a minute until it finally succeeds, in which case it will return to its regular timing as set in the <code class="literal">interval</code> parameter.</p><p>After the interval parameter is the <code class="literal">searchbase</code> parameter. This indicates what the base DN for the synchronization request will be. Generally, <code class="literal">searchbase</code> should be the same as the database <code class="literal">suffix</code> directive for the shadow server.</p><p>A shadow server need not replicate the entire directory information tree of the master server. For example, we could have configured the shadow server to just replicate the <code class="literal">ou=users</code> branch with a database configuration like this:</p><div><pre class="programlisting">database    hdb
suffix      "ou=users,dc=example,dc=com"
rootdn      "ou=users,dc=example,dc=com"
directory  /var/lib/ldap
index   objectClass,member eq
index   cn,uid,sn  eq,sub
index   entryCSN,entryUUID eq
include /etc/ldap/acl.conf

syncrepl rid=001
  provider=ldap://directory.example.com 
  type=refreshOnly
  interval=00:00:05:00
  searchbase="ou=users,dc=example,dc=com"
  binddn="uid=syncrepl,ou=system,dc=example,dc=com"
  credentials=secret</pre></div><p>Again, note that <code class="literal">suffix</code> and <code class="literal">searchbase</code> are the same.</p><p>The <code class="literal">searchbase</code> directive is one of several that compose the search specification. We could also use <code class="literal">scope</code>, <code class="literal">filter</code>, <code class="literal">attrs</code>, <code class="literal">attrsonly</code>, <code class="literal">sizelimit</code>, and <code class="literal">timelimit</code> parameters to construct a more complex search specification. Leaving these parameters off though, we have simply accepted the default which performs a search like this:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">scope</code> is set to <code class="literal">sub</code></li><li class="listitem" style="list-style-type: disc">The <code class="literal">filter</code> is set to <code class="literal">(objectclass=*)</code>.</li><li class="listitem" style="list-style-type: disc">The <code class="literal">attrs</code> field is set to <code class="literal">*</code>,<code class="literal">+</code>, which will request all regular and operational attributes</li><li class="listitem" style="list-style-type: disc">No <code class="literal">attrsonly</code> flag is included so both attributes and values are returned</li><li class="listitem" style="list-style-type: disc">The <code class="literal">sizelimit</code> and <code class="literal">timelimit</code> parameters are both set to <code class="literal">unlimited</code></li></ul></div><p>The sixth and seventh parameters in the <code class="literal">syncrepl</code> directive are <code class="literal">binddn</code> and <code class="literal">credentials</code>. These are used to perform a simple bind to the directory.</p><p>When configuring the master server we created the <code class="literal">uid=syncrepl</code> account. Now we will use that same DN to connect from the shadow server to the master. As was noted before, the master server does not automatically grant this account any special privileges; the ACLs on the master will be applied to this account.</p><p>Also, size and time limits will be applied to this user. A frequently made mistake when configuring SyncRepl is to inadvertently subject the SyncRepl user to a size or time limit that is too low. The result of this is that the shadow server may only get part of the directory information tree that it is supposed to have, and will not be able to provide clients with complete directory information.</p><p>If system resources allow, you will typically want to allow the SyncRepl user unlimited time and request size.</p><p>The <code class="literal">credentials</code> parameter, in the case of a simple bind, holds the password.</p><div><div><h3 class="title"><a id="note128"/>Note</h3><p>Our basic configuration uses a simple bind and an unencrypted (plain LDAP) connection. This is not secure. Using StartTLS, SSL/TLS, or an appropriately strong SASL mechanism would provide increased security.</p></div></div><p>Simple binding is not the only type supported for SyncRepl. SASL authentication can also be turned on, though this may require additional parameters:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">bindmethod=sasl</code>: By default, the bind method is set to simple. To enable SASL authentication this parameter must be manually set.</li><li class="listitem" style="list-style-type: disc"><code class="literal">saslmech=&lt;SASL</code> <code class="literal">Mechanism&gt;</code>: This should be set, for example, to <code class="literal">DIGEST-MD5</code> to do MD5 hashing of the password prior to transmitting it. See the SASL section in Chapter 4 for more information.</li><li class="listitem" style="list-style-type: disc"><code class="literal">authcid=&lt;uid&gt;</code>: This should be set to the SASL ID of the account that will be used to authenticate. The (similar) <code class="literal">authzid</code> parameter can be used to configure an alternate authorization account.</li><li class="listitem" style="list-style-type: disc"><code class="literal">credentials=&lt;SASL</code> <code class="literal">Credentials&gt;</code>: The <code class="literal">credentials</code> field is used, in SASL authentication, to pass credential information to the SASL subsystem. In the DIGEST-MD5 mechanism, for example, <code class="literal">credentials</code> holds the account's password.</li><li class="listitem" style="list-style-type: disc"><code class="literal">realm=&lt;SASL</code> <code class="literal">Realm&gt;</code>: Realm information (see Chapter 4) can be passed with this parameter.</li><li class="listitem" style="list-style-type: disc"><code class="literal">secprops=&lt;SASL</code> <code class="literal">Security</code> <code class="literal">Props&gt;</code>: Additional SASL security properties can be passed with this parameter.</li></ul></div><p>Finally, it should be noted that by default, during a SyncRepl operation, the shadow server does not perform schema checking on the records that it receives from the master. In other words, if the master sends the shadow server a record that violates schema constraints, the shadow server will simply store the errant record, making no attempt to validate or reject it.</p><p>Usually, it is desirable to have schema checking disabled. Since the master server should always be doing schema checking a second set of identical checks is redundant, and it slows down the replication process. However, on rare occasions it may be desirable to have that extra layer of evaluation. Schema checking of replicated records can be enabled in the <code class="literal">syncrepl</code> directive by adding the <code class="literal">schemachecking=on</code> parameter.</p></div><div><div><div><div><h3 class="title"><a id="ch07lvl3sec95"/>Configuring a Referral</h3></div></div></div><a class="indexterm" id="id753"/><a class="indexterm" id="id754"/><p>Operations that write to a replicated directory information tree can only be done on the master server. You cannot, for example, change an attribute by connecting to a shadow server and performing an LDAP add operation. In other words, shadow servers are effectively read-only.</p><p>If a client attempts to modify an entry on a shadow server, that server will respond that it will not perform the modification:</p><div><pre class="programlisting">$ ldapmodify -x -W -D "uid=matt,ou=users,dc=example,dc=com" -H \
    ldap://localhost
Enter LDAP Password:

dn: uid=matt,ou=users,dc=example,dc=com
changetype: modify
replace: description
description: testing modify against shadow.

modifying entry "uid=matt,ou=users,dc=example,dc=com"
<strong>ldap_modify: Server is unwilling to perform (53)</strong>
<strong>    additional info: shadow context; no update referral</strong>
</pre></div><p>In this example, when we tried to modify the description attribute value for our own record, the server responded with <code class="literal">unwilling</code> <code class="literal">to</code> <code class="literal">perform</code> error.</p><p>While a shadow server cannot allow updates of its own data, it can be configured to redirect the client to the master server. This is done by adding an additional directive to the database section (typically just below the <code class="literal">syncrepl</code> directive) to indicate what server requests should be redirected to. The directive looks like this:</p><div><pre class="programlisting">updateref ldap://directory.example.com </pre></div><p>Now, when a client attempts to perform a write operation, instead of receiving an error, it will receive a referral:</p><div><pre class="programlisting">$ ldapmodify -x -W -D "uid=matt,ou=users,dc=example,dc=com" -H \ 
    ldap://localhost
Enter LDAP Password:

dn: uid=matt,ou=users,dc=example,dc=com
changetype: modify
replace: description
description: testing modify against shadow.

modifying entry "uid=matt,ou=users,dc=example,dc=com"
ldap_modify: Referral (10)
  referrals:
    ldap://directory.example.com/uid=matt,ou=users,dc=example,dc=com </pre></div><p>Many clients can be configured to do what is called <strong>referral chasing</strong>. That is, when they receive a referral they can automatically follow the referral. In a case like the given one, the client would automatically attempt the modification operation against the master server at <code class="literal">directory.example.com</code>.<a class="indexterm" id="id755"/>
</p></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec93"/>Starting Replication</h2></div></div></div><a class="indexterm" id="id756"/><p>At this point we have taken a close look at both the master and shadow configuration options for SyncRepl. Now we are ready to turn things on.</p><p>Once the master server is configured it must be restarted for the configuration changes to take effect. Once the <code class="literal">syncprov</code> overlay is loaded, SLAPD will be functioning as a master. This should all be done before starting up the configured consumer server, otherwise the shadow server will try to fetch information from the master, but the master will not have the necessary LDAP operation available.</p><p>After the master is running again the shadow server can be started. For a small to medium-sized directory on a network with decent bandwidth, there is no reason to manually load any directory data into the shadow server. Instead, when the shadow server initially contacts the master, it will fetch a fresh copy of the directory information tree (to the extent that the master's ACLs allow) and store it all locally.</p><p>Within a few minutes, the shadow server should have a correct and complete replica of the information stored in the master server.</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec96"/>For Larger Directories...</h3></div></div></div><p>The automatic download of the directory information tree from master to shadow is definitely easy to do, but with a large directory information tree with gigabytes of information, performing the update over the network (using the LDAP protocol for every transaction) can be unduly time-intensive as well as resource-intensive.</p><p>In such cases, it is often better to use <code class="literal">slapcat</code> on the master to dump the directory contents (no need to stop SLAPD to do this), and then transfer the LDIF file to the shadow server and import it with <code class="literal">slapadd</code>.</p><div><div><h3 class="title"><a id="note129"/>Note</h3><p><a class="link" href="apc.html" title="Appendix C. Useful LDAP Commands">Appendix C</a> contains instructions on using <code class="literal">slapcat</code> and <code class="literal">slapadd</code> to dump and load SLAPD databases.</p></div></div><p>Since the <code class="literal">slapcat</code> and <code class="literal">slapadd</code> programs do not incur the overhead of the LDAP network protocol, they can outperform SyncRepl on adding new records. And on networks where bandwidth cannot be devoted to such large-scale data transfers, LDIF files can be transported via alternate (offline) media.</p><p>Once the directory databases have been populated with <code class="literal">slapadd</code>, you can start the shadow server.</p></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec94"/>Delta SyncRepl</h2></div></div></div><a class="indexterm" id="id757"/><a class="indexterm" id="id758"/><a class="indexterm" id="id759"/><p>By default, when the master sends a shadow server a modified or added record, it sends <em>the</em> <em>entire</em> <em>record</em>, not just the changes. This is done because the master does not keep track of what information has been sent to the shadow server.</p><p>But the <code class="literal">accesslog</code> overlay does keep track of what information is sent to the shadow servers. By configuring SLAPD to use the <code class="literal">accesslog</code> overlay to provide logging information for the the <code class="literal">syncprov</code> overlay the replication process can be streamlined, sending only the changed information instead of the whole record. This is called <strong>Delta SyncRepl</strong>. In modification-heavy networks or directories that contain very large records, this streamlining can result in noticeable performance improvements.</p><div><div><h3 class="title"><a id="note130"/>Note</h3><p>
<strong>Delta SyncRepl</strong> is an advanced configuration. As it involves the cooperation of a couple of overlays, as well as some fairly-complicated configuration, it may not be the best solution for all configurations. My own experience with small and medium-sized directories replicating over LAN and WAN links has been that regular SyncRepl is sufficient, and Delta SyncRepl is not necessary.</p></div></div><p>Configuring Delta SyncRepl requires a few changes on the master server, and a small change on the shadow server.</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec97"/>The Master Server's Configuration</h3></div></div></div><a class="indexterm" id="id760"/><p>The master server must be running the <code class="literal">accesslog</code> overlay, which we implemented in Chapter 5. We will start off by setting up the logging database for that overlay. This configuration is very similar to the one created in Chapter 5:</p><div><pre class="programlisting"># Database 1: Logging DB
# This is used by the access
# log overlay

database hdb
suffix cn=log
rootdn          "cn=Manager,cn=log"
rootpw          secret
directory       /var/lib/ldap/accesslog
index reqStart,objectclass,entryCSN,reqResult eq

overlay syncprov
syncprov-nopresent TRUE
syncprov-reloadhint TRUE</pre></div><p>This section creates a new logging database, named <code class="literal">cn=log</code>, into which access log information will be written.</p><p>Only a few lines in this section differ from the configuration in Chapter 5. First, the index directive now builds indexes on <code class="literal">reqStart</code>, <code class="literal">objectclass</code>, <code class="literal">entryCSN</code>, and <code class="literal">reqResult</code>. While <code class="literal">reqStart</code> and <code class="literal">entryCSN</code> are used internally, the SyncRepl consumer will make heavy use of <code class="literal">objectclass</code> and <code class="literal">reqResult</code> attributes, so indexing these will speed up the replication process. <a class="indexterm" id="id761"/>
</p><p>The last four directives are new. The <code class="literal">syncprov</code> overlay must be added to the accesslog database configuration in order to configure the accesslog for SyncRepl. These two flags, <code class="literal">syncprov-nopresent</code> and <code class="literal">syncprov-reloadhint</code>, both must be turned on (<code class="literal">TRUE</code>) for the Delta SyncRepl to work. In fact, the <code class="literal">syncprov-nopresent</code> flag should <em>only</em> be turned on when doing Delta SyncRepl.</p><div><div><h3 class="title"><a id="tip5454635435"/>Tip</h3><p><strong>Setting Limits and ACLs</strong></p><p>Depending on your <code class="literal">sizelimit</code> and <code class="literal">timelimit</code> settings, you may need to explicitly grant the <code class="literal">uid=syncrepl</code> user unlimited time and size limits on the <code class="literal">cn=log</code> database. Also, make sure the ACLs for this database grant <code class="literal">read</code> access to <code class="literal">uid=syncrepl</code>. See Chapter 4 for more on ACLs, and Chapter 5 for more on <code class="literal">limit</code> directives.</p></div></div><p>Finally, we want to give the <code class="literal">syncrepl</code> user unlimited search time and result size with the <code class="literal">limit</code> directive introduced in Chapter 5.</p><p>Next, we need to slightly reconfigure the database that we are going to replicate. In the <code class="literal">slapd.conf</code> file, this should be placed directly beneath the given accesslog definition:</p><div><pre class="programlisting">##############################
# Database 2: Example.Com

database        hdb
cachesize       500
idlcachesize    1500
suffix          "dc=example,dc=com"
rootdn          "cn=Manager,dc=example,dc=com"
rootpw          secret
directory      /var/lib/ldap
index   objectClass     eq
index   cn      eq,sub,pres,approx
index   uid     eq,sub,pres
index   sn      eq,sub,approx
index   member  eq
index   entryCSN,entryUUID      eq
overlay syncprov
syncprov-checkpoint 50 10
syncprov-sessionlog 100
<a class="indexterm" id="id762"/>
<strong>overlay accesslog
logdb cn=log
logops writes
# Purge logs for entries one week old, check once every two days.
logpurge 7+00:00 2+00:00</strong>
<strong>logsuccess TRUE</strong>
</pre></div><p>The highlighted section marks the new addition to the database section of the replicated backend database. The <code class="literal">accesslog</code> overlay here is configured to use the <code class="literal">cn=log</code> database defined previously. The only operations we need to record are those that write to the database (add, modify, delete, and modrdn).</p><div><div><h3 class="title"><a id="note131"/>Note</h3><p>Depending on your size and time-limit settings, you may also need to add an explicit limits directive granting <code class="literal">uid=syncrepl</code> unlimited time and result size to finish operations.</p></div></div><p>These are the only changes that need to be done on the master. Now we will look at the changes to the shadow server's <code class="literal">slapd.conf</code> file.</p></div><div><div><div><div><h3 class="title"><a id="ch07lvl3sec98"/>The Shadow Server's Configuration</h3></div></div></div><a class="indexterm" id="id763"/><p>On the consumer (shadow server) side, enabling Delta SyncRepl requires the addition of a couple of parameters in the <code class="literal">syncrepl</code> directive:</p><div><pre class="programlisting">syncrepl rid=001
  provider=ldap://10.21.77.100
  type=refreshOnly
  interval=00:00:02:00
  searchbase="dc=example,dc=com"
  binddn="uid=syncrepl,ou=system,dc=example,dc=com"
  credentials="secret"
<strong>  syncdata=accesslog</strong>
<strong>  logbase="cn=log"</strong>
<strong>  logfilter="(&amp;(objectclass=auditWriteObject)(reqResult=0))"</strong>
</pre></div><p>The new portion of the <code class="literal">syncrepl</code> directive consists of the addition of the three highlighted lines at the end of the given example. These lines instruct the shadow server to consult the master's accesslog database to get information about synchronization.</p><p>The <code class="literal">syncdata</code> parameter indicates what source SyncRepl should use to get information about the records which need updating. This should be set to <code class="literal">accesslog</code> to indicate that we are using an accesslog backend.</p><p>The <code class="literal">logbase</code> directive should be set to the base DN of the access-log on the master server. In the previous section we set this to <code class="literal">cn=log</code>.<a class="indexterm" id="id764"/>
</p><p>Finally, the <code class="literal">logfilter</code> parameter defines what filter ought to be used when searching the master server's accesslog. When it comes to replication, we want information about any changes to the database—adds, modifies, modRDNs, or deletes. These are all writing operations and will be recorded in the accesslog with the <code class="literal">auditWriteObject</code> object class. Further, we only want to synchronize transactions that were done successfully (remember, accesslog records failed attempts to change the directory and we don't want to replicate those). In cases where writes are successful the <code class="literal">reqResult</code> flag will be set to <code class="literal">0</code>. So we add that to our filter too.</p><div><div><h3 class="title"><a id="note132"/>Note</h3><p>For a complete set of configuration files doing Delta SyncRepl, see the following Tech Note on the Connexitor blog: <a class="ulink" href="http://www.connexitor.com/forums/viewtopic.php?t=3">http://www.connexitor.com/forums/viewtopic.php?t=3</a> (Connexitor is Symas's commercially-supported distribution of OpenLDAP).</p></div></div><p>Now both the master and the shadow servers are configured. When starting things up for the first time you may want to delete the old shadow database (see the instructions earlier in this chapter) and start over. Again, restart the master server before starting the consumer.</p><p>That's all there is to configuring Delta SyncRepl. Next, we will take a look at some strategies for debugging replication problems.</p></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec95"/>Debugging SyncRepl</h2></div></div></div><a class="indexterm" id="id765"/><p>One of the frustrating factors of configuring a network-based server-to-server setup like SyncRepl is the difficulty in debugging. Here are a few tips for making SyncRepl debugging easier.</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec99"/>Starting Over</h3></div></div></div><p>Sometimes a first shot at configuring replication fails. It is possible, and in fact quite easy, to wipe out the entire database for the shadow server and then start over again from scratch.</p><p>If you are using the BDB or HDB backends, all you need to do is delete all of the data files in the database directory:</p><div><pre class="programlisting">
<strong>  $ sudo /etc/init.d/slapd stop</strong>
<strong>  $ cd /var/lib/ldap</strong>
<strong>  $ rm -f *.bdb __db.* log.*</strong>
</pre></div><div><div><h3 class="title"><a id="note133"/>Note</h3><p>Warning: Make sure you do not delete the <code class="literal">DB_CONFIG</code> file!</p></div></div><p>The next time you restart SLAPD it will rebuild the data files from scratch.</p><p>Similar steps can be taken to migrate databases, fix corrupted backends, and so forth. But these cases require a little more care. For more detailed instructions, see <a class="link" href="apc.html" title="Appendix C. Useful LDAP Commands">Appendix C</a>.</p></div><div><div><div><div><h3 class="title"><a id="ch07lvl3sec100"/>Strategic Logging</h3></div></div></div><a class="indexterm" id="id766"/><p>Another way of debugging replication is to run the shadow SLAPD instance in the foreground and turn on the <code class="literal">sync</code> log level:</p><div><pre class="programlisting">
<strong>  $ sudo slapd -d sync</strong>
</pre></div><p>This will print verbose information on the synchronization process.</p><p>Increasing log information on the master server may also be helpful. The <code class="literal">acl</code> logging level can be useful for evaluating how access rules are applied to the SyncRepl user's requests. For harder issues, the <code class="literal">trace</code> debug level can also be very helpful.</p></div><div><div><div><div><h3 class="title"><a id="ch07lvl3sec101"/>A Few Common Mistakes</h3></div></div></div><a class="indexterm" id="id767"/><p>There are a few common mistakes made when configuring SyncRepl.</p><p>
<strong>Limits and ACLs</strong><a class="indexterm" id="id768"/>
<a class="indexterm" id="id769"/>: I have already mentioned the time- and size-limit issue: <code class="literal">sizelimit</code> and <code class="literal">timelimit</code> directives apply to the SyncRepl user just as they do to any other non-manager account. If the database has more entries than the maximum size limit, or the connection takes a long time to replicate, then the replication from master to shadow may end prematurely, resulting in an incomplete synchronization.</p><p>ACLs too can have surprising results in replication. If an ACL denies access to the SyncRepl user, it will not be able to synchronize that information. That, too, can result in incomplete synchronization. Fortunately, SLAPD will attempt to automatically bridge as many of these inconsistencies as it can. Unfortunately, that may keep the problem invisible for a longer period of time.</p><p><strong>Untuned DB_CONFIG</strong>: <a class="indexterm" id="id770"/>In Chapter 5, we looked at the <code class="literal">DB_CONFIG</code> file, a special configuration file for tuning the BDB/HDB database backend. When configuring a shadow server it is important to put a <code class="literal">DB_CONFIG</code> file in the database directory (<code class="literal">/var/lib/ldap</code>). If the <code class="literal">DB_CONFIG</code> file is absent or poorly tuned, the database environment will be much slower. While that may not be noticeable to clients performing brief occasional searches, this can have detrimental effects on replication. Larger transactions (like the initial update or transferring of significant modifications) can be many times slower than they would be with a well-tuned database environment.</p><p>Sometimes, this just increases delay times in updating the database, but when combined with time limits, it can result in truncated synchronizations.</p><p><strong>Failed SASL Authentication</strong>: <a class="indexterm" id="id771"/>SASL configurations can sometimes cause confusion when implementing SyncRepl (or SLURPD, for that matter). If you typically use SASL for authentication, and the SASL information is not stored in the directory information tree, then you will also need to make sure the external SASL data is synchronized.</p><p>In Chapter 4 we configured SASL to do DIGEST-MD5 authentication using the external <code class="literal">/etc/sasldb2</code> file for storing passwords. If we are to use SASL DIGEST-MD5 authentication on our shadow servers, we will need to make sure that they each have the same <code class="literal">/etc/sasldb2</code> file, which will require using some other non-OpenLDAP tool, like <strong>rsync</strong> (<a class="ulink" href="http://samba.anu.edu.au/rsync/">http://samba.anu.edu.au/rsync/</a>).</p><p>One method of working around this is to store cleartext SASL passwords inside of the directory, instead of in the <code class="literal">sasldb2</code> file. This is done simply by using the <code class="literal">{CLEARTEXT}</code> password hash instead of <code class="literal">{SSHA}</code> or some other mechanism. See Chapter 3 for more information. The OpenLDAP Administrator's Guide (<a class="ulink" href="http://openldap.org">http://openldap.org</a>) also explains this configuration.</p><p>Simple binding (by DN and user password) should work just fine with replication, as should the SASL EXTERNAL authentication we configured in Chapter 6.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec41"/>Configuring an LDAP Proxy</h1></div></div></div><a class="indexterm" id="id772"/><p>Sometimes, instead of replicating a directory information tree, it is desirable to proxy the communication with an LDAP directory. In this scenario a SLAPD server is configured to stand between clients and another LDAP server elsewhere on the network, and respond to client requests with directory information retrieved from the other LDAP server.</p><p>OpenLDAP supports a couple of different ways of configuring SLAPD to serve as a proxy.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec96"/>Using the LDAP Backend</h2></div></div></div><a class="indexterm" id="id773"/><p>One way of setting up proxying between two servers is to configure one server to use the <code class="literal">ldap</code> backend (instead of BDB or HDB). The <code class="literal">ldap</code> backend listens for requests and, when it gets them, transparently forwards the request to another LDAP server. For example, say we have two servers, directory.example.com, which stores the database, and proxy.example.com which uses the <code class="literal">ldap</code> backend to proxy requests to the directory.example.com server.</p><p>From the client's perspective, when the client connects to proxy.example.com, it appears to get results from proxy.example.com. All network traffic moves between the client and the proxy, and there is nothing in the returned results that indicates that the result were fetched from another server. In addition, the <code class="literal">ldap</code> backend follows referrals automatically, rather then requiring the client application to do referral chasing.</p><p>From the perspective of directory.example.com, the connection comes from proxy.example.com.</p><p>At the protocol level, the <code class="literal">ldap</code> backend transparently forwards all requests from the client on to the other server. In other words, when the client binds, it is not binding to proxy.example.com but to directory.example.com.</p><div><div><h3 class="title"><a id="note134"/>Note</h3><p>This too is configurable, and more advanced binding configurations can be achieved. Such features are discussed in the section <em>Using</em> <em>Identity</em> <em>Management</em> <em>Features</em>.</p></div></div><p>Every client gets its own connection from the proxy to the directory, with one exception. All the clients that connect as the anonymous user are proxied through the same connection to the remote server.</p><div><div><h3 class="title"><a id="note135"/>Note</h3><p>TLS connections go from the client to the proxy. The proxy can be configured to use TLS between it and the remote server either when the client requests TLS, or every time the proxy connects to the remote server. This is done with the <code class="literal">tls</code> directive for the <code class="literal">ldap</code> backend.</p></div></div><p>Configuring the <code class="literal">ldap</code> backend to act as a proxy is very simple. Here is a complete <code class="literal">slapd.conf</code> configured for the <code class="literal">ldap</code> backend:</p><div><pre class="programlisting"># slapd.conf - Configuration file for LDAP SLAPD
##########
# Basics #
##########

include  /etc/ldap/schema/core.schema
include  /etc/ldap/schema/cosine.schema
include  /etc/ldap/schema/inetorgperson.schema
include  /etc/ldap/schema/blog.schema

pidfile  /var/run/slapd/slapd.pid
argsfile /var/run/slapd/slapd.args
loglevel none

modulepath /usr/lib/ldap
<strong>moduleload back_ldap
################
# LDAP Backend #
################</strong>
<strong>database ldap</strong>
<strong>uri "ldap://directory.example.com"</strong>
<strong>suffix "dc=example,dc=com"</strong>
</pre></div><p>The significant points of this example are highlighted.</p><p>Once the <code class="literal">back_ldap</code> module has been loaded, the backend is defined in just three directives. The database directive points to the <code class="literal">ldap</code> backend (instead of the <code class="literal">hdb</code> backend we have been using in previous chapters).</p><p>The <code class="literal">uri</code> directive takes as a value a space-separated list of LDAP URLs. In this case there is only one. Having more than one URL comes in handy when one of the servers goes down. When there is a list, the <code class="literal">ldap</code> backend will try to connect to the servers in order. If the first server is down, it will move on to the second URL, and so on until it either runs out of servers or finally makes a connection.</p><p>The <code class="literal">suffix</code> directive indicates which suffix or suffixes this backend serves. This should contain the base DN or DNs that the remote directory provides. It is possible to use the proxy to make available only a branch or two of the remote server using this method. For example, the remote server might provide access to <code class="literal">dc=example,dc=com</code>. But we could set the suffix on this proxy to <code class="literal">ou=users,dc=example,dc=com</code>, and users of this server would then only be able to search that part of the directory information tree through this proxy.</p><div><div><h3 class="title"><a id="note136"/>Note</h3><p>A number of OpenLDAP users have reported successfully implementing the <code class="literal">ldap</code> backend to proxy requests to other directory servers, such as Microsoft's Active Directory.</p></div></div><p>There are a handful of other configuration options available for the <code class="literal">ldap</code> backend, all of which are document in the <code class="literal">slapd-ldap</code> man page: <code class="literal">man</code> <code class="literal">slapd-ldap</code>. But we will only look at one subset: the identity management features.<a class="indexterm" id="id774"/>
</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec102"/>Using Identity Management Features</h3></div></div></div><a class="indexterm" id="id775"/><p>There are more sophisticated things that can be done with the <code class="literal">ldap</code> backend. You can, for instance, separate the authentication and authorization tasks, authenticating as the DN supplied by the client but then performing all work as a different user.</p><a class="indexterm" id="id776"/><p>This feature, called <strong>ID assertion</strong>,  allows you to set up a proxy (perhaps accessible on a less secure network) that can allow users to bind as themselves, but then use an account with lower permissions (such as a system account whose permissions are restricted by ACLs) to get only a limited subset of information from the directory.</p><p>Configuring ID assertion requires only a few additional directives. On the proxy, you will need to add two directives to the <code class="literal">ldap</code> database configuration: <code class="literal">idassert-bind</code> and <code class="literal">idassert-authzFrom</code>.</p><p>The <code class="literal">idassert-bind</code> directive specifies how the proxy server ought to authenticate to the remote directory server. Here's an example configuration:</p><div><pre class="programlisting">idassert-bind
  bindmethod=simple
  binddn="uid=authenticate,ou=system,dc=example,dc=com"
  credentials="secret"
  mode=none</pre></div><p>This directive defines the account (and authentication style) that the proxy will use to connect to the remote directory in order to authenticate the client.</p><p>The supported values of <code class="literal">bindmethod</code> are <code class="literal">simple</code> (to do a simple bind), <code class="literal">sasl</code> (to do SASL binds), and <code class="literal">none</code>. If <code class="literal">none</code> is used then ID assertion is not done (which achieves the same effect as not using this directive at all).</p><p>The <code class="literal">binddn</code> and <code class="literal">credentials</code> parameters specify the DN and password for connecting to the remote directory.</p><p>The mode parameter specifies whose identity will be asserted to the remote server. In the given example we set the mode to <code class="literal">none</code>, which means that the proxy will assert the DN specified in <code class="literal">binddn</code> as its identity. In other words, the proxy will perform all operations on the remote server as the DN in <code class="literal">binddn</code>.</p><p>For a more complicated proxy, you can set <code class="literal">mode</code> to <code class="literal">anonymous</code> (which asserts the anonymous identity to the remote directory) or <code class="literal">self</code> (which asserts the identity sent by the client). These implement the <strong>Proxied Authorization </strong>(<strong>proxyAuth</strong>)<strong> Control</strong> defined in RFC 4370 (<a class="ulink" href="http://www.rfc-editor.org/rfc/rfc4370.txt">http://www.rfc-editor.org/rfc/rfc4370.txt</a>).</p><p>For <code class="literal">anonymous</code> or <code class="literal">self</code>, you may also need to set the <code class="literal">authz-policy</code> directive in <code class="literal">ldap.conf</code>, and add <code class="literal">authzFrom</code> or <code class="literal">authzTo</code> entries to the proxy's or client's DN (respectively). For more information see the man pages for <code class="literal">slapd.conf</code> and <code class="literal">slapd-ldap</code>.</p><p>The <code class="literal">idassert-authzFrom</code> directive is used to authorize which clients can make use of the proxy. For example, we could set a rule that allows users to use the proxy if their DNs are in the <code class="literal">ou=users</code> subtree:<a class="indexterm" id="id777"/>
</p><div><pre class="programlisting">idassert-authzFrom dn.subtree="ou=users,dc=example,dc=com"</pre></div><p>Like other directives that make use of the <code class="literal">dn</code> specifier, this one supports the regular list of modifiers, like <code class="literal">dn.subtree</code>, <code class="literal">dn.one</code>, and <code class="literal">dn.regex</code>. See the discussion of limits in Chapter 5 for an explanation of these modifiers.</p></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec97"/>Turning the Simple Proxy into a Caching Proxy</h2></div></div></div><a class="indexterm" id="id778"/><p>As we have configured the proxy so far, every request to the proxy is relayed to the remote directory server. No results are retained on the proxy. <a class="indexterm" id="id779"/>So when the same request is performed several times, the proxy connects to the remote directory server each time and forwards the request. It is possible, however, to use the <code class="literal">pcache</code> (<strong>Proxy Cache</strong>) overlay to add caching to the proxy, storing a subset of the remote directory on the proxy. This can significantly speed up performance in some cases.</p><p>Proxy Cache works by storing a subset of frequently-accessed information in a database on the proxy SLAPD instance. When the proxy receives a request for information stored in the cache, it will return the cached data instead of fetching the records from the remote server.</p><p>Records are stored in an <strong>LRU (Least Recently Used)</strong> cache, which means that once the cache fills up, the records that were accessed <em>least</em> <em>recently</em> are removed to make way for new entries. Additionally, an entry is only served out of the cache for a certain period of time (called Time To Live, or TTL) before the proxy once again connects to the remote directory to fetch a fresh copy of the entry. This keeps the proxy from serving stale or out of date information that has changed in the main directory since the last time the proxy accessed the records.</p><div><div><h3 class="title"><a id="note137"/>Note</h3><p>Binding is not cached by <code class="literal">pcache</code>. Every client connection must still bind, and the behavior of the bind operation depends on the configuration of the <code class="literal">ldap</code> backend. It can use ID assertion, or pass authentication through to the remote host.</p></div></div><p>The <code class="literal">pcache</code> overlay is configured in the proxy's <code class="literal">slapd.conf</code> file. The first few steps of implementing the <code class="literal">pcache</code> overlay are familiar. Near the top of our configuration file we need to add the <code class="literal">moduleload</code> <code class="literal">pcache</code> line to load the correct module.</p><p>In the database section we need to add the <code class="literal">pcache</code> overlay with the usual <code class="literal">overlay</code> directive. Then, there are several directives necessary to configure the <code class="literal">pcache</code> overlay. Here is the entire database configuration section for an <code class="literal">ldap</code> database with the proxy cache overlay:</p><div><pre class="programlisting">database ldap
uri "ldap://10.21.77.100"
suffix  "dc=example,dc=com"
rootdn "cn=Manager,dc=example,dc=com"

idassert-bind
  bindmethod=simple
  binddn="uid=authenticate,ou=system,dc=example,dc=com"
  credentials="secret"
  mode=none

idassert-authzFrom "dn.subtree:dc=example,dc=com"

overlay pcache
proxycache bdb 1000 1 50 1200
directory /var/lib/ldap/cache
index objectclass eq
index uid,mail eq,sub
index queryid eq
<a class="indexterm" id="id780"/>
proxycachequeries 100
proxyattrset 0 uid mail cn sn givenName
proxytemplate (uid=) 0 600</pre></div><p>The beginning of the file does not differ much from the identity assertion configuration we used in the previous section. One difference however, is the addition of the <code class="literal">rootdn</code> directive which is required by the database-backed <code class="literal">pcache</code> overlay. It is never used for authentication purposes so using the base DN of the directory is fine.</p><p>Once the overlay has been added to the overlay stack using <code class="literal">overlay</code> <code class="literal">pcache</code>, the first proxy cache directive appears:</p><div><pre class="programlisting">proxycache bdb 1000 1 50 1200</pre></div><p>This directive handles the core configuration of the proxy cache engine. It has five different parameters: </p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The database type: <code class="literal">pcache</code> needs a place to store the cached data, and it can use one of the underlying database mechanisms such as <code class="literal">bdb</code>, <code class="literal">hdb</code>, or <code class="literal">ldif</code>. If you want an efficient storage system, <code class="literal">bdb</code> or <code class="literal">hdb</code> are the best choices. Later in the configuration, we will have to set some directives for the database.</li><li class="listitem" style="list-style-type: disc">The maximum number of entries in the cache: You can set an upper limit on the number of entries that will be cached. You can estimate how many entries you need based on the number of records in this database and the type of use that this proxy will get.</li><li class="listitem" style="list-style-type: disc">The number of attribute sets to store: The proxy cache stores a subset of information from the remote directory. Which attributes are cached is controlled by defining <strong>attribute sets</strong>. This parameter should be set to the number of attribute sets defined. We will initially define one, so the value above is <code class="literal">1</code>.<a class="indexterm" id="id781"/></li><li class="listitem" style="list-style-type: disc">The maximum number of entires per search result. Some searches can return a large number of entries, and this takes up a lot of space on the proxy (and introduces inefficiency if this particular large search is not frequently performed). To avoid such a problem, this parameter specifies the maximum number of entries that a search can have if its results are to be cached. A search that returns more than the max (<code class="literal">50</code> in this case) will not be cached.</li><li class="listitem" style="list-style-type: disc">The consistency check interval. This specifies the number of seconds to wait between checking records for expired TTLs. If a record's TTL has passed, then the record is considered stale and is removed from the cache.</li></ul></div><p>The first field in the <code class="literal">proxycache</code> directive is the database type, specifying what database backend will be used to store cached data. Now we need to add a few directives to configure that database backend:</p><div><pre class="programlisting">directory /var/lib/ldap/cache
index objectclass eq
index uid,mail eq,sub
index queryid eq</pre></div><p>The <code class="literal">directory</code> directive (a familiar one we used when configuring the HDB backend in Chapter 3) points to the directory where the BDB files will be stored.</p><p>If you set <code class="literal">directory</code> to a location that doesn't exist yet, make sure to create that directory on the file system: <code class="literal">mkdir</code> <code class="literal">/var/lib/ldap/cache</code>. You should also put a copy of the <code class="literal">DB_CONFIG</code> file in the <code class="literal">cache/</code> directory, or else the default Berkeley DB settings will be used, and those usually result in poor performance.</p><p>After the database directive, there are several index directives which specify which indexes ought to be created and what types of searches each should support. As usual, these index files can be used to expedite performance.</p><p>There are two indexes that should definitely be included: an equality index on <code class="literal">objectclass</code>, and an equality index on <code class="literal">queryid</code>. The <code class="literal">queryid</code> index is specific to the <code class="literal">pcache</code> backend which uses <code class="literal">queryid</code> to identify queries cached in the database. Other indexes should be specified where they will increase lookup speeds for the queries defined in the proxy cache templates (which we will examine in a moment).</p><p>You can also use other directives (like <code class="literal">cachesize</code>) that are defined for the BDB backend. See the discussion in Chapter 5 and the man page for <code class="literal">slapd-bdb</code> for more detail.</p><p>Now we have a few more pcache-specific directives to examine:</p><div><pre class="programlisting">proxycachequeries 100
proxyattrset 0 uid mail cn sn givenName
proxytemplate (uid=) 0 600</pre></div><p>The <code class="literal">proxycachequeries</code> directive specifies how many queries (not entries) should be cached.<a class="indexterm" id="id782"/>
</p><p>The <code class="literal">proxyattrset</code> directive indicates what attributes ought to be cached. The proxy cache stores a subset of the remote directory. That subset is not merely a subset of the total entries, but also a subset of the attributes for each entry. In the example here, this <code class="literal">proxyattrset</code> specifies that only the <code class="literal">uid</code>, <code class="literal">mail</code>, <code class="literal">cn</code>, <code class="literal">sn</code>, and <code class="literal">givenName</code> attributes (and their values) should be cached. A request for any other attribute will be proxied to the remote server.</p><p>The <code class="literal">proxyattrset</code> directive has two parts:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The first is an integer identifier, <code class="literal">0</code> for the first <code class="literal">proxyattrset</code>, <code class="literal">1</code> for the second, and so on </li><li class="listitem" style="list-style-type: disc">The second part is the list of attributes (separated by spaces) that will be stored in the cache</li></ul></div><p>There can be more than one <code class="literal">proxyattrset</code>, but the total number of <code class="literal">proxyattrset</code> directives must be explicitly specified in the <code class="literal">proxycache</code> directive. In our configuration, we only have one <code class="literal">proxyattrset</code> directive, so the third parameter (the number of attribute sets) in the <code class="literal">proxycache</code> directive is set to <code class="literal">1</code>.</p><p>The last directive is the <code class="literal">proxytemplate</code> directive. A <strong>filter template</strong> specifies what sort of searches will be stored in the cache, and indicates which attributes will be stored for records that match the search filter. The directive has three parameters:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A filter template</li><li class="listitem" style="list-style-type: disc">The <code class="literal">proxyattrset</code> directive to use</li><li class="listitem" style="list-style-type: disc">The TTL for entries that match this template</li></ul></div><p>A filter template is a variation on a regular LDAP filter. A regular filter might look like this: <code class="literal">(uid=m*)</code>, or <code class="literal">(&amp;(ou=users)(objectclass=person))</code>. A filter template is a filter without the asserted value; that is, it is a template with nothing on the right-side of the equals sign. <code class="literal">(uid=)</code> and <code class="literal">(&amp;(ou=)(objectclass=))</code> are filter templates for the two search filters.</p><p>If an incoming search's filter matches the filter template (and it doesn't return more than the maximum number of results) then it will be handled by the cache. For example, the filters <code class="literal">(uid=*)</code>, <code class="literal">(uid=mat*)</code> and <code class="literal">(uid=dave)</code> all match the filter template <code class="literal">(uid=)</code>. They can be handled by the cache, but <code class="literal">(&amp;(uid=*)(ou=system))</code> cannot as it doesn't match a defined filter template.</p><p>The second parameter is the numeric identifier for the <code class="literal">proxyattrset</code> directive that should be used. In our example we set this to <code class="literal">0</code>, which uses <code class="literal">proxyattrset</code> <code class="literal">0</code>. Thus, this filter template caches the values of the <code class="literal">uid</code>, <code class="literal">mail</code>, <code class="literal">cn</code>, <code class="literal">sn</code>, and <code class="literal">givenName</code> attributes.</p><p>The <code class="literal">proxyattrset</code> directive is used to determine whether to serve incoming searches from the cache or by connecting to the remote directory. If the request matches a search filter template, and the attributes list supplied by the client has only attributes in <code class="literal">proxyattrset</code>, then results may be served out of the proxy cache. For example, if a request comes in with the search filter <code class="literal">(uid=m*)</code> (which matches the <code class="literal">(uid=)</code> template) and requests the <code class="literal">uid</code>, <code class="literal">mail</code>, and <code class="literal">sn</code> attributes, these results can be served out of the cache. On the other hand, if the attributes list is <code class="literal">uid</code>, <code class="literal">mail</code>, and <code class="literal">telephoneNumber</code>, then the cache will be skipped and the proxy will fetch the information from the remote server. Why is this? Simply because one of the attributes, <code class="literal">telephoneNumber</code>, is not stored in the cache at all, and so the <code class="literal">pcache</code> overlay cannot fulfill the entire request.</p><p>The third parameter for the <code class="literal">proxytemplate</code> directive is the TTL. This specifies how many seconds an entry can be in the cache before it is considered stale and removed or refreshed.<a class="indexterm" id="id783"/>
</p><p>There is a special fourth parameter that can be used too: the so-called <strong>Negative TTL</strong>. By default, the proxy cache caches only successful requests. That is, if a search request is made, and the remote directory returns zero records, no information is cached.</p><p>Sometimes, however, it might be useful to cache a "miss," so that if the same query comes in again it can be immediately served from the cache, instead of requiring another trip to the remote directory—a trip likely to result in the same empty result set. The negative TTL parameter allows you to turn on caching of misses, and also set the number of seconds that a negative result (a record of a miss) should be retained in the cache.</p><div><div><div><div><h3 class="title"><a id="ch07lvl3sec103"/>Notes on the Attribute Sets and Templates</h3></div></div></div><a class="indexterm" id="id784"/><a class="indexterm" id="id785"/><a class="indexterm" id="id786"/><p>One of the potentially confusing things about the proxy cache overlay is the relationship between attribute sets and filter templates (and the <code class="literal">proxycache</code> directive's count of attribute sets).</p><p>Every attribute set should be referenced by at least one filter template. But multiple filter templates can use the same attribute set. For example, the following is legitimate: </p><div><pre class="programlisting">proxycachequeries 100
proxyattrset 0 uid mail cn sn givenName
proxytemplate (&amp;(mail=)(objectclass=)) 0 600
proxytemplate (uid=) 0 600</pre></div><p>In this case, both filter templates refer to the same attribute set (the one with the ID number <code class="literal">0</code>).</p><p>The same template can be used with different attribute sets. Here's what happens under such circumstances. Consider the following:</p><div><pre class="programlisting">overlay pcache
proxycache bdb 1000 2 50 1200
# ... skipped a few lines...
proxyattrset 0 uid mail cn sn givenName
proxyattrset 1 uid description
proxytemplate (uid=) 0 600
proxytemplate (uid=) 1 600</pre></div><p>The above is legal and works but has interesting results.</p><div><div><h3 class="title"><a id="note138"/>Note</h3><p>Notice that the third parameter of <code class="literal">proxycache</code> is now <code class="literal">2</code> instead of <code class="literal">1</code>. This reflects the fact that there are now two <code class="literal">proxyattrset</code> directives defined.</p></div></div><p>If a search is done for <code class="literal">(uid=m*)</code> requesting <code class="literal">uid</code> and <code class="literal">mail</code>, a cache entry will be generated for the first attribute set.</p><p>But if a search is done for <code class="literal">(uid=m*)</code> requesting <code class="literal">uid</code> and <code class="literal">description</code>, then an entry is generated for the second attribute set.</p><p>If a search is done for <code class="literal">(uid=m*)</code> requesting <code class="literal">mail</code> and <code class="literal">description</code>, it will <em>miss</em> both caches and results will be retrieved from the remote server.</p><p>The proxy cache overlay can turn the <code class="literal">ldap</code> backend into more than just a simple proxy. By tuning the attribute sets and templates to match frequently used queries, you can use <code class="literal">pcache</code> to improve the responsiveness of the proxy and reduce the amount of traffic to the remote directory.</p></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec98"/>A Translucent Proxy</h2></div></div></div><a class="indexterm" id="id787"/><p>Consider the following situation. A remote directory contains the basic information that you need. You want to create an LDAP proxy to that directory but there are a few values that you want to modify on the proxy (but not on the remote directory).</p><p>This can be done with the <code class="literal">translucent</code> overlay, which proxies requests to a remote directory, but also allows attributes to be locally modified and stored while not modifying the remote directory information tree. This sort of hybrid proxy is called a <strong>translucent proxy</strong>.<a class="indexterm" id="id788"/>
</p><p>We will briefly take a look at configuring a translucent proxy.</p><p>As usual, near the top of the <code class="literal">slapd.conf</code> file of the proxy, we will need to load the translucency module. We will also need the LDAP and BDB module, since both backends will be used:</p><div><pre class="programlisting">moduleload back_ldap
moduleload back_bdb
moduleload translucent</pre></div><p>Now we can skip ahead in the configuration file to the database section.</p><p>For a translucent proxy we will need to configure it to store some information locally, but also act like a proxy and retrieve information from a remote directory server. Here is a sample configuration for the <code class="literal">transparent</code> overlay:</p><div><pre class="programlisting">database bdb
directory /var/lib/ldap/transparent
suffix "dc=example,dc=com"
rootdn "uid=authenticate,ou=system,dc=example,dc=com"
rootpw secret
index objectclass eq
index uid eq,sub
lastmod off
overlay translucent
uri "ldap://10.21.77.100"

idassert-bind
    bindmethod=simple
    binddn="uid=authenticate,ou=system,dc=example,dc=com"
    credentials="secret"
    mode=none

idassert-authzFrom "dn.subtree:dc=example,dc=com"</pre></div><p>The <code class="literal">transparent</code> overlay uses a database (in this case the <code class="literal">bdb</code> backend) to store information locally, and then implicitly uses the <code class="literal">ldap</code> backend to connect to the remote directory. As with the <code class="literal">pcache</code> overlay, it is best to use BDB or HDB for the backend data storage mechanism.</p><p>For the <code class="literal">bdb</code> backend configuration, we need the usual directives: <code class="literal">directory</code>, <code class="literal">suffix</code>, <code class="literal">rootdn</code>, <code class="literal">rootpw</code>, and one or more <code class="literal">index</code> directives (we should at least have an equality index on <code class="literal">objectclass</code>).</p><p>We also turn off modification timestamps (<code class="literal">lastmod</code> <code class="literal">off</code>) so that SLAPD doesn't automatically generate the corresponding <code class="literal">modifiersName</code> and <code class="literal">modifyTimestamp</code> operational attributes. You can remove this line if you want that information to be stored in the proxy's database but, when a client requests a record from the proxy, it will see different modification information than it would see if connecting to the remote directory.</p><p>The <code class="literal">rootdn</code> and <code class="literal">rootpw</code> password play a special role in a translucent proxy. This DN is the <em>only</em> user that can add new records to the proxy's database. And any LDAP modification, add, or modRDN operations that come from this user will change <em>only</em> the local copy of the data. <a class="indexterm" id="id789"/>
</p><div><div><h3 class="title"><a id="note139"/>Note</h3><p>The root DN can only access values on the remote server that it is allowed to access, but it can add or modify any record on the local translucent database. This means, effectively, that it may be able to write entries into branches of the directory tree that it cannot access (because of ACLs on the remote directory).</p></div></div><p>Now we have the backend database configured. Next, we want to configure the <code class="literal">translucent</code> overlay.</p><p>After the <code class="literal">overlay</code> directive, inserting <code class="literal">translucent</code> into the overlay stack, we need to supply the <code class="literal">translucent</code> overlay with information about the remote directory.</p><p>Since the <code class="literal">translucent</code> overlay uses the <code class="literal">ldap</code> backend, any <code class="literal">ldap</code> backend parameters can be used here:</p><div><pre class="programlisting">overlay translucent
uri "ldap://10.21.77.100"

idassert-bind
  bindmethod=simple
  binddn="uid=authenticate,ou=system,dc=example,dc=com"
  credentials="secret"
  mode=none

idassert-authzFrom "dn.subtree:dc=example,dc=com"</pre></div><p>The <code class="literal">uri</code> directive is used to point the translucent proxy to the remote server. And again we use the identity assertion discussed earlier in this chapter to handle authorization to information from the remote server.</p><p>Now let's examine a few examples of the translucent proxy in action. First, we can grab a record proxied from the remote server:</p><div><pre class="programlisting">$ ldapsearch -x -W -D 'uid=matt,ou=users,dc=example,dc=com' \
    -H ldap://proxy.example.com -b 'dc=example,dc=com' 
      -LLL '(uid=manny)'
Enter LDAP Password: 

dn: uid=manny,ou=Users,dc=example,dc=com
sn: Kant
uid: immanuel
uid: manny
ou: Users
objectClass: person
objectClass: organizationalPerson
objectClass: inetOrgPerson
givenName: Manny
cn: Manny Kant<a class="indexterm" id="id790"/>
</pre></div><p>In this example we use <code class="literal">ldapsearch</code> to connect to the proxy (<code class="literal">ldap://proxy.example.com</code>) and retrieve the record with <code class="literal">uid=manny</code>.</p><p>This operation causes the proxy to retrieve the record from the remote server. It then compares that record to the information in its own database of modifications and, if any local modifications to that record apply, they will be inserted into the resulting record.</p><p>Let's say that we want to add a <code class="literal">description</code> field to Manny's record, but we only want that field to exist on the proxy not on the remote directory. We can accomplish this by using <code class="literal">ldapmodify</code>, and authenticating as the root DN for the proxy (<code class="literal">uid=authenticate,ou=system,dc=example,dc=com</code>):</p><div><pre class="programlisting">$ ldapmodify -x -W \
    -D 'uid=authenticate,ou=system,dc=example,dc=com'\
      -H ldap://proxy.example.com
Enter LDAP Password: 
<strong>dn: uid=manny,ou=users,dc=example,dc=com</strong>
<strong>changetype: modify</strong>
<strong>add: description</strong>
<strong>description: This was added only to the proxy.</strong>

modifying entry "uid=manny,ou=users,dc=example,dc=com"</pre></div><p>This modification simply adds the description attribute along with the message: <strong>This was added only to the proxy</strong>.</p><div><div><h3 class="title"><a id="note140"/>Note</h3><p>Note that in this example we bind as the DN listed as the rootdn for the translucent database. That is because this is the only DN that can write to the translucent (local) database.</p></div></div><p>Now the modification should have been written only to the translucent database. As a result we should be able to repeat our search before against the proxy and see the new description field:</p><div><pre class="programlisting">$ ldapsearch -x -W -D 'uid=matt,ou=users,dc=example,dc=com' \
    -H ldap://proxy.example.com -b 'dc=example,dc=com' -LLL \
      '(uid=manny)'
Enter LDAP Password: 

dn: uid=manny,ou=Users,dc=example,dc=com
sn: Kant
uid: immanuel
uid: manny
ou: Users
objectClass: person
objectClass: organizationalPerson
objectClass: inetOrgPerson
givenName: Manny
cn: Manny Kant<a class="indexterm" id="id791"/>
<strong>description: This was added only to the proxy.</strong>
</pre></div><p>When the proxy receives this search operation, it requests the entire record for <code class="literal">uid=manny</code> from the remote directory. That record looks something like this (plus the operational attributes, which are not shown):</p><div><pre class="programlisting">dn: uid=manny,ou=Users,dc=example,dc=com
sn: Kant
uid: immanuel
uid: manny
ou: Users
objectClass: person
objectClass: organizationalPerson
objectClass: inetOrgPerson
givenName: Manny
cn: Manny Kant</pre></div><p>The translucent proxy then compares that record with its own, which looks like this:</p><div><pre class="programlisting">dn: uid=manny,ou=users,dc=example,dc=com
description: This was added only to the proxy.</pre></div><p>The two records are then merged, with changes to the translucent database taking precedence over those from the remote directory. The result is the appending of the <code class="literal">description</code> attribute to the end of the returned record.</p><div><div><h3 class="title"><a id="note141"/>Note</h3><p>The translucent database can be dumped with the <code class="literal">slapcat</code> tool, and backups can be loaded with the <code class="literal">slapadd</code> tool.</p></div></div><p>But how do we know that this modification wasn't written to the remote directory? We can run a search on that directory and see the unchanged record:</p><div><pre class="programlisting">$ ldapsearch -x -W -D 'uid=matt,ou=users,dc=example,dc=com' \
    -H ldap://directory.example.com -b 'dc=example,dc=com' -LLL \
      '(uid=manny)'
Enter LDAP Password: 

dn: uid=manny,ou=Users,dc=example,dc=com
sn: Kant
uid: immanuel
uid: manny
ou: Users
objectClass: person
objectClass: organizationalPerson
objectClass: inetOrgPerson
givenName: Manny
cn: Manny Kant<a class="indexterm" id="id792"/>
</pre></div><p>A transparent proxy can be used to provide local modification of entries that are otherwise controlled externally. Like the other forms of proxying, there is no OpenLDAP-specific remote directory, the transparent proxy can use any standards-compliant LDAP v3 directory as a remote directory.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec42"/>Summary</h1></div></div></div><p>In this chapter we have examined several strategies for configuring LDAP servers to work cooperatively. We first looked at synchronizing and replicating a directory information tree from a master directory to one or more shadow (subordinate) directory servers using SyncRepl.</p><p>After looking at replication we turned to proxying, and looked at three different proxy configurations: the simple proxy, a caching proxy, and a transparent proxy.</p><p>This chapter concludes our detailed look at the OpenLDAP server suite. Next we will turn to the tasks of integrating LDAP and extending applications to make use of directory data. Most of the applications we will examine use the OpenLDAP libraries to implement their LDAP functionality.</p></div></body></html>